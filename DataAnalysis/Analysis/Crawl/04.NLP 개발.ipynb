{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://hipster4020.tistory.com/176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Service \n",
    "def blue(str):\n",
    "    from Functions import Service\n",
    "    return Service.colored_text(str,'blue')\n",
    "def yellow(str):\n",
    "    from Functions import Service\n",
    "    return Service.colored_text(str,'yellow')\n",
    "def red(str):\n",
    "    from Functions import Service\n",
    "    return Service.colored_text(str,'red')\n",
    "\n",
    "## ìì—°ì–´ì²˜ë¦¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜ \n",
    "def NLPInstalls():\n",
    "    import subprocess,sys\n",
    "    # pipê°€ ì—†ìœ¼ë©´ pipë¥¼ ì„¤ì¹˜\n",
    "    try:import pip\n",
    "    except ImportError:\n",
    "        print(\"Install pip for python3\")\n",
    "        subprocess.call(['sudo', 'apt-get', 'install', 'python3-pip'])\n",
    "    \n",
    "    # tweepy ì—†ìœ¼ë©´ tweepy ì„¤ì¹˜\n",
    "    try:import tweepy        \n",
    "    except ModuleNotFoundError:\n",
    "        print(\"Install tweepy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'tweepy==3.10.0'])\n",
    "    finally:import tweepy \n",
    "    \n",
    "    # konlpy ì—†ìœ¼ë©´ konlpy ì„¤ì¹˜\n",
    "    try:import konlpy\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install konlpy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'konlpy'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # eunjeon ì—†ìœ¼ë©´ eunjeon ì„¤ì¹˜\n",
    "    try:import eunjeon\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install eunjeon : eunjeon\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'eunjeon'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # datasets ì—†ìœ¼ë©´ datasetsë¥¼ ì„¤ì¹˜\n",
    "    try:import datasets\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install eunjeon : datasets\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'datasets'])\n",
    "    finally:import datasets\n",
    "    \n",
    "    # pytorch ì—†ìœ¼ë©´ pytorch ì„¤ì¹˜\n",
    "    try:import torch\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install eunjeon : pytorch\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'pytorch'])\n",
    "    finally:import torch\n",
    "    \n",
    "    # transformers ì—†ìœ¼ë©´ transformers ì„¤ì¹˜\n",
    "    try:import transformers\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install eunjeon : transformers\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'transformers'])\n",
    "    finally:import transformers\n",
    "NLPInstalls()\n",
    "\n",
    "\n",
    "## ê°ì •ë¶„ì„ ë°ì´í„° ì…‹ ì¤€ë¹„ \n",
    "from datasets import load_dataset\n",
    "emotions = load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mğŸ”¸ model check point : \u001b[0m distilbert-base-uncased\n",
      "\u001b[93mğŸ”¸ ì‚¬ìš©í•˜ëŠ” device : \u001b[0m cpu\n",
      "\u001b[93mğŸ”¸ ì‚¬ìš©í•˜ëŠ” ë””ë°”ì´ìŠ¤ì— ë§ëŠ” ëª¨ë¸: \u001b[0m DistilBertModel(\n",
      "  (embeddings): Embeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (layer): ModuleList(\n",
      "      (0-5): 6 x TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## pytorch importing \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings ; warnings.filterwarnings('ignore')\n",
    "from transformers import AutoTokenizer\n",
    "# from transformers import DistilBertTokenizer\n",
    "\n",
    "## chkpt :  Hugging face ì— ë“±ë¡ëœ distilBert ì–¸ì–´ ëª¨ë¸ì„ ê°€ì ¸ì˜´ .\n",
    "model_ckpt = 'distilbert-base-uncased' \n",
    "print(yellow(\"ğŸ”¸ model check point : \"), model_ckpt)\n",
    "## í† í¬ë‚˜ì´ì €ë¥¼ í†µí•´ì„œ í† í°í™” ì‘ì—….\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "## pretrained model  ì„ ì‚¬ìš©í•˜ë ¤ë©´ automodel importing,\n",
    "from transformers import AutoModel\n",
    "## pytorch ë¥¼ ì‚¬ìš©í•˜ì—¬ GPU ì‚¬ìš© ì—¬ë¶€ë¥¼ í™•ì¸ \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "## ì‚¬ìš©í•˜ëŠ” device ì— ë§ëŠ” ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜´. \n",
    "print(yellow(\"ğŸ”¸ ì‚¬ìš©í•˜ëŠ” device : \"),device)\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)\n",
    "print(yellow(\"ğŸ”¸ ì‚¬ìš©í•˜ëŠ” ë””ë°”ì´ìŠ¤ì— ë§ëŠ” ëª¨ë¸: \"),model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "## frame work í˜¸í˜¸í™˜ ì˜ˆì‹œ\n",
    "def framework():\n",
    "    from transformers import TFAutoModel\n",
    "    tf_model = TFAutoModel.from_pretrained(model_ckpt)\n",
    "    ## í”„ë ˆì„ì›Œí¬ê°„ ìƒí˜¸ í˜¸í™˜ì´ ë˜ì§€ì•ŠìŒ, pytorch ì™€ tensorflow ì˜ ì²´í¬í¬ì¸íŠ¸ê°€ ë‹¤ ë‹¤ë¥´ë‹¤.!!\n",
    "    tf_xlmr = TFAutoModel.from_pretrained('xlm-roberta-base', from_pt =True)\n",
    "    ## ì´ëŸ°ì‹ìœ¼ë¡œ from_pt ë¥¼ ë¶™ì´ë©´ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìë™ìœ¼ë¡œ íŒŒì´í† ì¹˜ ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ìš´ë¡œë“œí•´ ë³€í™˜í•¨. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ë§ˆì§€ë§‰ ì€ë‹‰ ìƒíƒœ ì¶”ì¶œí•˜ê¸° \n",
    "- í•˜ë‚˜ì˜ ë¬¸ìì—´ì— ëŒ€í•œ ë§ˆì§€ë§‰ ì€ë‹‰ ìƒíƒœë¥¼ ì¶”ì¶œ í•¨. \n",
    "- ë¬¸ìì—´ì„ ì¸ì½”ë”©í•˜ê³  í† í°ì„ íŒŒì´í† ì¹˜ í…ì„œë¡œ ë³€í™˜í•¨. \n",
    "- tokenizer ì— return_tensor=\"pt\" ë§¤ê°œë³€ìˆ˜ë¥¼ ì§€ì •í•´ ì´ì‘ì—…ì„ ìˆ˜í–‰í•¨. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mì›ë³¸ text : \u001b[0m \u001b[91mthis is a test i am Forrest\u001b[0m\n",
      "\u001b[93mğŸ”¸  ì…ë ¥ í…ì„œ í¬ê¸° :torch.Size([1, 9]) = [bach_size, n_tokens]\u001b[0m\n",
      "\u001b[93mğŸ”¸  Ids(vector) : tensor([[  101,  2023,  2003,  1037,  3231,  1045,  2572, 16319,   102]])\u001b[0m\n",
      "\u001b[93mğŸ”¸  Attention mask : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023,  2003,  1037,  3231,  1045,  2572, 16319,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = 'this is a test i am Forrest'\n",
    "inputs = tokenizer(text,return_tensors ='pt') ## íŒŒì´í† ì¹˜í…ì„œë¡œ ë³€í™˜\n",
    "print(blue(f'ì›ë³¸ text : '),red(f'{text}'))\n",
    "print(yellow(f'ğŸ”¸  ì…ë ¥ í…ì„œ í¬ê¸° :{inputs[\"input_ids\"].size()} = [bach_size, n_tokens]'))\n",
    "print(yellow(f'ğŸ”¸  Ids(vector) : {inputs[\"input_ids\"]}'))\n",
    "print(yellow(f'ğŸ”¸  Attention mask : {inputs[\"attention_mask\"]}'))\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> device ì— ìˆëŠ” ëª¨ë¸ì— ì…ë ¥ì„ ì „ë‹¬\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023,  2003,  1037,  3231,  1045,  2572, 16319,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutput(last_hidden_state=tensor([[[ 0.0185,  0.0394,  0.0283,  ..., -0.0326,  0.2196,  0.3650],\n",
      "         [-0.1387, -0.3454, -0.0797,  ..., -0.1926,  0.3445,  0.2568],\n",
      "         [-0.1854, -0.1602,  0.1703,  ...,  0.1295,  0.2070,  0.7750],\n",
      "         ...,\n",
      "         [ 0.1707,  0.2024,  0.1363,  ...,  0.1139,  0.2042,  0.1838],\n",
      "         [ 0.3101, -0.1290, -0.0113,  ...,  0.4925, -0.1913,  0.0816],\n",
      "         [ 0.9054,  0.2051, -0.3114,  ...,  0.1355, -0.6349, -0.3079]]]), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "## k -> input_ids,attenition_mask v -> tensor, tensor\n",
    "inputs = {k:v.to(device) for k,v in inputs.items()} \n",
    "\n",
    "with torch.no_grad(): ## ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©.  ë©”ëª¨ë¦¬ì–‘ ì¤„ì–´ ì¶”ë¡ í• ë•Œ ìœ ë¦¬í•¨. \n",
    "    outputs = model(**inputs)\n",
    "    # ëª¨ë¸ì€ ì€ë‹‰ìƒíƒœ í•˜ë‚˜ë§Œ ë°˜í™˜í•¨. \n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.size()\n",
    "# ì€ë‹‰ìƒíƒœ í…ã……ì„œ í¬ê¸° \n",
    "# [batch_size, n_tokens, hidden_dim ] -> 768 ê°œì˜ ë²¡í„°ê°€ ìƒì„±ë¨ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state[:,0].size()\n",
    "# outputs.last_hidden_state[:,0] ## ë¬¸ìì—´ ì²« ë¬¸ìì˜ ì€ë‹‰ìƒíƒœ ë¥¼ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
