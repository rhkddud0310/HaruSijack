{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://hipster4020.tistory.com/176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Service \n",
    "def blue(str):\n",
    "    from Functions import Service\n",
    "    return Service.colored_text(str,'blue')\n",
    "def yellow(str):\n",
    "    from Functions import Service\n",
    "    return Service.colored_text(str,'yellow')\n",
    "def red(str):\n",
    "    from Functions import Service\n",
    "    return Service.colored_text(str,'red')\n",
    "\n",
    "## 자연어처리 패키지 설치 \n",
    "def NLPInstalls():\n",
    "    import subprocess,sys\n",
    "    # pip가 없으면 pip를 설치\n",
    "    try:import pip\n",
    "    except ImportError:\n",
    "        print(\"Install pip for python3\")\n",
    "        subprocess.call(['sudo', 'apt-get', 'install', 'python3-pip'])\n",
    "    \n",
    "    # tweepy 없으면 tweepy 설치\n",
    "    try:import tweepy        \n",
    "    except ModuleNotFoundError:\n",
    "        print(\"Install tweepy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'tweepy==3.10.0'])\n",
    "    finally:import tweepy \n",
    "    \n",
    "    # konlpy 없으면 konlpy 설치\n",
    "    try:import konlpy\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install konlpy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'konlpy'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # eunjeon 없으면 eunjeon 설치\n",
    "    try:import eunjeon\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install eunjeon : eunjeon\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'eunjeon'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # datasets 없으면 datasets를 설치\n",
    "    try:import datasets\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install eunjeon : datasets\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'datasets'])\n",
    "    finally:import datasets\n",
    "    \n",
    "    # pytorch 없으면 pytorch 설치\n",
    "    try:import torch\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install eunjeon : pytorch\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'pytorch'])\n",
    "    finally:import torch\n",
    "    \n",
    "    # transformers 없으면 transformers 설치\n",
    "    try:import transformers\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install eunjeon : transformers\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'transformers'])\n",
    "    finally:import transformers\n",
    "NLPInstalls()\n",
    "\n",
    "\n",
    "## 감정분석 데이터 셋 준비 \n",
    "from datasets import load_dataset\n",
    "emotions = load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m🔸 model check point : \u001b[0m distilbert-base-uncased\n",
      "\u001b[93m🔸 사용하는 device : \u001b[0m cpu\n",
      "\u001b[93m🔸 사용하는 디바이스에 맞는 모델: \u001b[0m DistilBertModel(\n",
      "  (embeddings): Embeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (layer): ModuleList(\n",
      "      (0-5): 6 x TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## pytorch importing \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings ; warnings.filterwarnings('ignore')\n",
    "from transformers import AutoTokenizer\n",
    "# from transformers import DistilBertTokenizer\n",
    "\n",
    "## chkpt :  Hugging face 에 등록된 distilBert 언어 모델을 가져옴 .\n",
    "model_ckpt = 'distilbert-base-uncased' \n",
    "print(yellow(\"🔸 model check point : \"), model_ckpt)\n",
    "## 토크나이저를 통해서 토큰화 작업.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "## pretrained model  을 사용하려면 automodel importing,\n",
    "from transformers import AutoModel\n",
    "## pytorch 를 사용하여 GPU 사용 여부를 확인 \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "## 사용하는 device 에 맞는 모델을 자동으로 가져옴. \n",
    "print(yellow(\"🔸 사용하는 device : \"),device)\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)\n",
    "print(yellow(\"🔸 사용하는 디바이스에 맞는 모델: \"),model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "## frame work 호호환 예시\n",
    "def framework():\n",
    "    from transformers import TFAutoModel\n",
    "    tf_model = TFAutoModel.from_pretrained(model_ckpt)\n",
    "    ## 프레임워크간 상호 호환이 되지않음, pytorch 와 tensorflow 의 체크포인트가 다 다르다.!!\n",
    "    tf_xlmr = TFAutoModel.from_pretrained('xlm-roberta-base', from_pt =True)\n",
    "    ## 이런식으로 from_pt 를 붙이면 라이브러리가 자동으로 파이토치 가중치를 다운로드해 변환함. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 마지막 은닉 상태 추출하기 \n",
    "- 하나의 문자열에 대한 마지막 은닉 상태를 추출 함. \n",
    "- 문자열을 인코딩하고 토큰을 파이토치 텐서로 변환함. \n",
    "- tokenizer 에 return_tensor=\"pt\" 매개변수를 지정해 이작업을 수행함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m원본 text : \u001b[0m \u001b[91mthis is a test i am Forrest\u001b[0m\n",
      "\u001b[93m🔸  입력 텐서 크기 :torch.Size([1, 9]) = [bach_size, n_tokens]\u001b[0m\n",
      "\u001b[93m🔸  Ids(vector) : tensor([[  101,  2023,  2003,  1037,  3231,  1045,  2572, 16319,   102]])\u001b[0m\n",
      "\u001b[93m🔸  Attention mask : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023,  2003,  1037,  3231,  1045,  2572, 16319,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = 'this is a test i am Forrest'\n",
    "inputs = tokenizer(text,return_tensors ='pt') ## 파이토치텐서로 변환\n",
    "print(blue(f'원본 text : '),red(f'{text}'))\n",
    "print(yellow(f'🔸  입력 텐서 크기 :{inputs[\"input_ids\"].size()} = [bach_size, n_tokens]'))\n",
    "print(yellow(f'🔸  Ids(vector) : {inputs[\"input_ids\"]}'))\n",
    "print(yellow(f'🔸  Attention mask : {inputs[\"attention_mask\"]}'))\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> device 에 있는 모델에 입력을 전달\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023,  2003,  1037,  3231,  1045,  2572, 16319,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutput(last_hidden_state=tensor([[[ 0.0185,  0.0394,  0.0283,  ..., -0.0326,  0.2196,  0.3650],\n",
      "         [-0.1387, -0.3454, -0.0797,  ..., -0.1926,  0.3445,  0.2568],\n",
      "         [-0.1854, -0.1602,  0.1703,  ...,  0.1295,  0.2070,  0.7750],\n",
      "         ...,\n",
      "         [ 0.1707,  0.2024,  0.1363,  ...,  0.1139,  0.2042,  0.1838],\n",
      "         [ 0.3101, -0.1290, -0.0113,  ...,  0.4925, -0.1913,  0.0816],\n",
      "         [ 0.9054,  0.2051, -0.3114,  ...,  0.1355, -0.6349, -0.3079]]]), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "## k -> input_ids,attenition_mask v -> tensor, tensor\n",
    "inputs = {k:v.to(device) for k,v in inputs.items()} \n",
    "\n",
    "with torch.no_grad(): ## 컨텍스트 매니저 사용.  메모리양 줄어 추론할때 유리함. \n",
    "    outputs = model(**inputs)\n",
    "    # 모델은 은닉상태 하나만 반환함. \n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.size()\n",
    "# 은닉상태 텐ㅅ서 크기 \n",
    "# [batch_size, n_tokens, hidden_dim ] -> 768 개의 벡터가 생성됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state[:,0].size()\n",
    "# outputs.last_hidden_state[:,0] ## 문자열 첫 문자의 은닉상태 를 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
