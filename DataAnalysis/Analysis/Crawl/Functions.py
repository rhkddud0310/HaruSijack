"""
---
## üìå Project : ÌïòÎ£®ÏãúÏûë ÌîÑÎ°úÏ†ùÌä∏ Module functions  üìåüî∏üü¶‚úÖüÜïüâê
## üìå Description : 
    üî∏  Data Ï†ïÏ†úÎ•º ÏúÑÌïú Fuction module
    üî∏ Î∞±Ïï§Îìú ÏÑúÎπÑÏä§Î•º ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò Î∞è Î®∏Ïã†Îü¨Îãù ÏÑúÎπÑÏä§ function 
## üìå Author : Forrest Dpark (Î∂ÑÏÑù Îã¥Îãπ)
## üìå Date : 2024.05.31 ~
## üìå Detail : 
    üî∏ Î™®Îìà ÏÇ¨Ïö© Î∞©Î≤ï : 
        1. [ directory Í∞Ä Îã§Î•ºÎïå Server ÏóêÏÑú ÏÇ¨Ïö©Î≤ï ]--
            #> from Functions  import Service   # module importing 
            #> Service.dataInfoProcessing(df)  # Data information Ï†ïÎ≥¥ Ï∂úÎ†• 
            #> Service.plotSetting()           # OS ÌïúÍ∏ÄÌôî Ìïú Matplotlib 
        2.[ directory Í∞Ä Îã§Î•ºÎïå Server.py ÏóêÏÑú ÏÇ¨Ïö©Î≤ï ]--
            #> import sys,os 
            #> parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            #> sys.path.append(parent_dir)
            #> from Module.Functions import Service
        3. [ directory Í∞á Îã§Î•º Îïå Jupyter ÏóêÏÑú ÏÇ¨Ïö© Î≤ï ]
            #> import sys,os 
            #> parent_dir = os.path.dirname(os.getcwd())
            #> sys.path.append(parent_dir)
            #> from Module.Functions import Service
## üìå Update:  
    üü¶ 2024.06.02 by pdg : multiprocessing import 
        ‚úÖ Data frame column Ï†ïÎ≥¥ ( Null check, Ï§ëÎ≥µÏ≤¥ÌÅ¨ )ÌîåÎûè 
    üü¶ 2024.06.03 by pdg : datdaInfoProcessing Ìï®Ïàò ÏÉùÏÑ±
        ‚úÖ DataInfoProcessing Ìï®ÏàòÏùò printoutcolnumber ÌîåÎûèÌï† ÏπºÎüº Í∞ØÏàòÎ•º ÏÑ†ÌÉùÌï†ÏàòÏûàÍ≤å ÏÑ§Ï†ïÌï®. 
    üü¶ 2024.06.05 by pdg : Í∏∞ÌÉÄ Ìï®Ïàò ÏÉùÏÑ± 
        ‚úÖ plotSetting Ìï®Ïàò Ï∂îÍ∞Ä 
        ‚úÖ reorder_columns Ìï®Ïàò Ï∂îÍ∞Ä -> ÏπºÎüºÏùò ÏàúÏÑúÎ•º Î∞îÍæ∏Ïñ¥Ï§å.
        ‚úÖ currentPassengerCalc Ìï®Ïàò Ï∂îÍ∞Ä ÌòÑÏû¨ ÌÉëÏäπÍ∞ù Î∞è ÎüâÎãπ ÎπàÏûêÎ¶¨ Ï∂îÏ∂ú(ÎÖ∏Ïù∏ÏÑù Ï†úÏô∏)
        ‚úÖ stationDispatchBarplot Ìï®Ïàò Ï∂îÍ∞Ä -> ÏßÄÌïòÏ≤† Ïó≠Î≥Ñ Î∞∞Ï∞® ÏßÄÌïòÏ≤† ÏàòÏπò barplot check 
        ‚úÖ dayToIntConvert  Ìï®Ïàò Ï∂îÍ∞Ä
        ‚úÖ date_Divid_Add_YMW_cols Ìï®ÏàòÏ∂îÍ∞Ä 
        ‚úÖ holidaysToIntConvert Ìï®Ïàò Ï∂îÍ∞Ä 
    üü¶ 2024.06.07 by pdg : validation ÏùÑ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî Ìï®Ïàò 
        ‚úÖ station_name_to_code Ìï®Ïàò Ï∂îÍ∞Ä
        ‚úÖ sdtation_inout_lmplot Ìï®Ïàò Ï∂îÍ∞Ä
    üü¶ 2024.06.09 by pdg :  ÏßÄÌïòÏ≤† Ïó≠Î™Ö Ï≤òÎ¶¨ Î∞è ÏΩîÎìú Ï§ëÎ≥µÏ≤òÎ¶¨ Î¨∏Ï†úÎ°ú Îç∞Ïù¥ÌÑ∞ ÎàÑÎùΩÎêòÎäî Ïù¥Ïäà Ìï¥Í≤∞ 
        ‚úÖ subway_info_table Ìï®ÏàòÏ∂îÍ∞Ä 
        ‚úÖ Ìï®Ïàò ÏàúÏÑú Î∞îÍøà, Ï£ºÏÑù Ï∂îÍ∞Ä
        ‚úÖ Ìò∏ÏÑ†ÎãπÏÑúÎπÑÏä§Î∂àÍ∞ÄÏó≠Ïù¥Î¶ÑÏ∂îÏ∂ú Ìï®Ïàò Ï∂îÍ∞Ä
        
        %%% Í∞Å Ìï®ÏàòÎ≥ÑÎ°ú Ïñ¥Îñ§ Ï£ºÌîºÌÑ∞ÏóêÏÑú ÏûëÏÑ±ÎêòÏóàÎäîÏßÄ Î∂ÑÎ•òÎÇòÎàåÍ≤É
        
    üü¶ 2024.06.10 by pdg : KNN regression model Ï†ÄÏû• 
        ‚úÖ Ìï®Ïàò Ï†ÄÏû• ÌïòÎèÑÎ°ù Î∞îÍøà
    üü¶ 2024.06.12 by pdg : Ìï®Ïàò Ï†ïÎ¶¨ Î∞è Ï£ºÏÑù Ï†ïÎ¶¨ 
    üü¶ 2024.06.13 by pdg : 
        ‚úÖ color text Ìï®Ïàò Ï∂îÍ∞Ä
        ‚úÖ subwayInfo Ìï®Ïàò ÏàòÏ†ï 
    * 2024.06.14 by pdg :
        Î®∏Ïã†Îü¨Îãù ÌÜµÌï© ÌååÏùºÏóêÏÑú ÏÇ¨Ïö©ÌïòÎäî StationInfo ÌååÏùº dict Ìôî Ìï®Ïàò Ï∂îÍ∞Ä 
        - Í∞ÅÌï®ÏàòÏóêÌîÑÎ¶∞Ìä∏Î•º ÎÑ£Ïñ¥ÏÑú Î¨¥ÏóáÏùÑ Ïã§ÌñâÌïòÎäî Ìï®ÏàòÏù∏ÏßÄ print ÌïúÌõÑ Ïã§ÌñâÎê†ÏàòÏûàÎèÑÎ°ù Ìï®. 
        - mlTableGenÌï® Ïàò Ï∂îÍ∞Ä 
        - ÌÜµÌï© feature ÌÖåÏù¥Î∏î ÌòïÏÑ±ÌïòÏó¨ npy Ï†ÄÏû•Ìï®. 
    

---
"""
## project data processing functions 
# Service.Explaination(title,explain

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error, r2_score
class Service:
    
    def __init__(self) -> None:
        pass
    
#### Í∏∞Î≥∏ Setting Ìï®Ïàò
    def colored_text(text, color='default', bold=False):
        '''
        #### ÏòàÏãú ÏÇ¨Ïö©Î≤ï
        print(colored_text('Ï†ÄÏû• ÌïòÏßÄ ÏïäÏäµÎãàÎã§.', 'red'))
        print(colored_text('Ï†ÄÏû• Ìï©ÎãàÎã§.', 'green'))
        default,red,green,yellow,blue, magenta, cyan, white, rest
        '''
        colors = {
            'default': '\033[99m',
            'red': '\033[91m',
            'green': '\033[92m',
            'yellow': '\033[93m',
            'blue': '\033[94m',
            'magenta': '\033[95m', #Î≥¥ÎùºÏÉâ
            'cyan': '\033[96m',
            'white': '\033[97m',
            'bright_black': '\033[90m',  # Î∞ùÏùÄ Í≤ÄÏ†ïÏÉâ (ÌöåÏÉâ)
            'bright_red': '\033[91m',  # Î∞ùÏùÄ Îπ®Í∞ÑÏÉâ
            'bright_green': '\033[92m',  # Î∞ùÏùÄ Ï¥àÎ°ùÏÉâ
            'bright_yellow': '\033[93m',  # Î∞ùÏùÄ ÎÖ∏ÎûÄÏÉâ
            'bright_blue': '\033[94m',  # Î∞ùÏùÄ ÌååÎûÄÏÉâ
            'bright_magenta': '\033[95m',  # Î∞ùÏùÄ Î≥¥ÎùºÏÉâ
            'bright_cyan': '\033[96m',  # Î∞ùÏùÄ Ï≤≠Î°ùÏÉâ
            'bright_white': '\033[97m',  # Î∞ùÏùÄ Ìù∞ÏÉâ
            'reset': '\033[0m'
        }
        color_code = colors.get(color, colors['default'])
        bold_code = '\033[1m' if bold else ''
        reset_code = colors['reset']
        
        return f"{bold_code}{color_code}{text}{reset_code}"
    def Explaination(title,explain):
        title =str(title).upper()
        print(Service.colored_text(f"___ üü° {title}. ",'green',bold=True))
        print(Service.colored_text(f"______ üìå {explain}",'yellow'))
    def plotSetting(pltStyle="seaborn-v0_8"):
        '''
        # Fucntion Description : Plot ÌïúÍ∏ÄÌôî Setting
        # Date : 2024.06.05
        # Author : Forrest D Park 
        # update : 
        '''
        Service.Explaination("plotSetting","matplotlibn plot ÌïúÍ∏ÄÌôî Setting")
        # graph style seaborn
        import matplotlib.pyplot as plt # visiulization
        import platform
        from matplotlib import font_manager, rc # rc : Ìè∞Ìä∏ Î≥ÄÍ≤Ω Î™®Îìàfont_manager : Ìè∞Ìä∏ Í¥ÄÎ¶¨ Î™®Îìà
        plt.style.use(pltStyle)
        plt.rcParams['axes.unicode_minus'] = False# unicode ÏÑ§Ï†ï
        if platform.system() == 'Darwin': rc('font', family='AppleGothic') # osÍ∞Ä macos
        elif platform.system() == 'Windows': # osÍ∞Ä windows
            path = 'c:/Windows/Fonts/malgun.ttf' 
            font_name = font_manager.FontProperties(fname=path).get_name()
            rc('font', family=font_name)
        else:
            print("Unknown System")
        print(Service.colored_text("___## OS platform ÌïúÍ∏Ä ÏÑ∏ÌåÖÏôÑÎ£å ## ___",'magenta'))
    def indexFind(colnamelist, search_target_word):
        print(Service.colored_text("üìåÌï¥Îãπ Îã®Ïñ¥Í∞Ä Ï°¥Ïû¨ÌïòÎäî ÏπºÎüºÏùò Ïù¥Î¶ÑÏù¥ÏûàÎäî ÏπºÎüºÏùò indxÎ•º Ï∂úÎ†•Ìï©ÎãàÎã§.",'yellow'))
        # Ìï¥Îãπ Îã®Ïñ¥Í∞Ä Ï°¥Ïû¨ÌïòÎäî ÏπºÎüºÏùò Ïù¥Î¶ÑÏù¥ÏûàÎäî ÏπºÎüºÏùò indxÎ•º Ï∂úÎ†•Ìï©ÎãàÎã§. 
        import numpy as np
        indices = np.where([search_target_word in col for col in colnamelist])[0]
        return indices
####  Îç∞Ïù¥ÌÑ∞ Ï≤¥ÌÅ¨Î∞è Ï†ïÏ†ú Í¥ÄÎ†® Ìï®ÏàòÎì§ 
    def dataInfoProcessing(df, replace_Nan=False, PrintOutColnumber = 6,nanFillValue=0):
        ''' 
        üìå Fucntion Description :  Data frame Ïùò Ï†ïÏ†úÌï¥ÏïºÌï† Î∂ÄÎ∂ÑÏùÑ Ï≤¥ÌÅ¨Ìï¥Ï£ºÎäî Ìï®Ïàò 
        üìå Date : 2024.06.02 
        üìå Author : Forrest D Park 
        üìå update : 
            üü¶ 2024.06.02 by pdg: ÏùºÎ≥Ñ Îç∞Ïù¥ÌÑ∞ Ï†ïÏ†ú 
                ‚úÖ Îç∞Ïù¥ÌÑ∞Ïóê null Ïù¥ ÏûàÏùåÏùÑ Î∞úÍ≤¨, data Ï†ïÏ†ú Ìï®Ïàò update 
                ‚úÖ Ìï®ÏàòÏóêÏÑú replace_Nan ÏïÑÍ∑ú Î©òÌä∏ Î∞õÏïÑÏÑú true ÏùºÍ≤ΩÏö∞ nan ÏùÑ 0 ÏúºÎ°ú ÎåÄÏ≤¥ ÌïòÍ≤å ÎßåÎì¨. 
            üü¶ 2024.06.04 by pdg : Ìï®ÏàòÎ≥ÄÍ≤Ω
                ‚úÖ Í¥ÄÏã¨ ÏπºÎüºÏù¥ ÎßéÏùÑÎïå ÏπºÎüº Í∞úÏàòÎ•º Ï°∞Ï†ïÌï†ÏàòÏûàÍ≤å Ìï®. 
        '''
        Service.Explaination("dataInfoProcessing","Data frame Ïùò Ï†ïÏ†úÌï¥ÏïºÌï† Î∂ÄÎ∂ÑÏùÑ Ï≤¥ÌÅ¨Ìï¥Ï£ºÎäî Ìï®Ïàò ÏûÖÎãàÎã§")
        
        print(Service.colored_text(f"  1Ô∏è‚É£ Data row/colum numbers : {len(df.index)}/{len(df.columns)}",'red'))
        #print(subway.columns)
        #print(subway.info())
        null_message =f"Ï¥ù {df.isnull().sum().sum()}Í∞úÏùò null Ïù¥ ÏûàÏäµÎãàÎã§!" if df.isnull().sum().sum() else "Null ÏóÜÎäî clean data!"
        print(Service.colored_text(f"  2Ô∏è‚É£ null check Í≤∞Í≥º{null_message}",'red'))
        ### Null Ïù¥ ÏûàÎäî ÏπºÎüº Ï∂îÏ∂ú
        haveNullColumn =[]
        for idx, col in enumerate(df.columns):
            if df[f"{col}"].isnull().sum():
                print(f"   => {idx}Î≤àÏß∏.[{col}]Ïª¨Îüº : ",f"null {df[f'{col}'].isnull().sum()} Í∞ú,\t not null {df[f'{col}'].notnull().sum()} Í∞ú")
                ## Null data fill
                if replace_Nan : ## nan ÏùÑ 0 ÏúºÎ°ú ÎåÄÏ≤¥ 
                    df=df[col].fillna(value=nanFillValue, inplace=True)  
            
        
        print(Service.colored_text("  3Ô∏è‚É£ Column  Information (Ï§ëÎ≥µÏ≤¥ÌÅ¨)",'red'))
        print( "\tidx.columName |\t\t\t\t |Colum Info(dtype)|** ")
        print( "\t","--"*len("columIdx |\t\t\t\t **|Col(dtype)|** "))
        for idx, col in enumerate(df.dtypes.keys()):
            if idx< PrintOutColnumber:
                if len(f"\t{idx}.[{col}({df.dtypes[col]})]:")<20:
                    print(f"\t{idx}.[{col}({df.dtypes[col]})]:",\
                        f"{len(df[col].unique())}/{len(df[col])} [uniq/raw]", sep=" \t\t\t")
                else:
                        print(f"\t{idx}.[{col}({df.dtypes[col]})]:",\
                        f"{len(df[col].unique())}/{len(df[col])} [uniq/raw]", sep=" \t\t")

        else: 
            print(f"\t ...etc (Ï∂îÍ∞ÄÎ°ú {len(df.dtypes.keys())-PrintOutColnumber}Í∞úÏùò ÏπºÎüºÏù¥ ÏûàÏäµÎãàÎã§ )")
        return df
    def reorder_columns(df, col_name, target_idx):
        """
        üìå Description : Reorder columns in a DataFrame by moving a specific column to a target index.
        üìå Date : 2024.06.05
        üìå Author : Forrest Dpark
        # Detail:
            * df (pandas.DataFrame): The input DataFrame.
            * col_name (str): The name of the column to be moved.
            * target_idx (int): The target index where the column should be placed.
            * Returns: pandas.DataFrame: The DataFrame with the column reordered.
        """
        Service.Explaination('reorder_columns','ÏπºÎüºÏùÑ Ïù¥ÎèôÌï®')
        print(Service.colored_text(f'{col_name}ÏùÑ {target_idx}Î°ú Ïù¥ÎèôÌï®','yellow'))
        cols = list(df.columns)
        current_idx = cols.index(col_name)
        cols.pop(current_idx)
        cols.insert(target_idx, col_name)
        # print("--"*110)
        return df[cols]

#### ÏßÄÌïòÏ≤† Ïó≠ÏÇ¨ Ï†ïÎ≥¥ Ï†ïÏ†ú ÌõÑ Ï†ÄÏû•
    def  subway_info_table(subway, save=False,saveFileName=""):
        import pandas as pd, numpy as np
        """
        üìå Description :  ÏäπÌïòÏ∞® Ïù∏Ïõê Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Í∞Å Ïó≠ÏóêÎåÄÌïú Ï†ïÎ≥¥ ( Ïó≠ÏÇ¨ÏΩîÎìú Ìò∏ÏÑ† Îì±)Î•º Ï∂îÏ∂úÌïú ÌÖåÏù¥Î∏îÏùÑ Î∞òÌôò
        üìå Date : 2024.06.13
        üìå Author : Forrest Dpark
        üìå Detail:
            üî∏ Returns: 
        üìå Updates : 
            2024.06.13 by pdg : ÌîÑÎ¶∞Ìä∏Ïóê ÏÉâÍπîÏûÖÌûò. 
        """
        Service.Explaination('subway_info_table','ÏäπÌïòÏ∞® Ïù∏Ïõê Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Í∞Å Ïó≠ÏóêÎåÄÌïú Ï†ïÎ≥¥ ( Ïó≠ÏÇ¨ÏΩîÎìú Ìò∏ÏÑ† Îì±)Î•º Ï∂îÏ∂úÌïú ÌÖåÏù¥Î∏îÏùÑ Î∞òÌôò')
        # print(Service.colored_text("""\n üî∏üî∏üî∏ÏßÄÌïòÏ≤† Ïó≠Ï†ïÎ≥¥ ÌÖåÏù¥Î∏î Ìï®Ïàò Ïã§Ìñâüî∏üî∏üî∏ """,'magenta'))
        print("  |- Ï≤´ ÏàòÏÜ°ÏùºÏûê :",list(subway['ÏàòÏÜ°ÏùºÏûê'])[0])
        print("  |- ÎßàÏßÄÎßâ ÏàòÏÜ°ÏùºÏûê :",list(subway['ÏàòÏÜ°ÏùºÏûê'])[-1])
        ## Ïó≠Î™ÖÏóêÏÑú () ÎπºÎ≤ÑÎ¶¨Í∏∞ 
        Ï†ïÏ†úÎêúÏó≠Î™Ö = [i.split("(")[0] for i in subway['Ïó≠Ïù¥Î¶Ñ']]
        subway['Ïó≠Ïù¥Î¶Ñ']= Ï†ïÏ†úÎêúÏó≠Î™Ö
        # if subway.reorder_columns 
        
        subway_test = subway.rename({'Í≥†Ïú†Ïó≠Î≤àÌò∏(Ïô∏Î∂ÄÏó≠ÏΩîÎìú)':'Ïó≠ÏÇ¨ÏΩîÎìú'},axis=1)
        ### Ïó≠ÏΩîÎìú obj -> int Î°ú Î≥ÄÌôò  ** ÏïÑÎ¨¥Í≤ÉÎèÑ ÏóÜÎäî Îç∞Ïù¥ÌÑ∞Îäî 000 ÏúºÎ°ú Î≥ÄÌôò 
        new_stationCode = []
        issued_index =[]
        for i, code in enumerate(subway_test['Ïó≠ÏÇ¨ÏΩîÎìú']):
            # print(str(i).replace(" ",""))
            try : 
                new_stationCode.append(int(str(code)))
            except ValueError : 
                print(f"{i}Î≤àÏß∏ Îç∞Ïù¥ÌÑ∞ {code}" ,"<-value errer: ")
                new_stationCode.append(000)
                issued_index.append(i)
                continue
        print(f"{issued_index}Îäî Í∞íÏóêÎü¨ 0 ÏúºÎ°ú ÎåÄÏ≤¥Ìï®" if len(new_stationCode)== len(subway_test) else "ÎåÄÏ≤¥ ÏïàÎê®")
        #0,Í¥ëÎ™ÖÏÇ¨Í±∞Î¶¨,7,1 Ïù¥ ÏΩîÎìúÍ∞Ä Î¨∏Ï†úÎê®..
        subway_test['Ïó≠ÏÇ¨ÏΩîÎìú'] = new_stationCode
        
        # Ïó≠ÏÇ¨ÏΩîÎìúÏóê Ìï¥ÎãπÌïòÎäî Ïó≠Ïù¥Î¶ÑÍ≥º Ìò∏ÏÑ†ÏùÑ ÌÖåÏù¥Î∏îÎ°ú ÎßåÎì§Í≥† Ïã∂Îã§.
        # Ï§ëÎ≥µ Ï†úÍ±∞ ÌõÑ Ïó≠ Î≤àÌò∏, Ïó≠ Ïù¥Î¶Ñ, Ìò∏ÏÑ† Ï†ïÎ≥¥Î•º Ï∂îÏ∂ú
        unique_stations = subway_test.drop_duplicates(subset=['Ïó≠ÏÇ¨ÏΩîÎìú', 'Ïó≠Ïù¥Î¶Ñ', 'Ìò∏ÏÑ†'])
        #Ïó≠Î™Ö ÏΩîÎìúÍ∞Ä 0 Ïù¥Î©¥ Ìñâ drop 
        unique_stations = unique_stations[unique_stations['Ïó≠ÏÇ¨ÏΩîÎìú'] != 0]
        subway_info =unique_stations[['Ïó≠ÏÇ¨ÏΩîÎìú', 'Ïó≠Ïù¥Î¶Ñ', 'Ìò∏ÏÑ†']]
        subway_info.reset_index(inplace=True,drop=True)

        ## ÌôòÏäπÏó≠ Ïó¨Î∂Ä ÏπºÎüºÏùÑ Ï∂îÍ∞ÄÌïú StationInfo data ÎßåÎì§Ïûê .

        test1 = dict(subway_info['Ïó≠Ïù¥Î¶Ñ'].value_counts())
        to_merge_df_exchange = pd.DataFrame(
            {
            'Ïó≠Ïù¥Î¶Ñ':list(test1.keys()),
            'ÌôòÏäπÏó≠Ïàò':list(test1.values())
            }
        )
        merged_table = pd.merge(
            subway_info,to_merge_df_exchange,
            on='Ïó≠Ïù¥Î¶Ñ'
        )
        to_saveDataframe = merged_table[['Ïó≠ÏÇ¨ÏΩîÎìú','Ïó≠Ïù¥Î¶Ñ','Ìò∏ÏÑ†','ÌôòÏäπÏó≠Ïàò']]
        if save: 
        # to_saveDataframe.to_csv(f"../Data/StationInfo.csv",index=None)

            print(f'\033[92m >>{saveFileName}ÏúºÎ°ú Ï†ÄÏû•Ìï©ÎãàÎã§.\033[0m') 
            to_saveDataframe.to_csv(f"../Data/{saveFileName}.csv",index=None)
        else:
            print('\033[91m >>Ï†ÄÏû• ÌïòÏßÄ ÏïäÏäµÎãàÎã§.\033[0m')

        return to_saveDataframe

#### ÏßÄÌïòÏ≤† Î∞∞Ï∞®Ìëú Ìò∏ÏÑ†Î≥Ñ ÌÖåÏù¥Î∏î Ï†ïÏ†ú Ìï®Ïàò 
    def dispatch_table_forML(line_Î∞∞Ïπò, save=False, saveFileName=""):
        """
        #### üìå Description : ÌäπÏ†ï Ìò∏ÏÑ†ÏóêÎåÄÌïú Î∞∞ÏπòÌëú Ï†ïÎ≥¥Î•º Î∞õÏïÑÏÑú pivotable Î°úÏãúÍ∞ÑÎåÄÎ≥Ñ ÏπºÎüºÏÉùÏÑ±ÌõÑ Î∞∞Ï∞® ÏàòÎ•º Í≥ÑÏÇ∞
        #### üìå Date : 2024.06.09
        #### üìå Author : Forrest Dpark
        #### üìå Detail:
            * line_Î∞∞Ïπò (df)
            * Returns: pivotable for machine learning (df)
        """
        Service.Explaination('dispatch_table_forML','ÌäπÏ†ï Ìò∏ÏÑ†ÏóêÎåÄÌïú Î∞∞ÏπòÌëú Ï†ïÎ≥¥Î•º Î∞õÏïÑÏÑú pivotable Î°úÏãúÍ∞ÑÎåÄÎ≥Ñ ÏπºÎüºÏÉùÏÑ±ÌõÑ Î∞∞Ï∞® ÏàòÎ•º Í≥ÑÏÇ∞')
        import warnings ; warnings.filterwarnings('ignore')
        # ÏÉàÎ°úÏö¥ ÌÖåÏù¥Î∏î ÎßåÎì§Í∏∞
        line_Î∞∞Ïπò['Ïó¥Ï∞®ÏãúÍ∞ÑÍ≥ÑÏÇ∞']=line_Î∞∞Ïπò['Ïó¥Ï∞®ÎèÑÏ∞©ÏãúÍ∞Ñ'].str.split(':').str[0]
        # 'Ïó≠ÏÇ¨Î™Ö'Í≥º 'ÏãúÍ∞Ñ'Ïù¥ Í∞ôÏùÄ Îç∞Ïù¥ÌÑ∞ Í∑∏Î£πÌôî
        grouped = line_Î∞∞Ïπò.groupby(['Ïó≠ÏÇ¨ÏΩîÎìú', 'Ïó¥Ï∞®ÏãúÍ∞ÑÍ≥ÑÏÇ∞','Ï£ºÏ§ëÏ£ºÎßê','Î∞©Ìñ•'])
        # Í∞Å Í∑∏Î£πÏùò ÌÅ¨Í∏∞(Í∞úÏàò) Í≥ÑÏÇ∞
        count = grouped.size().rename('Ï∞®ÎüâÏàò')
        # Í≤∞Í≥ºÎ•º DataFrameÏúºÎ°ú Î≥ÄÌôò
        interval = count.reset_index()
        # return interval['Ïó≠ÏÇ¨ÏΩîÎìú'].unique()
        # Ïó¥ Ïù¥Î¶Ñ ÏßÄÏ†ï
        interval.columns = ['Ïó≠ÏÇ¨ÏΩîÎìú', 'ÏãúÍ∞Ñ', 'Ï£ºÏ§ëÏ£ºÎßê','Î∞©Ìñ•','Î∞∞Ï∞®Ïàò']
        interval['Ïó≠ÏÇ¨ÏΩîÎìú'] = interval['Ïó≠ÏÇ¨ÏΩîÎìú'].astype('int64')
        # Ïó≠ÏÇ¨ÏΩîÎìú(=),Ï£ºÏ§ëÏ£ºÎßê(=)ÏùÑ Í∏∞Ï§ÄÏúºÎ°ú Î∞©Ìñ•Ïù¥ Îã§Î•∏ Î∞∞Ï∞®ÏàòÎ•º Ìï©Ïπú ÌõÑ ÏÉàÎ°úÏö¥ Î°úÏö∞ ÏÉùÏÑ±ÌõÑ Î∞©Ìñ• Ïª¨Îüº ÏÇ≠Ï†úÌïú ÏÉàÎ°úÏö¥ Îç∞Ïù¥ÌÑ∞ ÏÖã ÎßåÎì§Í∏∞
        # Î∞©Ìñ• Î≥ÑÎ°ú Î∞∞Ï∞®Ïàò Ìï©ÏπòÍ∏∞
        
        interval = interval.groupby(['Ïó≠ÏÇ¨ÏΩîÎìú', 'ÏãúÍ∞Ñ', 'Ï£ºÏ§ëÏ£ºÎßê'])['Î∞∞Ï∞®Ïàò'].sum().reset_index()
        interval['Î∞∞Ï∞®Ïàò']=interval['Î∞∞Ï∞®Ïàò']/2
        
        # ÌîºÎ≤ó ÌÖåÏù¥Î∏î ÏÉùÏÑ±
        pivot_df = interval.pivot_table(index=['Ïó≠ÏÇ¨ÏΩîÎìú', 'Ï£ºÏ§ëÏ£ºÎßê'], columns='ÏãúÍ∞Ñ', values='Î∞∞Ï∞®Ïàò', aggfunc='mean')

        # # Ïù∏Îç±Ïä§Î•º Ïó¥Î°ú Î¶¨ÏÖã
        interval = pivot_df.reset_index()
        # return interval
        # # Ï≤´ Î≤àÏß∏ Ïù∏Îç±Ïä§ Ïó¥ÏùÑ Ï∂îÍ∞ÄÌïòÏó¨ ÏÉàÎ°úÏö¥ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ ÏÉùÏÑ±
        # interval['Ïó≠ÏÇ¨ÏΩîÎìú2'] = interval['Ìò∏ÏÑ†']
        # interval.drop(columns=['Ïó≠ÏÇ¨ÏΩîÎìú2'],inplace=True)
        # interval.index = interval['Ïó≠ÏÇ¨ÏΩîÎìú']
        interval.fillna(0, inplace=True)
        cols = interval.columns.tolist()
        cols.append(cols.pop(cols.index('00')))
        interval = interval[cols]

        interval.rename(columns={'00': '24'}, inplace=True)
        interval['Ìò∏ÏÑ†']=line_Î∞∞Ïπò['Ìò∏ÏÑ†'].unique()[0] 
        interval=Service.reorder_columns(col_name='Ìò∏ÏÑ†',df=interval,target_idx=1)
        print(Service.colored_text(f" üî∏{line_Î∞∞Ïπò['Ìò∏ÏÑ†'].unique() }Ìò∏ÏÑ† Ïóê ÎåÄÌïú Î∞∞Ï∞® ÌÖåÏù¥Î∏î ÌëúÏ†ïÏ†ú Í≤∞Í≥º",'green'))
        
        if save: 
            print(Service.colored_text('Î∞∞Ï∞®Ï†ïÎ≥¥Î•º Ï†ÄÏû•Ìï©ÎãàÎã§.','red'))
            interval.to_csv(f'../Data/ÏßÄÌïòÏ≤†Î∞∞Ï∞®ÏãúÍ∞ÑÎç∞Ïù¥ÌÑ∞/{saveFileName}_Ìò∏ÏÑ†Î∞∞Ï∞®.csv',index =None)
        else:
            print(Service.colored_text('Î∞∞Ï∞®Ï†ïÎ≥¥Î•º Ï†ÄÏû•ÌïòÏßÄ ÏïäÏäµÎãàÎã§','red'))
        return interval
    def table_merge_subwayInfo_dispatch(subwayInfo,line_Î∞∞Ïπò,histPlot = False):
        """
        #### üìå Description : Ïó≠ÏÇ¨Ï†ïÎ≥¥ÏôÄ Î∞∞Ï∞®ÌÖåÏù¥Î∏îÏùÑ Merge Ìï©ÎãàÎã§.
        #### üìå Date : 2024.06.09
        #### üìå Author : Forrest Dpark
        #### üìå Detail:
            * line_Î∞∞Ïπò (df)
            * save (Bool) : Ï†ÄÏû•Ìï†Í≤ÉÏù¥Î©¥ True
            * saveFileName (str) : Ï†ÄÏû•ÌååÏùº Ïù¥Î¶Ñ Ï£ºÏÜå 
            * Returns: pivotable for machine learning (df)
        """
        import pandas as pd 
        Service.Explaination('table_merge_subwayInfo_dispatch',"Ïó≠ÏÇ¨Ï†ïÎ≥¥ÏôÄ Î∞∞Ï∞®ÌÖåÏù¥Î∏îÏùÑ Merge Ìï©ÎãàÎã§.")
        print(Service.colored_text('--- Î∞∞Ï∞®ÏãúÍ∞ÑÌëú + Ïó≠ÏÇ¨Ï†ïÎ≥¥ ---','yellow'))
        print(Service.colored_text(f"{line_Î∞∞Ïπò['Ìò∏ÏÑ†'].unique() }Ìò∏ÏÑ† Î∞∞Ï∞®ÏãúÍ∞ÑÌëú Ïó≠ÏÇ¨ÏΩîÎìú Í∞úÏàò :{len(line_Î∞∞Ïπò['Ïó≠ÏÇ¨ÏΩîÎìú'].unique())}",'yellow'))
        test_merged_interval= pd.merge(subwayInfo,line_Î∞∞Ïπò, on= ['Ïó≠ÏÇ¨ÏΩîÎìú','Ìò∏ÏÑ†'])
        print(Service.colored_text(f"{line_Î∞∞Ïπò['Ìò∏ÏÑ†'].unique()}Ìò∏ÏÑ†ÌÖåÏù¥Î∏î Î≥ëÌï©ÌõÑ ÏÑúÎπÑÏä§Í∞ÄÎä•Ìïú Ï¥ù Ïó≠ Í∞úÏàò",'yellow'),len(test_merged_interval['Ïó≠ÏÇ¨ÏΩîÎìú'].unique()))
        ## Ï£ºÏ§ë Ï£ºÎßê  Ïπ¥ÌÖåÍ≥†Î¶¨Î•º 0,1 Î°ú Î∞îÍæ∏Ïñ¥Ï§å Ï£ºÎßêÏùºÍ≤ΩÏö∞ 1 Ï£ºÏ§ëÏùºÍ≤ΩÏö∞ 0  ->onehot encoding 
        test_mi = test_merged_interval.copy()
        # test_mi.rename({'Ï£ºÏ§ëÏ£ºÎßê':'Ï£ºÎßê'}, axis=1,inplace=True)
        test_mi_week_dummies = pd.get_dummies(test_mi['Ï£ºÏ§ëÏ£ºÎßê'])


        test_mi_week_dummies.head()
        test_ = pd.concat([test_mi,test_mi_week_dummies], axis=1)
        # Ï£ºÎßê ÏπºÎüº ÏÇ≠Ï†ú , day -> Ï£ºÏ§ë, sat -> Ï£ºÎßê Î°ú Î≥ÄÍ≤Ω 
        # test_.drop('Ï£ºÎßê', axis=1, inplace=True)
        # for idx, col in enumerate(list(test_.columns)):
        #     print(idx, col)
        # Ïù∏Îç±Ïä§ 2Ïùò Í∞íÏùÑ Ïù∏Îç±Ïä§ 4Î°ú Ïù¥Îèô

        test_ =Service.reorder_columns(test_,'SAT',4)
        test_ =Service.reorder_columns(test_,'DAY',5)
        ## Î∞∞Ï∞®ÏãúÍ∞Ñ ÏπºÎüº Ïù¥Î¶Ñ Î≥ÄÍ≤Ω 
        # t1=pd.concat([test_.columns[:8].to_series(),test_.columns[8:].to_series()+'ÏãúÎ∞∞Ï∞®'])
        # test_.columns =t1
        test_.rename(
            {
                'SAT':'Ï£ºÎßê',
                'DAY':'Ï£ºÏ§ë'
            }, axis=1, inplace=True
        )
        print(Service.colored_text('SAT,DAY -> Ï£ºÎßê,Ï£ºÏ§ë'))
        if histPlot:
            print("ÏòàÏãúÌûàÏä§ÌÜ†Í∑∏Îû® 1Í∞úÎßå ÌîåÎûèÌï©ÎãàÎã§(ÎÇòÎ®∏ÏßÄÎäî Ï†ÄÏû•Îê®)")
            for i in range(0,len(test_[:2]),2): ## ÏòàÏãúÎ°ú 2Í∞ú
                Service.stationDispatchBarplot(test_,i, title_columnName='Ïó≠Ïù¥Î¶Ñ',startColNum=9)
        print(Service.colored_text("ÏµúÏ¢Ö Î≥ëÌï©Îêú ÌÖåÏù¥Î∏îÏùÑ Ï∂úÎ†•Ìï©ÎãàÎã§",'yellow'))
        return test_
    def data_preprocessing_toAnalysis(data_dict,key_data):
        """
            # üìå Description : Îç∞Ïù¥ÌÑ∞ ÌÜµÌï© Ï†ïÏ†ú Ìï®Ïàò!!!
            # üìå Date : 2024.06.13
            # üìå Author : Forrest Dpark
            # üìå Detail:
                * key_data(str) : ÏòàÎ•º Îì§Î©¥ subway_23_0 Ïù¥ÎùºÎäîÎç∞Ïù¥ÌÑ∞ÏóêÏÑú 23_0 ÏùÑ ÏùòÎØ∏Ìï®!
                * data_dict : ÏäπÌïòÏ∞® Îç∞Ïù¥ÌÑ∞Î•º Ìè¨Ìï®ÌïòÍ≥† ÏûàÎäî dictionary
                * ÏÇ¨Ïö©Ïãú Ïù¥ÏÉÅÌïúÎ∂ÄÎ∂Ñ Î¨∏Ïùò => 010-7722-15920
                * Returns: colum Ïù¥Î¶ÑÎì§ÏùÑ Ï†ïÏ†úÌïòÍ≥† NanÏùÑ Ï†úÍ±∞Ìïú Ï†ïÏ†ú Îç∞Ïù¥ÌÑ∞ table
        """
        Service.Explaination('data_preprocessing_toAnalysis','Îç∞Ïù¥ÌÑ∞ ÌÜµÌï© Ï†ïÏ†ú Ìï®Ïàò!!!')
        import pandas as pd, numpy as np
        # ÌïÑÏàò Ìï≠Î™© check 
        # coloum check 
        saveFileName = "StationInfo_"+key_data.split("subway")[-1]
        test = data_dict[key_data] # ÏòàÏãú-> subway_dict_22_23['subway23_0']
        print(Service.colored_text("columns ---üëá", 'green'))
        print(test.columns.tolist())
        # Ìò∏ÏÑ†, Ïó≠ÏÇ¨Î≤àÌò∏,Ïó≠Î™Ö, ÏäπÌïòÏ∞®Íµ¨Î∂Ñ
        # Ïó∞Î≤àÏùÄ drop ÌïúÎã§. 
        if 'Ïó∞Î≤à' in test.columns.tolist():
            print(" 1. Ïó∞Î≤àÏùÑ ÏÇ≠Ï†úÌï©ÎãàÎã§. ")
            test.drop('Ïó∞Î≤à',axis=1,inplace = True)
            # print(test.columns)
        # Ïó≠Î™Ö -> Ïó≠Ïù¥Î¶Ñ
        if 'Ïó≠Î™Ö' in test.columns.tolist():
            print(' 2."Ïó≠Î™Ö" ->"Ïó≠Ïù¥Î¶Ñ", "Ïó≠Î≤àÌò∏"->"Ïó≠ÏÇ¨ÏΩîÎìú ".')
            test.rename({
                'ÎÇ†Ïßú': 'ÏàòÏÜ°ÏùºÏûê',
                'Ïó≠Î≤àÌò∏':'Ïó≠ÏÇ¨ÏΩîÎìú',
                'Ïó≠Î™Ö':'Ïó≠Ïù¥Î¶Ñ'}
                ,axis = 1
                ,inplace = True 
                )
        # Ïó≠Î≤àÌò∏ -> Ïó≠ÏÇ¨Î≤àÌò∏ 
        # Ìò∏ÏÑ† Îç∞Ïù¥ÌÑ∞Í∞Ä integer Ïù∏ÏßÄ ÌôïÏù∏ 
        if str(test['Ìò∏ÏÑ†'].dtype)=='object':
            print(' 3. Ìò∏ÏÑ† Îç∞Ïù¥ÌÑ∞Í∞Ä object ÏûÖÎãàÎã§. ')
            for idx,line in enumerate(test['Ìò∏ÏÑ†'].unique()):
                print("   -",line)
                if idx==2:
                    print(" ..")
                    break
            line_int=[int(linename.split("Ìò∏ÏÑ†")[0]) for linename in test['Ìò∏ÏÑ†']]
            print(" üòÄÌò∏ÏÑ†ÏùÑ integer Î°ú ÎßåÎì≠ÎãàÎã§.")
            print(" 3-1. Ìò∏ÏÑ† ÏùÑ Ï†úÍ±∞Ìïú Ïù¥Î¶Ñ unique : ",*np.unique(line_int),sep=", ")
            test['Ìò∏ÏÑ†'] = line_int
            print(" ‚úÖÎ≥ÄÍ≤ΩÎêú Ìò∏ÏÑ† ÏπºÎüºÏùò data type :",test['Ìò∏ÏÑ†'].dtype)
        else : 
            print('3. Ìò∏ÏÑ† Îç∞Ïù¥ÌÑ∞Í∞Ä integer ÏûÖÎãàÎã§.')
            for idx,line in enumerate(test['Ìò∏ÏÑ†'].unique()):
                print(" -",line)
                if idx==2:
                    print(" ..")
                    break
        ## null check -> ÏóÜÎã§Í≥† Í∞ÄÏ†ï 
        subway=Service.dataInfoProcessing(test,replace_Nan=True,nanFillValue=0 )
        #Ïó≠ÏΩîÎìú Í∞úÏàò Ï≤¥ÌÅ¨ -> ÏÉÅÍ¥ÄÏóÜÏùå
        stationInfo = Service.subway_info_table(
            subway,
            save=True,
            saveFileName=saveFileName
            )
        print(subway.iloc[:4,:6])
        stationInfo

        station= pd.read_csv(f'../Data/{saveFileName}.csv')
        subway_dispatch = pd.read_csv("../Data/ÏßÄÌïòÏ≤†Î∞∞Ï∞®ÏãúÍ∞ÑÎç∞Ïù¥ÌÑ∞/ÏÑúÏö∏ÍµêÌÜµÍ≥µÏÇ¨_ÏÑúÏö∏ ÎèÑÏãúÏ≤†ÎèÑ Ïó¥Ï∞®Ïö¥ÌñâÏãúÍ∞ÅÌëú_20240305.csv", encoding='euc-kr')

        for i in range(1,8):
            _ = Service.Ìò∏ÏÑ†ÎãπÏÑúÎπÑÏä§Î∂àÍ∞ÄÏó≠Ïù¥Î¶ÑÏ∂îÏ∂ú(i,station, subway_dispatch)
        print("Î∞∞Ï∞® ÏãúÍ∞Ñ Ï†úÍ≥µ Ïó≠ Í∞úÏàò: ",len(subway_dispatch['Ïó≠ÏÇ¨Î™Ö'].unique())) # Ï¥ù 394Í∞úÏùò Ïó≠ÏóêÎåÄÌïú Î∞∞Ï∞® ÏãúÍ∞ÑÎç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎã§. 
        print(" Ìò∏ÏÑ† ->",*np.sort(subway_dispatch['Ìò∏ÏÑ†'].unique())) #1, 2, 3, 4, 5, 6, 7, 8, 9  -> 9Ìò∏ÏÑ† Îç∞Ïù¥ÌÑ∞ ÍπåÏßÄ ÏûàÏùå

        ## line Î≥ÑÎ°ú ÌÖåÏù¥Î∏îÏùÑ Îî∞Î°ú ÎßåÎì†Îã§, 
        # line1_Î∞∞Ïπò= subway_dispatch[subway_dispatch['Ìò∏ÏÑ†']==1]

        line_Î∞∞Ïπò_dict = {}

        for i in range(1,9):
            line_Î∞∞Ïπò_dict[f"{i}Ìò∏ÏÑ†"] =subway_dispatch[subway_dispatch['Ìò∏ÏÑ†']==i]
            interval= Service.dispatch_table_forML(
                line_Î∞∞Ïπò_dict[f"{i}Ìò∏ÏÑ†"],
                save=True,
                saveFileName=saveFileName+f"_{i}"
                )
            print(interval.iloc[0:3,:6].head(3))
        #Ï†ïÏ†úÌõÑ Îç∞Ïù¥ÌÑ∞ Ï∂úÎ†•
        return subway

#### ÌòÑÏû¨ÌÉëÏäπÍ∞ùÏàò Ï∂îÏ†ï ÏïåÍ≥†Î¶¨Ï¶ò
    def currentPassengerCalc(stations,pass_in,pass_out,dispached_subway_number):
        """
        # üìå Description : Í∞Å Ïó≠ÏóêÏÑúÏùò Ï∂îÏ†ï ÌÉëÏäπÏù∏Ïõê Ïàò 
        # üìå Date : 2024.06.05
        # üìå Author : Forrest Dpark
        # üìå Detail:
            * stations (list): Ìïú Ìò∏ÏÑ†Ïùò Ïó≠ÏΩîÎìú or Ïó≠ Ïù¥Î¶Ñ Î∞∞Ïó¥ 
            * pass_in (list): Í∞Å Ïó≠Îãπ ÏäπÏ∞® Ïù∏ÏõêÏàò Î∞∞Ïó¥ 
            * pass_out (list): Í∞Å Ïó≠Îãπ ÌïòÏ∞® Ïù∏ÏõêÏàò Î∞∞Ïó¥
            * dispached_subway_number (int): Î∞∞Ï∞®ÎåÄÏàò
            * Returns: dataframe table
        """
        Service.Explaination('currentPassengerCalc',' Í∞Å Ïó≠ÏóêÏÑúÏùò Ï∂îÏ†ï ÌÉëÏäπÏù∏Ïõê Ïàò Í≥ÑÏÇ∞ ')
        import pandas as pd , numpy as np
        # ÏäπÌïòÏ∞® Ï†ïÎ≥¥ ÏóÜÏùÑÎïå ÎûúÎç§ ÏäπÌïòÏ∞® Ïù∏Ïõê Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± 
        if pass_in ==[] and pass_out ==[]:
            pass_in = np.zeros(shape=(len(stations)), dtype=int)
            pass_out = np.zeros(shape=(len(stations)), dtype=int)
            presentPassenger= np.zeros(shape=(len(stations)), dtype=int)
            for i,station in enumerate(stations):
                    pass_in[i]= np.random.randint(1,100) if i !=len(stations)-1 else 0
                
                    if i >0:
                        pass_out[i]= np.random.randint(1,presentPassenger[i-1])
                        presentPassenger[i] = presentPassenger[i-1] +pass_in[i]-pass_out[i]
                    else:
                        presentPassenger[i] = pass_in[i]
                    # print(station, f"Ïó≠ => ÏäπÏ∞®: {input_pasasengers_rand[i]} ,ÌïòÏ∞® :{output_pasasengers_rand[i]}")
                    # print('ÌòÑÏû¨ÌÉëÏäπÏù∏Ïõê : ',presentPassenger)
        #Ïó≠Î≥Ñ Î≥ÄÎèôÏù∏Ïõê
        
        diff_arr = np.asarray(pass_in) - np.asarray(pass_out)

        print(f"{dispached_subway_number}Í∞ú ÏßÄÌïòÏ≤†Ïù¥ Î∞∞Ï∞®ÎêòÏóàÏùÑÎïå ")
        result = pd.DataFrame(
            {
                'Ïó≠Ïù¥Î¶Ñ': stations,
                'ÏäπÏ∞®Ïù∏Ïõê': pass_in,
                'ÌïòÏ∞®Ïù∏Ïõê': pass_out,
                'Î≥ÄÎèôÏù∏Ïõê': diff_arr,
                'ÌÉëÏäπÏûêÏàò': presentPassenger,
                'Î∞∞Ï∞®ÎãπÌÉëÏäπÏûêÏàò': presentPassenger/dispached_subway_number,
                'ÎüâÎãπÎπàÏ¢åÏÑùÏàò' :42 -(presentPassenger/dispached_subway_number)/8 #42 Í∞ú 6*7 ÎÖ∏ÏïΩÏûê Ï†úÏô∏ , 7Ìò∏ÏÑ†ÏùÄ 8Îüâ
            }
        )
        return result
    def stationDispatchBarplot(df,row,title_columnName,startColNum):
        """
        ### üìå Description : Ïó≠Îì§Ïùò ÏßÄÌïòÏ≤† Î∞∞Ï∞® Ïàò(Ïã±ÌóπÍ≥º ÌïòÌñâÏù¥ Í±∞Ïùò ÎπÑÏä∑ÌïòÎã§Îäî Í∞ÄÏ†ïÌïòÏóê Ï∂îÏ†ïÏàòÏπòÏûÑ)
        ### üìå Date : 2024.06.05
        ### üìå Author : Forrest Dpark
        ### üìå Detail:
            * df pd.DataFrame:(Ïó≠ÏÇ¨ÏΩîÎìúÏôÄ Ïó≠Ïù¥Î¶Ñ, ÌèâÍ∑† Î∞∞Ï∞®Ïàò Î•º Í∞ÄÏßÄÍ≥† ÏûàÎäî Îç∞Ïù¥ÌÑ∞ ÌîÑÎ†àÏûÑ )
            * row (int): Ï£ºÏ§ë Ìñâ , row+1 ÏùÄ Ï£ºÎßê ÌñâÏûÑ. 
            * title_columnName (string) : Ïó≠Ïù¥Î¶Ñ ÏïåÏàòÏûàÎäî ÏπºÎüº. 
            * Returns: -
        """
        Service.Explaination('stationDispatchBarplot',' Ïó≠Îì§Ïùò ÏßÄÌïòÏ≤† Î∞∞Ï∞® Ïàò(Ïã±ÌóπÍ≥º ÌïòÌñâÏù¥ Í±∞Ïùò ÎπÑÏä∑ÌïòÎã§Îäî Í∞ÄÏ†ïÌïòÏóê Ï∂îÏ†ïÏàòÏπòÏûÑ)')
        import matplotlib.pyplot as plt, seaborn as sns
        # fig =plt.figure(figsize=(20,5))
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))
        bar1 = sns.barplot(
            data=df.iloc[row,startColNum:],
            color='orange',
            ax= ax1
        )
        ax1.set_title(f"{df[title_columnName].iloc[row]}Ïó≠ ÏãúÍ∞ÑÎåÄÎ≥Ñ Î∞∞Ï∞® Ïàò Î∂ÑÌè¨[{'Ï£ºÏ§ë' if df['Ï£ºÏ§ë'].iloc[row] ==True else 'Ï£ºÎßê'}]")
        ax1.set_ylabel("ÏßÄÌïòÏ≤† Î∞∞Ï∞® Ïàò")
        bar1.bar_label(bar1.containers[0])
        
        bar2 = sns.barplot(
            data=df.iloc[row+1,startColNum:],
            color='green',
            ax= ax2,
            
        )
        bar2.bar_label(bar2.containers[0])
        
        ax2.set_title(f"{df[title_columnName].iloc[row+1]}Ïó≠ ÏãúÍ∞ÑÎåÄÎ≥Ñ Î∞∞Ï∞® Ïàò Î∂ÑÌè¨[{'Ï£ºÏ§ë' if df['Ï£ºÏ§ë'].iloc[row+1] ==True else 'Ï£ºÎßê'}]")
        ax2.set_ylabel("ÏßÄÌïòÏ≤† Î∞∞Ï∞® Ïàò")
        maxlim=(max((df.iloc[row,startColNum:]).to_numpy()))
        # print(maxlim)
        ax2.set_ylim([0,maxlim])
        # bar2.set_ylim =[0,maxlim]
        plt.show()

#### ÎÇ†Ïßú Î•º Ï†ïÏ†úÌïòÎäî Ìï®Ïàò
    def dayToIntConvert(df, dateColName):
        """
        ### üìå Description : STring type Ïùò ÎÇ†Ïßú (ex 2024-11-23)Î•º ÏöîÏùºÎ°ú Î∞îÍæ∏Í≥† 0~6Ïóê Ìï¥ÎãπÌïòÎäî Ïà´ÏûêÎ°ú ÏπºÎüºÏùÑ ÏÉùÏÑ±Ìï¥ Î∞òÌôò
        ### üìå Date : 2024.06.05
        ### üìå Author : Forrest Dpark
        ### üìå Detail:
            * df pd.DataFrame: ÎÇ†ÏßúÏπºÎüºÏùÑ Ìè¨Ìï®ÌïòÎäî Îç∞Ïù¥ÌÑ∞ ÌîÑÎ†àÏûÑ 
            * dateColName : ÎÇ†ÏßúÏπºÎüº Ïù¥Î¶Ñ
            * Returns: 'ÏöîÏùº' ÏπºÎüºÏù¥ ÏÉùÏÑ±ÎêòÏñ¥ Ìè¨Ìï®Îêú Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ
        """
        Service.Explaination('dayToIntConvert','STring type Ïùò ÎÇ†Ïßú (ex 2024-11-23)Î•º ÏöîÏùºÎ°ú Î∞îÍæ∏Í≥† 0~6Ïóê Ìï¥ÎãπÌïòÎäî Ïà´ÏûêÎ°ú ÏπºÎüºÏùÑ ÏÉùÏÑ±Ìï¥ Î∞òÌôò')
        # ÏàòÏÜ°ÏùºÏûê ÎÇ†ÏßúÌòïÏúºÎ°ú Î≥ÄÌôò
        import pandas as pd
        ## ÏöîÏùº Ïª¨Îüº ÏÉùÏÑ±
        df['ÏöîÏùº'] = pd.to_datetime(df[dateColName], format='%Y-%m-%d').dt.day_name().values
        # ÏöîÏùºÏùÑ ÏòÅÏñ¥ÏóêÏÑú ÌïúÍµ≠Ïñ¥Î°ú Î≥ÄÌôò
        day_name_mapping = {
            'Sunday': 0,
            'Monday': 1,
            'Tuesday': 2,
            'Wednesday': 3,
            'Thursday': 4,
            'Friday': 5,
            'Saturday': 6
        }
        
        from datetime import datetime, timedelta
        # Service.Explaination(title,explain)
        years = []
        weeks = []
        months = []
        for data in df[dateColName] :
            date_obj = pd.to_datetime(data)
            year, week, _ = date_obj.isocalendar()
            month = date_obj.month
            years.append(year)
            weeks.append(week)
            months.append(month)
            
        import holidays
        kr_holidays = holidays.KR()
        df['Ï£ºÏ§ëÏ£ºÎßê'] = df['ÏöîÏùº'].apply(lambda x: 'SAT' if x in [0, 6] else 'DAY')
        df['ÎÖÑÎèÑ'] = years
        df['Ïõî'] = months
        df['Ï£ºÏ∞®'] = weeks
        df['ÏöîÏùº'] = df['ÏöîÏùº'].map(day_name_mapping)
        df['Í≥µÌú¥Ïùº'] = df[dateColName].apply(lambda x: 0 if x in kr_holidays else 1)

        return df
    def date_Divid_Add_YMW_cols(df,DateColName):
        """
        ### üìå Description : ÎÇ†ÏßúÏπºÎüºÏù¥ Îì§Ïñ¥Í∞Ñ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏùÑ Î∞õÏïÑÏÑú ÎÖÑÎèÑ, Ïõî, Ï£ºÏ∞® ÏπºÎüºÏùÑ ÏÉùÏÑ±ÌïúÎí§ Î∞òÌôòÌïòÎäî Ìï®Ïàò
        ### üìå Date : 2024.06.05
        ### üìå Author : Forrest Dpark
        ### üìå Detail:
            * df pd.DataFrame: ÎÇ†ÏßúÏπºÎüºÏùÑ Ìè¨Ìï®ÌïòÎäî Îç∞Ïù¥ÌÑ∞ ÌîÑÎ†àÏûÑ 
            * dateColName : ÎÇ†ÏßúÏπºÎüº Ïù¥Î¶Ñ
            * Returns: 'ÎÖÑÎèÑ,Ïõî, Ï£ºÏ∞®' ÏπºÎüºÏù¥ ÏÉùÏÑ±ÎêòÏñ¥ Ìè¨Ìï®Îêú Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ
        """
        Service.Explaination('date_Divid_Add_YMW_cols','ÎÇ†ÏßúÏπºÎüºÏù¥ Îì§Ïñ¥Í∞Ñ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏùÑ Î∞õÏïÑÏÑú ÎÖÑÎèÑ, Ïõî, Ï£ºÏ∞® ÏπºÎüºÏùÑ ÏÉùÏÑ±ÌïúÎí§ Î∞òÌôòÌïòÎäî Ìï®Ïàò')
        import pandas as pd
        from datetime import datetime, timedelta
        # Service.Explaination(title,explain)
        years = []
        weeks = []
        months = []
        for data in df[DateColName] :
            date_obj = pd.to_datetime(data)
            year, week, _ = date_obj.isocalendar()
            month = date_obj.month
            years.append(year)
            weeks.append(week)
            months.append(month)
        df['ÎÖÑÎèÑ'] = years
        df['Ïõî'] = months
        df['Ï£ºÏ∞®'] = weeks
        return df
    def date_string_to_MonthWeekHolyDayname(date_str):
        """
        ### üìå Description : Î®∏Ïã†Îü¨Îãù ÏùÑ ÏúÑÌï¥ Ïï±ÏóêÏÑú Í∞ÄÏ†∏Ïò® ÎÇ†Ïßú string ÌïòÎÇòÎ•º Ïõî,Ï£ºÏ∞®,Ìú¥Ïùº,ÏöîÏùº Îç∞Ïù¥ÌÑ∞Î°ú Î∞òÌôò
        ### üìå Date : 2024.06.10
        ### üìå Author : Forrest Dpark
        ### üìå Detail:
            * date_str: ÎÇ†Ïßú string ex) 1988-10-27
            * Returns: month_number, week_number, is_holi,dayname_code
        """
        Service.Explaination('date_string_to_MonthWeekHolyDayname','Î®∏Ïã†Îü¨Îãù ÏùÑ ÏúÑÌï¥ Ïï±ÏóêÏÑú Í∞ÄÏ†∏Ïò® ÎÇ†Ïßú string ÌïòÎÇòÎ•º Ïõî,Ï£ºÏ∞®,Ìú¥Ïùº,ÏöîÏùº Îç∞Ïù¥ÌÑ∞Î°ú Î∞òÌôò')
        from datetime import datetime,timedelta
        # ÎÇ†Ïßú Î¨∏ÏûêÏó¥ÏùÑ datetime Í∞ùÏ≤¥Î°ú Î≥ÄÌôò
        date_object = datetime.strptime(date_str, '%Y-%m-%d')
        year = date_object.year
        # Ìï¥Îãπ ÎÇ†ÏßúÏùò Ï≤´ Î≤àÏß∏ ÎÇ†Ïù¥ ÏÜçÌïú Ï£ºÏùò Ï≤´ Î≤àÏß∏ ÎÇ†ÏßúÎ•º Ï∞æÏùå
        first_day_of_year = datetime(year, 1, 1)
        first_day_of_year_weekday = first_day_of_year.weekday()  # Ìï¥Îãπ ÎÖÑÎèÑÏùò 1Ïõî 1ÏùºÏùò ÏöîÏùº
        first_week_start_date = first_day_of_year - timedelta(days=first_day_of_year_weekday)
        
        # Ìï¥Îãπ ÎÇ†ÏßúÍ∞Ä Î™á Î≤àÏß∏ Ï£ºÏù∏ÏßÄ Í≥ÑÏÇ∞
        week_number = ((date_object - first_week_start_date).days // 7) + 1
        import holidays
        kr_holidays = holidays.KR()
        is_holi =  1 if date_object in kr_holidays else 0
        day_name = date_object.strftime('%A')
        month_number = date_object.month
        day_name_mapping = {
            'Sunday': 0,
            'Monday': 1,
            'Tuesday': 2,
            'Wednesday': 3,
            'Thursday': 4,
            'Friday': 5,
            'Saturday': 6
        }
        dayname_code = day_name_mapping.get(day_name)
        return month_number, week_number, is_holi,dayname_code
    def holidaysToIntConvert(df,DateColName):
        Service.Explaination('holidaysToIntConvert','Í≥µÌú¥Ïùº ÏπºÎüº ÏÉùÏÑ± ')
        # !pip install holidays
        import holidays
        kr_holidays = holidays.KR()
        df['Í≥µÌú¥Ïùº'] = df[DateColName].apply(lambda x: 0 if x in kr_holidays else 1)
        return df

####  Î®∏Ïã†Îü¨Îãù Í¥ÄÎ†® Ìï®Ïàò 
    def MultiOutputRegressorFunc_KNN(training_table, target_table,saveFileName) :
    
        """
        # Description : train, targetÎç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú MultiOutputRegressor model
        # Date : 2024.06.05
        # Author : Shin Nara + pdg
        # Detail:
            * training_table (df): train data
            * target_table (df): target data
            * Returns: - 
        # Updata:
            2024.06.07 by pdg :Î®∏Ïã†Îü¨Îãù Ìï®Ïàò ÏóÖÎç∞Ïù¥Ìä∏ 
                * Ï£ºÏÑù Îã¨ÏïòÏùå. 
            2024.06.09 by pdg : 
                * Ìï®ÏàòÌôî ÏôÑÎ£å
        """
        import pandas as pd, numpy as np
        import matplotlib.pyplot as plt 
        from sklearn.model_selection import train_test_split
        from sklearn.multioutput import MultiOutputRegressor
        from sklearn.neighbors import KNeighborsRegressor

        train_input, test_input, train_target, test_target = \
            train_test_split(training_table,
                            target_table, 
                            test_size=0.2,
                            random_state=42)
        ## KNN regression model 
        knn_regressor = KNeighborsRegressor(n_neighbors=3)
        ## Multi Output Setting
        multi_output_regressor = MultiOutputRegressor(knn_regressor)
        multi_output_regressor.fit(train_input, train_target)
        
        score = multi_output_regressor.score(test_input, test_target)
        print(f'Model score: {score}')
        
        predictions = multi_output_regressor.predict(test_input)
        # print(test_target.columns)
        # print(predictions[:5])
        print("Ï£ºÏ∞®     ÏöîÏùº ÏãúÍ∞ÑÎåÄÎ≥Ñ ÏòàÏ∏° :",*[f"{i}Ïãú" for i in range(5,25)], sep='\t')
        for idx,ÏãúÍ∞ÑÎåÄÎ≥ÑÏòàÏ∏° in enumerate(predictions):
            Ï£ºÏ∞® = test_input.to_numpy()[idx][1]
            ÏöîÏùº =test_input.to_numpy()[idx][3]
            Ïã§Ï†úÏπò = test_target.to_numpy()[idx]
            match ÏöîÏùº:
                case ÏöîÏùº if ÏöîÏùº == 0: ÏöîÏùº_str = 'Ïùº'; 
                case ÏöîÏùº if ÏöîÏùº == 1: ÏöîÏùº_str = 'Ïõî'; 
                case ÏöîÏùº if ÏöîÏùº == 2: ÏöîÏùº_str = 'Ìôî'; 
                case ÏöîÏùº if ÏöîÏùº == 3: ÏöîÏùº_str = 'Ïàò'; 
                case ÏöîÏùº if ÏöîÏùº == 4: ÏöîÏùº_str = 'Î™©'; 
                case ÏöîÏùº if ÏöîÏùº == 5: ÏöîÏùº_str = 'Í∏à'; 
                case ÏöîÏùº if ÏöîÏùº == 6: ÏöîÏùº_str = 'ÌÜ†'; 
                case _:print()
            print(f"{Ï£ºÏ∞®}Ï£ºÏ∞® {ÏöîÏùº_str}ÏöîÏùº ÏãúÍ∞ÑÎåÄÎ≥Ñ ÏòàÏ∏° :", *list(map(int,(ÏãúÍ∞ÑÎåÄÎ≥ÑÏòàÏ∏°))), sep='\t')
            print(f"{Ï£ºÏ∞®}Ï£ºÏ∞® {ÏöîÏùº_str}ÏöîÏùº ÏãúÍ∞ÑÎåÄÎ≥Ñ Ïã§Ï†ú :", *Ïã§Ï†úÏπò, sep='\t')
            print("---"*200)
        import joblib ## model Ï†ÄÏû• Ïö© Ìï®Ïàò 
        filename = f'../Server/MLModels/{saveFileName}.h5'
        print(f"üòÄüòÄüòÄüòÄ{filename} ÏùÑ Ï†ÄÏû•Ìï©ÎãàÎã§ üòÄüòÄüòÄ")
        joblib.dump(multi_output_regressor, filename)
        
        return multi_output_regressor
    def station_name_to_code(line,station_name):
        """
            # Description : Ïó≠Ïù¥Î¶ÑÏùÑ ÏΩîÎìúÎ°ú Î∞òÌôòÌïòÎäî Ìï®Ïàò
            # Date : 2024.06.07
            # Author : pdg
            # Detail:
                * line, station_name : '7Ìò∏ÏÑ†', 'Ï§ëÍ≥°'
                * Returns: Ìï¥Îãπ ÏßÄÌïòÏ≤† Ïó≠ÏÇ¨ ÏΩîÎìú 
            # Updata:
                * 2024.06.07 by pdg : Ïó≠ÏÇ¨ÏΩîÎìú Î∞òÌôòÌï®Ïàò 
                * 2024.06.09 by pdg : Ï§ëÎ≥µ Ïó≠ÏÇ¨ÏΩîÎìúÏùºÍ≤ΩÏö∞ Î∞∞Ïó¥ Î∞òÌôò?
                    - ÎßåÏïΩÏóê Ï¢ÖÎ°ú3Í∞ÄÏ≤òÎüº ÏΩîÎìúÍ∞Ä Ïó¨Îü¨Í∞úÏù∏ Ïó≠ÏÇ¨Ïù∏Í≤ΩÏö∞ 
                * 2024.06.10 by pdg : swift Î°ú api service Ìï†Îïå ÏΩîÎìú Î∞òÌôòÏïàÎêòÎäî Î¨∏Ï†ú Ìï¥Í≤∞ 
                    -Í∏∞Ï°¥Ïùò StationInfo.csv ÏóêÏÑú Ìò∏ÏÑ† ÏπºÎüºÏù¥ Ïà´ÏûêÍ∞ÄÏïÑÎãàÎùº ~Ìò∏ÏÑ† ÏúºÎ°ú Îç∞Ïù¥ÌÑ∞Í∞Ä Î∞îÎÄåÏñ¥ Ï†ïÏ†úÎêòÏñ¥ÏûàÏùå.
                    - Í≤∞Í≥º Î∞òÏòÅÌïòÏó¨ ÏàòÏ†ïÌï®. 
                2024.06.11 by pdg :  ÎîîÎ†âÌÜ†Î¶¨ Î≥ÄÍ≤ΩÌïúÌõÑÏóê subwayInfo.csv ÌååÏùºÏùÑ Ï∞æÏùÑÏàò ÏóÜÎã§Îäî ÏóêÎü¨Í∞ÄÎú∏..
                    - ÏÉÅÎåÄÍ≤ΩÎ°úÎ•º Ïù∏ÏãùÌï† ÏàòÏûàÎèÑÎ°ù datapath ÏÑ§Ï†ï Î≥ÄÍ≤Ω 
                
        """
        import pandas as pd
        import os

        # ÌòÑÏû¨ ÌååÏùº(Functions.py)Ïùò Ï†àÎåÄ Í≤ΩÎ°úÎ•º Í∏∞Ï§ÄÏúºÎ°ú ÌîÑÎ°úÏ†ùÌä∏ Ìè¥Îçî Í≤ΩÎ°úÎ•º Ï∞æÎäîÎã§.
        module_dir = os.path.dirname(os.path.abspath(__file__))
        project_dir = os.path.dirname(module_dir)
        data_path = os.path.join(project_dir, 'Data', 'StationInfo.csv')
        
        # print("ÏïÑÌïò ÎùºÏù∏ ÌÖåÏä§Ìä∏ type : ",type(line),line)
        stations = pd.read_csv(data_path) ## Ïó≠Ï†ïÎ≥¥ csv 
        # print(stations['Ìò∏ÏÑ†'])
        target_line_stations = stations[stations['Ìò∏ÏÑ†']==line] ## line select
        #print(target_line_stations)
        row = target_line_stations[station_name == target_line_stations['Ïó≠Ïù¥Î¶Ñ']]
        # print(f"{station_name}Ïùò Ïó≠ÏÇ¨ ÏΩîÎìúÎäî {row['Ïó≠ÏÇ¨ÏΩîÎìú'].values[0]}ÏûÖÎãàÎã§")
        print("rowÏùò ÎÇ¥Ïö©: ",row.to_numpy())
        if len(row.to_numpy().tolist()) > 1:
            print('ÌôòÏäπÏó≠ÏûÖÎãàÎã§')
            print(f"{station_name}Ïùò Ïó≠ÏÇ¨ ÏΩîÎìúÎäî {row['Ïó≠ÏÇ¨ÏΩîÎìú']}ÏûÖÎãàÎã§")
            return row['Ïó≠ÏÇ¨ÏΩîÎìú'].tolist()
        if len(row.to_numpy().tolist())==0:
            print('Ï∞æÏùÑÏàò ÏóÜÎäî Ïó≠ÏûÖÎãàÎã§')
        if len(row.to_numpy().tolist())==1:
            print(f"Îã®ÏùºÏó≠ÏûÖÎãàÎã§.{row['Ïó≠ÏÇ¨ÏΩîÎìú'].tolist()}")
            return row['Ïó≠ÏÇ¨ÏΩîÎìú'].values[0]
        
        print('Ïñ¥ÎîîÏÑúÎòê Ìò∏Ï∂úÎêòÎãà?')
    def sdtation_inout_lmplot(mlTable, line, station_name, time_passenger):
        """
            # Description : train, targetÎç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú ÌöåÍ∑Ä Î™®Îç∏ 
            # Date : 2024.06.07
            # Author : pdg
            # Detail:
                * mlTable : training + target column concated table 
                line, station_name : Ìò∏ÏÑ† ,Ïù¥Î¶Ñ 
                time_passenger ('string): ÏãúÍ∞ÑÎåÄ Ïù¥Î¶Ñ target colomn Ïù¥Î¶Ñ 
                ex) 7Ìò∏ÏÑ†', 'Ï§ëÍ≥°', '08ÏãúÏù∏Ïõê'
                * Returns: - 
            # Updata:
                2024.06.07 by pdg :ÌöåÍ∑ÄÌï®Ïàò Ìï®Ïàò ÏóÖÎç∞Ïù¥Ìä∏  
        """
        
        import pandas as pd
        import matplotlib.pyplot as plt
        import seaborn as sns
        from sklearn.linear_model import LinearRegression
        from sklearn.metrics import r2_score
        # ÏΩîÎìúÏóêÏÑú Îç∞Ïù¥ÌÑ∞Î•º Î∂àÎü¨Ïò§Í≥†, ÏÑúÎπÑÏä§ÎÇò Îã§Î•∏ ÌÅ¥ÎûòÏä§Îì§ÏùÄ Ïù∏ÏãùÌïòÏßÄ Î™ªÌï¥ÏÑú Í∑∏ÎåÄÎ°ú ÎÇ®Í≤®ÎëêÏóàÏäµÎãàÎã§.
        code = Service.station_name_to_code(line, station_name)
        test = mlTable[mlTable['Ïó≠ÏÇ¨ÏΩîÎìú'] == code]
        
        # Ïà´ÏûêÎ°ú Îêú ÏöîÏùºÏùÑ ÏöîÏùº Ïù¥Î¶ÑÏúºÎ°ú Îß§Ìïë
        day_mapping = {
            0: 'ÏùºÏöîÏùº',
            1: 'ÏõîÏöîÏùº',
            2: 'ÌôîÏöîÏùº',
            3: 'ÏàòÏöîÏùº',
            4: 'Î™©ÏöîÏùº',
            5: 'Í∏àÏöîÏùº',
            6: 'ÌÜ†ÏöîÏùº',
            7: 'ÏùºÏöîÏùº'  # 0Í≥º 7Ïù¥ Î™®Îëê ÏùºÏöîÏùºÏù¥ÎùºÍ≥† Í∞ÄÏ†ï
        }

        # 'ÏöîÏùº' Ïª¨ÎüºÏùÑ ÏöîÏùº Ïù¥Î¶ÑÏúºÎ°ú Îß§Ìïë
        test['ÏöîÏùº'] = test['ÏöîÏùº'].map(day_mapping)
        
        # ÏöîÏùºÎ≥ÑÎ°ú ÏÉâÍπîÏùÑ ÏßÄÏ†ïÌïòÍ∏∞ ÏúÑÌï¥ ÌåîÎ†àÌä∏Î•º ÏÑ§Ï†ï
        unique_days = test['ÏöîÏùº'].unique()
        palette = sns.color_palette("hls", 8)

        day_to_color = dict(zip(unique_days, palette))
        # print(day_to_color)
        # DataFrameÏùÑ Ï†ÄÏû•Ìï† Î¶¨Ïä§Ìä∏ ÏÉùÏÑ±
        regression_lines = []
        
        # ÏöîÏùºÎ≥ÑÎ°ú ÌîåÎ°ØÏùÑ ÎÇòÎàÑÍ∏∞ ÏúÑÌï¥ FacetGrid ÏÇ¨Ïö©
        g = sns.FacetGrid(test, col='ÏöîÏùº', col_wrap=4, height=4, aspect=1, palette=palette)
        g.map_dataframe(sns.scatterplot, 'Ï£ºÏ∞®', time_passenger, hue='ÏöîÏùº', palette=palette)

        for ax in g.axes.flatten():
                day = ax.get_title().split('=')[-1].strip()
                day_data = test[test['ÏöîÏùº'] == day]
                sns.regplot(
                    x='Ï£ºÏ∞®',
                    y=time_passenger,
                    data=day_data,
                    scatter=False,
                    ax=ax,
                    color=palette[list(day_mapping.values()).index(day)]
                )
                day_data = test[test['ÏöîÏùº'] == day]
                # ÌöåÍ∑Ä Î™®Îç∏ ÌïôÏäµ
                X = day_data[['Ï£ºÏ∞®']]
                y = day_data[time_passenger]
                reg = LinearRegression().fit(X, y)
                
                # ÌöåÍ∑Ä Î™®Îç∏Ïùò Í≤∞Ï†ï Í≥ÑÏàò (R-squared) Í≥ÑÏÇ∞
                r2 = 1 - r2_score(y, reg.predict(X))
                
                # ÌöåÍ∑Ä Î™®Îç∏Ïùò Í≥ÑÏàòÏôÄ Ï†àÌé∏
                coef = reg.coef_[0]
                intercept = reg.intercept_
                
                # ÌöåÍ∑ÄÏãùÏùÑ Î¨∏ÏûêÏó¥Î°ú Ï†ÄÏû•
                equation = f'y = {coef:.2f}x + {intercept:.2f}'
                
                # ÌöåÍ∑Ä Î™®Îç∏Ïùò ÏàòÏãùÏùÑ DataFrameÏóê Ï∂îÍ∞Ä
                regression_lines.append({'ÏöîÏùº': day, 'Í≥ÑÏàò': coef, 'Ï†àÌé∏': intercept, 'R2 Ïä§ÏΩîÏñ¥': r2})
                # ÌöåÍ∑Ä Î™®Îç∏Ïùò ÏàòÏãù ÌîåÎ°Ø

                ax.text(0.5, 0.9, f'R2 Score: {r2:.2f}\n{equation}', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes, fontsize=10)
        
        # DataFrameÏúºÎ°ú Î≥ÄÌôò
        regression_df = pd.DataFrame(regression_lines)
        
        # Ï†úÎ™© ÏÑ§Ï†ï
        g.set_titles(col_template="{col_name}")
        g.set_axis_labels('Ï£ºÏ∞®', 'Ïù∏ÏõêÏàò(Îã®ÏúÑ : Î™Ö)')
        title = f'{line} {station_name}Ïó≠ : ÏöîÏùº Î≥Ñ {time_passenger} Ï£ºÏ∞® vs Ïù∏ÏõêÏàò'
        plt.subplots_adjust(top=0.9)
        g.fig.suptitle(title)
        
        plt.show()
        
        # DataFrame Î∞òÌôò
        return regression_df
    def regression_predict(mlTable,line, station_name, week_index, dayName_int,target_colName= '08ÏãúÏù∏Ïõê'):
        """
        # Description : train, targetÎç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú ÌöåÍ∑Ä Î™®Îç∏  ÏòàÏ∏° 
        # Date : 2024.06.07
        # Author : pdg
        # Detail:
            * mlTable : training + target column concated table 
            line, station_name : Ìò∏ÏÑ† ,Ïù¥Î¶Ñ 
            time_passenger ('string): ÏãúÍ∞ÑÎåÄ Ïù¥Î¶Ñ target colomn Ïù¥Î¶Ñ 
            ex) 7Ìò∏ÏÑ†', 'Ï§ëÍ≥°', '08ÏãúÏù∏Ïõê'
            * Returns: Ï£ºÏ∞® 10Ïóê ÏõîÏöîÏùº 8Ïãú ÎåÄÌïú ÌöåÍ∑Ä Î™®Îç∏Ïùò ÏòàÏ∏°Í∞í
        # Updata:
            2024.06.07 by pdg :ÌöåÍ∑ÄÌï®Ïàò Ìï®Ïàò ÏóÖÎç∞Ïù¥Ìä∏  
            - ÏÇ¨Ïö© ÏòàÏãú : pred_result = regression_predict(test,'7Ìò∏ÏÑ†', 'Ï§ëÍ≥°',10,1,'08ÏãúÏù∏Ïõê')
        """
        print(line, station_name, week_index)
        from Project.HaruSijack.DataAnalysis.Module.Functions import Service
        test_code= Service.station_name_to_code(line,station_name)
        print(test_code)
        
        print(f'{line} {station_name}Ïó≠ [{test_code}] {week_index}Ï£ºÏ∞® ÏöîÏùº Î≥Ñ {target_colName} ')
        test_Ï§ëÍ≥° = mlTable[mlTable['Ïó≠ÏÇ¨ÏΩîÎìú']== test_code]
        
        regression_df = Service.sdtation_inout_lmplot(mlTable, line, station_name, target_colName)
        regression_equation = regression_df.loc[regression_df.index[dayName_int]]  # ÎßàÏßÄÎßâ ÌñâÏùò ÌöåÍ∑ÄÏãù
        # ÌöåÍ∑ÄÏãùÏóêÏÑú Í≥ÑÏàòÏôÄ Ï†àÌé∏ Ï∂îÏ∂ú
        intercept = regression_equation['Ï†àÌé∏']
        slope = regression_equation['Í≥ÑÏàò']
        # Ï£ºÏñ¥ÏßÑ Ï£ºÏ∞®Ïóê ÎåÄÌïú ÏòàÏ∏°Í∞í Í≥ÑÏÇ∞
        prediction = intercept + slope * week_index
        print(f"Ï£ºÏ∞® {week_index}Ïóê ÏõîÏöîÏùº 8Ïãú ÎåÄÌïú ÌöåÍ∑Ä Î™®Îç∏Ïùò ÏòàÏ∏°Í∞í:", prediction)
        target_table = test_Ï§ëÍ≥°[test_Ï§ëÍ≥°['Ï£ºÏ∞®']==week_index][['ÏöîÏùº',target_colName]]
        print(" ----Ïã§Ï†ú Ïù∏Ïõê ------")
        print(target_table.loc[target_table.index[dayName_int]])

        return prediction

### Îç∞Ïù¥ÌÑ∞ Ïã†Î¢∞ÏÑ± ÌåêÎã® Í¥ÄÎ†® Ìï®Ïàò
    def Ìò∏ÏÑ†ÎãπÏÑúÎπÑÏä§Î∂àÍ∞ÄÏó≠Ïù¥Î¶ÑÏ∂îÏ∂ú(line,ÏäπÌïòÏ∞®_Ïó≠Ï†ïÎ≥¥ÌÖåÏù¥Î∏î, Î∞∞Ï∞®Ïó≠Ï†ïÎ≥¥_ÌÖåÏù¥Î∏î):
        """
        # üìå Description :  ÏäπÌïòÏ∞® Îç∞Ïù¥ÌÑ∞Ïóê Ï°¥Ïû¨ÌïòÏßÄÏïäÎäî ÏÑúÎπÑÏä§Î∂àÍ∞Ä Ïó≠Ïùò Î¶¨Ïä§Ìä∏Î•º Ï∂úÎ†•Ìï®. 
        # üìå Date : 2024.06.09
        # üìå Author : pdg
        # üìå Detail:
            üî∏ line (int)
            üî∏ ÏäπÌïòÏ∞®_Ïó≠Ï†ïÎ≥¥ÌÖåÏù¥Î∏î (df)
            üî∏ Î∞∞Ï∞®Ïó≠Ï†ïÎ≥¥_ÌÖåÏù¥Î∏î(df)
            üî∏ Returns: ÏÑúÎπÑÏä§Î∂àÍ∞Ä Ïó≠Ïùò Î¶¨Ïä§Ìä∏
        # üìå Update:

        """

        result =[]
        try :
            ÏäπÌïòÏ∞®_Ïó≠ÏÇ¨ÏΩîÎìú = ÏäπÌïòÏ∞®_Ïó≠Ï†ïÎ≥¥ÌÖåÏù¥Î∏î[ÏäπÌïòÏ∞®_Ïó≠Ï†ïÎ≥¥ÌÖåÏù¥Î∏î['Ìò∏ÏÑ†']==line]['Ïó≠ÏÇ¨ÏΩîÎìú']
            Î∞∞Ï∞®Ïó≠_Ïó≠ÏÇ¨ÏΩîÎìú = Î∞∞Ï∞®Ïó≠Ï†ïÎ≥¥_ÌÖåÏù¥Î∏î[Î∞∞Ï∞®Ïó≠Ï†ïÎ≥¥_ÌÖåÏù¥Î∏î['Ìò∏ÏÑ†']==line]['Ïó≠ÏÇ¨ÏΩîÎìú']
            service_disable_station =list(map(int,list(set(Î∞∞Ï∞®Ïó≠_Ïó≠ÏÇ¨ÏΩîÎìú)- set(ÏäπÌïòÏ∞®_Ïó≠ÏÇ¨ÏΩîÎìú)))) ## service Î∂àÍ∞Ä ÏßÄÏó≠ Î¶¨Ïä§Ìä∏ 
            print(service_disable_station)
            uniq_Î∞∞Ï∞®=Î∞∞Ï∞®Ïó≠Ï†ïÎ≥¥_ÌÖåÏù¥Î∏î[['Ïó≠ÏÇ¨ÏΩîÎìú','Ïó≠ÏÇ¨Î™Ö','Ìò∏ÏÑ†']].drop_duplicates().reset_index(drop=True)
            target_line_subway= uniq_Î∞∞Ï∞®[uniq_Î∞∞Ï∞®['Ìò∏ÏÑ†']==line]
            print(service_disable_station)
            if service_disable_station !=[]:
                print(Service.colored_text(f"‚¨á--{line}Ìò∏ÏÑ† ÏÑúÎπÑÏä§Î∂àÍ∞Ä Ïó≠ÏÇ¨ÏΩîÎìú . Î∞è Ïó≠ÏÇ¨Î™Ö--‚¨á", 'red'))
                i = 0
                for idx, row in enumerate(target_line_subway.to_numpy()):
                    for j in service_disable_station:
                        if  row[0] == j :
                            print(f" {i+1}.{int(row[0])} {row[1]} Ïó≠")
                            result.append([int(row[0]), row[1], row[2]])
                            i +=1
                print("-"*20)
        except:
            pass
        finally :return result
        ''' Ìï®Ïàò ÏÇ¨Ïö© ÏòàÏãú!!
        for i in range(1,8):
            _ = Service.Ìò∏ÏÑ†ÎãπÏÑúÎπÑÏä§Î∂àÍ∞ÄÏó≠Ïù¥Î¶ÑÏ∂îÏ∂ú(i,station, subway_dispatch) 
        '''

### ÌÜµÌï© Î®∏Ïã†Îü¨ÎãùÏùÑ ÏúÑÌïú feature table Ï†ïÏ†ú 
    def from_StationInfo_csv_latlang_dispatchTable_merge(parent_dir):
        """
        # üìå Description : Í∏∞Ï¥àÏ†ÅÏù∏ Ïó≠Ï†ïÎ≥¥Îç∞Ïù¥ÌÑ∞(Ïó≠Ïù¥Î¶Ñ,Ïó≠ÏΩîÎìú,Ìò∏ÏÑ†)Ïóê ÏúÑÎèÑÍ≤ΩÎèÑÎ∞∞Ï∞®ÏãúÍ∞ÑÌëúÎ•º Î®∏ÏßÄÌïòÎäî ÏûëÏóÖ
        # üìå Date : 2024.06.09
        # üìå Author : pdg
        # üìå Detail:
            * StationInfo ÌååÏùºÏóêÎåÄÌïú Î∞∞Ï∞®ÌÖåÏù¥Î∏îÏùÑ Ï†úÏûë 
            üî∏ parent : /Users/forrestdpark/Desktop/PDG/Python_/Project/HaruSijack/DataAnalysis

            üî∏ Returns: -> Save files 
                table_merge_subwayInfo_dispatch Ìï®ÏàòÎ•º Ïù¥Ïö©ÌïòÏó¨ Î®∏ÏßÄÌõÑ Ï†ÄÏû•Ìï®. 
                : 
        # üìå Update:

        """
        Service.Explaination('from_StationInfo_csv_latlang_dispatchTable_merge','Í∏∞Ï¥àÏ†ÅÏù∏ Ïó≠Ï†ïÎ≥¥Îç∞Ïù¥ÌÑ∞(Ïó≠Ïù¥Î¶Ñ,Ïó≠ÏΩîÎìú,Ìò∏ÏÑ†)Ïóê ÏúÑÎèÑÍ≤ΩÎèÑÎ∞∞Ï∞®ÏãúÍ∞ÑÌëúÎ•º Î®∏ÏßÄÌïòÎäî ÏûëÏóÖ')
        import pandas as pd, numpy as np, os
        ##Î®∏Ïã†Îü¨ÎãùÏùÑ ÏúÑÌï¥ ÌïÑÏöîÌïúÍ≤É = feature table
        ## feature table ÏùÑ ÎßåÎì§Í∏∞ ÏúÑÌï¥ ÌïÑÏöîÌïúÍ≤É -> ÏßÄÌïòÏ≤† Ïó≠Ï†ïÎ≥¥(Ïó≠ÏÇ¨ÏΩîÎìú,Ïó≠ÏÇ¨Ïù¥Î¶Ñ, Ìò∏ÏÑ†, Î∞∞Ï∞®Ï†ïÎ≥¥) 
        # Ïó≠ÏÇ¨ Ï†ïÎ≥¥ Ï†ïÏ†úÌååÏùº Fetch
        # ÎÖÑÎèÑÎ≥ÑÎ°ú Ïó≠ÏÇ¨Ï†ïÎ≥¥(StationInfo_) Í∞Ä Data Ìè¥Îçî ÎÇ¥Ïóê ÏûàÎã§. 
        # Ïù¥Ìè¥ÎçîÎ•º list dir Ìï®ÏàòÎ•º ÏÇ¨Ïö©Ìï¥ ÏùΩÏñ¥Îì§Ïó¨ÏÑú Í∞ÅÎÖÑÎèÑÎ≥Ñ Ïó≠ÏÇ¨Ï†ïÎ≥¥Î•º dicitionary Î°ú Î≥ÄÏàòÏ†ÄÏû•ÌïúÎã§. 
        StationInfo_dict = {}
        print(Service.colored_text("Parent Directory : "+parent_dir,'green'))
        for i in os.listdir(parent_dir):
            # print(i)
            file_order = 0 # file ÏàúÏÑú 
            if i =='Data': # Data Ìè¥Îçî Ïù¥Î©¥ Ïã§Ìñâ 
                print(Service.colored_text("  |-Data Ìè¥ÎçîÏóêÏÑú Ïó≠ÏÇ¨ Ï†ïÎ≥¥Î•º Í∞ÄÏßÑ StationInfo  csv ÌååÏùºÏùÑ Í≤ÄÏÉâÌï©ÎãàÎã§.",'yellow'))
                for idx, filename in enumerate(os.listdir(os.path.join(parent_dir,i))):
                    # print(" |-",j)
                    if 'StationInfo' in filename: # Station info Îßå Ï∂îÏ∂ú
                        file_order += 1
                        print(f" {file_order}. -> ",filename)
                        key_name=filename.split(".csv")[0]
                        # print(key_name)
                        StationInfo_dict[f'{key_name}'] = pd.read_csv(os.path.join(parent_dir,i,filename))
        print(Service.colored_text("  >> üìå Data folder Ïóê ÏûàÎäî ÎÖÑÎèÑÎ≥Ñ Station Info Î•º  StationInfo_dict Ïóê Ï†ÄÏû•Ìï©ÎãàÎã§.", 'blue'))
        print("[[üîπüîπüîπ StationInfo keys Í∞í Ï†ïÎ≥¥üîπüîπüîπ]]")
        for i in StationInfo_dict.keys():
            print("  |-",Service.colored_text(i,'cyan'))
        
        print(Service.colored_text("  >> üìå Í∞ÅÏó≠ÏóêÏÑúÏùò ÏúÑÎèÑÍ≤ΩÎèÑ Îç∞Ïù¥ÌÑ∞Î•º Ï†ÄÏû•ÌïòÍ≥† Î∞∞Ï∞®ÏãúÍ∞ÑÌëúÎ•º Î≥ëÌï©ÌïòÏó¨ ÏßÄÌïòÏ≤† Î∞∞Ï∞®ÏãúÍ∞ÑÎç∞Ïù¥ÌÑ∞Ìè¥ÎçîÏóê Ï†ÄÏû•Ìï©ÎãàÎã§.", 'blue'))
        for key in StationInfo_dict.keys():
            ## Ïó≠Ï†ïÎ≥¥ Îç∞Ïù¥ÌÑ∞Ïùò  Ïù¥Î¶Ñ (ex. StationInfo_18) 
            data_name = key
            print(Service.colored_text(f"‚úÖ {data_name} :Ïó≠ÏÇ¨Ï†ïÎ≥¥ \n",'yellow'),StationInfo_dict[data_name].head(3))
            latlng = pd.read_csv("../Data/seoul_subway_latlon_zenzen.csv")
            latlng.rename( {'Í≥†Ïú†Ïó≠Î≤àÌò∏(Ïô∏Î∂ÄÏó≠ÏΩîÎìú)':'Ïó≠ÏÇ¨ÏΩîÎìú'}, inplace=True, axis=1)
            latlng.drop(['Ïó≠Î™Ö','Ìò∏ÏÑ†','ÌôòÏäπÏó≠Ïàò'], axis=1,inplace=True)
            print(Service.colored_text(f"‚úÖ {data_name} : Ïó≠ÏÇ¨Î≥Ñ ÏúÑÎèÑÍ≤ΩÎèÑ : \n",'yellow'),latlng.head(3))

            ## ÏúÑÎèÑ Í≤ΩÎèÑ Îç∞Ïù¥ÌÑ∞ merge 
            StationInfo_dict[data_name] = pd.merge(StationInfo_dict[data_name],latlng, on='Ïó≠ÏÇ¨ÏΩîÎìú',how='inner' )
            print(Service.colored_text('‚úÖ Merged data check(tail)','yellow'))
            print(StationInfo_dict[data_name].tail(3))

            # Ìò∏ÏÑ†Î≥Ñ Î∞∞Ï∞®ÏãúÍ∞ÑÎç∞Ïù¥ÌÑ∞  Ï†ÄÏû• 
            savefilename_indexName = data_name.split('StationInfo')[-1]
            line_Î∞∞Ïπò_dict ={}
            for i in range(1,9):
                try:
                    line_Î∞∞Ïπò_dict[f'{i}Ìò∏ÏÑ†'] = pd.read_csv(f'../Data/ÏßÄÌïòÏ≤†Î∞∞Ï∞®ÏãúÍ∞ÑÎç∞Ïù¥ÌÑ∞/StationInfo{savefilename_indexName}_{i}_Ìò∏ÏÑ†Î∞∞Ï∞®.csv')
                    line_Î∞∞Ïπò_dict[f'{i}Ìò∏ÏÑ†'] = \
                        Service.table_merge_subwayInfo_dispatch(
                            StationInfo_dict[data_name],
                            line_Î∞∞Ïπò_dict[f'{i}Ìò∏ÏÑ†'],
                            histPlot=False
                            )
                except: 
                    print(f"{key}Îç∞Ïù¥ÌÑ∞Ïùò{i}Ìò∏ÏÑ†Ïóê Î¨∏Ï†ú Í∞ÄÏûàÏäµÎãàÎã§")
                    continue
            # line_Î∞∞Ïπò_dict['7Ìò∏ÏÑ†'].tail()
        # return StationInfo_dict ## dictionary Î∞òÌôò 
    def mlTableGen(subway_dict, save_mlTable_dict_fileName):
        """
                # üìå Description : Î®∏Ïã†Îü¨ÎãùÏùÑ ÏúÑÌïú Feature table ÏÉùÏÑ±, ÎÇ†ÏßúÎ≥Ñ ÏäπÌïòÏ∞®Ï†ïÎ≥¥ÏôÄ Î∞∞Ï∞®Ï†ïÎ≥¥, ÎÇ†ÏßúÏ†Å ÌäπÏßïÏùÑ Î≥¥Ïú†Ìïú ÌÖåÏù¥Î∏î ÏÉùÏÑ±
                # üìå Date : 2024.06.14
                # üìå Author : pdg
                # üìå Detail:
                    03-2.Î®∏Ïã†Îü¨Îãù ÌÜµÌï©.ipynb ÏóêÏÑú ÌôúÏö©ÎêòÎäî Ìï®Ïàò 
                    ÏäπÌïòÏ∞® Îç∞Ïù¥ÌÑ∞ dictionaryÏóêÏÑú ÏäπÌïòÏ∞® Ïù∏Ïõê Îç∞Ïù¥ÌÑ∞Î•º Ï∂îÏ∂úÌïòÍ≥† ÎÖÑÎèÑÎ≥Ñ Ìò∏ÏÑ†Î≥Ñ Î∞∞Ï∞®ÏãúÍ∞ÑÌëúÎç∞Ïù¥ÌÑ∞ÏôÄ Ï°∞Ìï©ÌïòÏó¨
                    Î®∏Ïã†Îü¨ÎãùÏù¥ ÎèåÏïÑÍ∞àÏàòÏûáÎäî Feature table ÏùÑ ÏÉùÏÑ±Ìï®.
                    üî∏ Returns: -> Save files 

                # üìå Update:

        """
        import pandas as pd, numpy as np, os
        Service.Explaination('ml_Table_Generator','Î®∏Ïã†Îü¨ÎãùÏùÑ ÏúÑÌïú Feature table ÏÉùÏÑ±, ÎÇ†ÏßúÎ≥Ñ ÏäπÌïòÏ∞®Ï†ïÎ≥¥ÏôÄ Î∞∞Ï∞®Ï†ïÎ≥¥, ÎÇ†ÏßúÏ†Å ÌäπÏßïÏùÑ Î≥¥Ïú†Ìïú ÌÖåÏù¥Î∏î ÏÉùÏÑ±')
        # Ï†ÑÏ≤¥ÌïôÏäµÎç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± 
        # Í∏∞Î≥∏ ÏäπÌïòÏ∞®Îç∞Ïù¥ÌÑ∞Ïùò ÏäπÌïòÏ∞® ÏπºÎüºÎì§ÏùÑ Îã§Ïãú Ï†ïÏ†ú Ìï¥ÏïºÌï®. 
        mlTable_dict = {}
        for i,key in enumerate(subway_dict.keys()):
            print(Service.colored_text(f'üîπ {i} key : {key}','cyan'))
            mlTable_dict[key]= Service.data_preprocessing_toAnalysis(subway_dict,key)

        print(Service.colored_text("########### Ï†ïÏ†úÎêú Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Feature Engineering ÏùÑ ÏãúÏûëÌï©ÎãàÎã§ #################",'yellow'))

        for i,key in enumerate(mlTable_dict.keys()):
            print(Service.colored_text(f'üîπ {i} key : {key}','cyan'))
            # print(Service.colored_text(f">> üìå{key}data Ïùò ÏàòÏÜ°ÏùºÏûê ÏπºÎüºÏóêÏÑú ÏöîÏùº(int)ÏùÑ Ï∂îÏ∂úÌïúÎí§ 4Î≤àÏß∏ ÏπºÎüºÏúºÎ°ú Ïù¥Îèô",'yellow'))
            print(Service.colored_text(f'üîπ mlTable Ïóê ÎÇ†ÏßúÎ•º Ï†ïÏ†úÌïòÏó¨ ÎÇ†ÏßúÍ¥ÄÎ†® feature Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§. ','cyan'))
            mlTable_dict[key]= Service.dayToIntConvert(mlTable_dict[key], "ÏàòÏÜ°ÏùºÏûê")
            mlTable_dict[key] = Service.reorder_columns(mlTable_dict[key],col_name="ÏöîÏùº",target_idx=4)
            ##ÎÇ†ÏßúÏóêÏÑú ÎÖÑÎèÑ,Ïõî, Ï£ºÏ∞®
            mlTable_dict[key] = Service.date_Divid_Add_YMW_cols(mlTable_dict[key] ,'ÏàòÏÜ°ÏùºÏûê')
            ## ÎÇ†ÏßúÏóêÏÑú Í≥µÌú¥Ïùº Îç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
            mlTable_dict[key]= Service.holidaysToIntConvert(mlTable_dict[key],DateColName='ÏàòÏÜ°ÏùºÏûê')
            ## ÏàòÏÜ°ÏùºÏûê , Ïó∞Î≤à ÏÇ≠Ï†ú ÏãúÍ∞ÑÍ¥ÄÎ†®Îç∞Ïù¥ÌÑ∞ ÏïûÏúºÎ°ú Ïù¥Îèô 
            for idx, col in enumerate(["ÎÖÑÎèÑ","Ïõî","Ï£ºÏ∞®","Í≥µÌú¥Ïùº"]):
                mlTable_dict[key] =Service.reorder_columns(col_name=col,df=mlTable_dict[key] ,target_idx=idx)
            mlTable_dict[key]['Ï£ºÏ§ëÏ£ºÎßê'] = ['SAT' if day in [5, 6] else 'DAY' for day in mlTable_dict[key]['ÏöîÏùº']]
            mlTable_dict[key]=Service.reorder_columns(col_name='Ï£ºÏ§ëÏ£ºÎßê',df= mlTable_dict[key],target_idx=4)

        # ÏãúÍ∞ÑÎåÄ ÏπºÎüº Ïù¥Î¶Ñ Î≥ÄÍ≤Ω ~Ïãú Ïù∏ÏõêÏúºÎ°ú 
        print(Service.colored_text("ÏãúÍ∞ÑÎåÄ ÏπºÎüº Ïù¥Î¶Ñ Î≥ÄÍ≤Ω ~Ïãú Ïù∏ÏõêÏúºÎ°ú",'yellow'))
        for key in  mlTable_dict.keys():
            colnamelist =mlTable_dict[key].columns.tolist()
            ÏãúÍ∞ÑÎåÄÏãúÏûëindex=Service.indexFind(colnamelist,'06')[0]
            # print(*colnamelist[ÏãúÍ∞ÑÎåÄÏãúÏûëindex:])
            for colname in colnamelist[ÏãúÍ∞ÑÎåÄÏãúÏûëindex:]:
                # print(f'{colname[:2]}ÏãúÏù∏Ïõê')
                if '06ÏãúÏù¥Ï†Ñ' == colname:
                    mlTable_dict[key].rename({colname:f'05ÏãúÏù∏Ïõê'}, inplace=True, axis=1)    
                else:
                    mlTable_dict[key].rename({colname:f'{colname[:2]}ÏãúÏù∏Ïõê'}, inplace=True, axis=1)
        print(Service.colored_text("########### Feature Engineering ÏôÑÎ£å #################",'yellow'))
        integrated_mltable_line_dict ={}
        # Î∞∞Ï∞®ÏãúÍ∞ÑÌëúÎäî Line Î≥ÑÎ°úÎêòÏñ¥ÏûàÍ∏∞ÎïåÎ¨∏Ïóê ÎÇòÎà†ÏÑú Î®∏Ïã†Îü¨Îãù ÎßåÎì¨... 
        for key in mlTable_dict.keys():

            data_name=key # 'subway19'
            print(Service.colored_text(f"#___ data name = {data_name}",'yellow'))
            savefilename_indexName = data_name.split('subway')[-1]
            mlTable=mlTable_dict[key]
            
            mlTable_line_dict  ={}
            for line in range(1,9):
                # print(mlTable[mlTable['Ìò∏ÏÑ†']==line])
                try: 
                    mlt= mlTable[mlTable['Ìò∏ÏÑ†']==line]
                    # print(mlt.columns)
                    line_Î∞∞Ïπò = pd.read_csv(f'../Data/ÏßÄÌïòÏ≤†Î∞∞Ï∞®ÏãúÍ∞ÑÎç∞Ïù¥ÌÑ∞/StationInfo_{savefilename_indexName}_{i}_Ìò∏ÏÑ†Î∞∞Ï∞®.csv')
                    mlTable_line_dict[f'{key}_{line}Ìò∏ÏÑ†']= pd.merge(line_Î∞∞Ïπò,mlt,on = ['Ïó≠ÏÇ¨ÏΩîÎìú','Ï£ºÏ§ëÏ£ºÎßê','Ìò∏ÏÑ†'])
                    
                except: continue
            # integrated_mltable_line_dict[f'{key}_line_dict']=mlTable_line_dict
            mlTable_dict[key]=mlTable_line_dict
        print(Service.colored_text("########### Ìò∏ÏÑ†Î≥Ñ mlTable ÏÉùÏÑ± ÏôÑÎ£å #################",'yellow'))
        # return integrated_mltable_line_dict
        # return mlTable_dict
        ## Î∞∞Ï∞® ÏãúÍ∞ÑÎåÄ ÏπºÎüº Ïù¥Î¶Ñ ~Î∞∞Ï∞®Î°ú Î∞îÍæ∏Í∏∞ 
        for key in mlTable_dict.keys():
            for line in mlTable_dict[key].keys():
                table = mlTable_dict[key][line]
                colnamelist = table.columns
                Î∞∞Ï∞®StartIndex = Service.indexFind(colnamelist=colnamelist.tolist(),search_target_word='05')[0]
                Î∞∞Ï∞®FinalIndex = Service.indexFind(colnamelist=colnamelist.tolist(),search_target_word='24')[0]
                for colname in colnamelist[Î∞∞Ï∞®StartIndex:Î∞∞Ï∞®FinalIndex+1]:
                    # print(f'{colname[:2]}ÏãúÏù∏Ïõê')
                    table.rename({colname:f'{colname[:2]}Î∞∞Ï∞®'}, inplace=True, axis=1)
                mlTable_dict[key][line]=table
                print(mlTable_dict[key][line])
        print(Service.colored_text("###########Î∞∞Ï∞® ÏãúÍ∞ÑÎåÄ ÏπºÎüº Ïù¥Î¶Ñ ~Î∞∞Ï∞®Î°ú Î∞îÍæ∏Í∏∞ ÏôÑÎ£å #################",'yellow'))
        # print("#"*20)   
        # print(mlTable_dict)
        np.save(f'../Data/mlTables/mlTable_dict_{save_mlTable_dict_fileName}.npy',mlTable_dict, allow_pickle=True)
        return mlTable_dict
    def grid_search(X_train,X_test,y_train,y_test,params, reg = DecisionTreeRegressor(random_state=2)):
        from sklearn.model_selection import GridSearchCV
        import numpy as np
        params = {'max_depth':[None,2,3,4,6,8,10,20]}
        reg = DecisionTreeRegressor(random_state=2)
        grid_reg = GridSearchCV(reg,params, scoring='neg_mean_squared_error',
                                cv=5,
                                return_train_score=True,
                                n_jobs=-1
                                )
        grid_reg.fit(X_train,y_train)
        best_params= grid_reg.best_params_
        print("ÏµúÏÉÅÏùò Îß§Í∞úÎ≥ÄÏàò: ",best_params)
        best_score = np.sqrt(-grid_reg.best_score_)
        print(f"ÌõàÎ†®Ï†êÏàò : {best_score:.3f}")
        y_pred =grid_reg.predict(X_test)
        rmse_test = mean_squared_error(y_test,y_pred)**0.5
        print(f'ÌÖåÏä§Ìä∏ Ï†êÏàò: {rmse_test:.3f}')

if __name__ == '__main__':  print("main stdart")
    



