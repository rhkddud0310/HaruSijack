{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Chapter 3 \n",
    "- 텍스트 분류\n",
    "- 텍스트 유사도\n",
    "- 텍스트 생성\n",
    "- 기계 이해 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 단어 임베딩 ( 벡터화 ) 에 4대하여 \n",
    "- one hot 의 단점 : 단어 벡터의 크기가 너무 크고 희소하다는 문제, 단어 벡터가 단어의 의미나 특성을 전혀 표현할 수없다는 문제 가 있음. \n",
    "- 분포가설( Distributed hypothesis) \n",
    "    : 비슷 환 위치에 나오는 단어는 비슷한 의미를 가진다. \n",
    "    1. 카운트 기반 방법 (Co-occurrence)\n",
    "    2. 예측 방법 (신경망 사용 )\n",
    "        - Word2vec :\n",
    "            * CBOW(Continuous Bag of Words) : 어떤 단어를 문맥 안의 주변 단어들을 통해 예측 \n",
    "            * Skip-Gram  : 어떤 단어를 가지고 특정 문맥안의 주변 단어들을 예측하는 방법\n",
    "            <img src = \"https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F914ff162-e9aa-4454-80d2-30b702551154%2F30356fcc-4e9c-40ab-b2f7-7e0d2d868152%2FUntitled.png?table=block&id=e4ab956d-01f1-42af-95e9-d0893e96468e&spaceId=914ff162-e9aa-4454-80d2-30b702551154&width=1710&userId=d72aebc7-576c-4f0e-9c69-1d5d32da7874&cache=v2\" width=\"400\" height=\"300\"/><br> \n",
    "\n",
    "            => word2Vec 의 두모델은 기존의 카운트 기반 방법으로 만든 단어 벡터보다 단어 간의 유사도를 잘 측정한다. 그리고 단어들의 복잡한 특징까지도 잘 잡는다. \n",
    "        - NNLM(Neural Network Language Model)\n",
    "        - RNNLM(Recurrent Neural Network Language Model )\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m📌 - PROGRAM START \n",
      "\t\u001b[0m\n",
      "\u001b[93m📌 - MPS 장치를 지원 Build 여부 : \u001b[0m True\n",
      "\u001b[93m📌 - MPS 장치 사용가능 여부 : \u001b[0m True\n"
     ]
    }
   ],
   "source": [
    "## Forrest Park's notion  ## Updated 2024.07.03\n",
    "### Service  Text Coloring option\n",
    "from Functions import Service as S\n",
    "def blue(str):return S.colored_text(str,'blue')\n",
    "def yellow(str):return S.colored_text(str,'yellow')\n",
    "def red(str):return S.colored_text(str,'red')\n",
    "def green(str):return S.colored_text(str,'green')\n",
    "def imd(str):return S.imd(green(str))\n",
    "## 자연어처리 패키지 설치 \n",
    "def NLPInstalls():\n",
    "    import subprocess,sys\n",
    "    import warnings ; warnings.filterwarnings('ignore')\n",
    "    # pip가 없으면 pip를 설치\n",
    "    try:import pip\n",
    "    except ImportError:\n",
    "        print(\"Install pip for python3\")\n",
    "        subprocess.call(['sudo', 'apt-get', 'install', 'python3-pip'])\n",
    "    \n",
    "    # tweepy 없으면 tweepy 설치\n",
    "    try:import tweepy        \n",
    "    except ModuleNotFoundError:\n",
    "        print(\"Install tweepy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'tweepy==3.10.0'])\n",
    "    finally:import tweepy \n",
    "    \n",
    "    # konlpy 없으면 konlpy 설치\n",
    "    try:import konlpy\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install konlpy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'konlpy'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # eunjeon 없으면 eunjeon 설치\n",
    "    try:import eunjeon\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install eunjeon : eunjeon\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'eunjeon'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # datasets 없으면 datasets를 설치\n",
    "    try:import datasets\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install datasets : datasets\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'datasets'])\n",
    "    finally:import datasets\n",
    "    \n",
    "    # pytorch 없으면 pytorch 설치\n",
    "    try:import torch\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install torch : pytorch\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'pytorch'])\n",
    "    finally:import torch\n",
    "    \n",
    "    # transformers 없으면 transformers 설치\n",
    "    try:import transformers\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install transformer : transformers\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'transformers'])\n",
    "    finally:import transformers\n",
    "        \n",
    "    # UMAP 없으면 UMAP 설치\n",
    "    try:import umap\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install umap : umap\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'umap'])\n",
    "    finally:import umap\n",
    "        \n",
    "    # UMAP 없으면 UMAP 설치\n",
    "    try:from umap import UMAP\n",
    "    except ImportError: \n",
    "        print(\"Install umap : umap-learn\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'umap-learn'])\n",
    "    finally:import umap\n",
    "   \n",
    "import torch\n",
    "# NLPInstalls()\n",
    "print(yellow(f\"📌 - PROGRAM START \\n\\t\"))\n",
    "## GPU setting (in MacOS)\n",
    "print(yellow(f\"📌 - MPS 장치를 지원 Build 여부 : \"),torch.backends.mps.is_built())\n",
    "print(yellow(f\"📌 - MPS 장치 사용가능 여부 : \"),torch.backends.mps.is_available())\n",
    "# device = torch.device(\"mps\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#### Jupyter Basic Setting ####\n",
    "import pandas as pd,numpy as np\n",
    "import matplotlib.pyplot as plt,seaborn as sns  # 시각화\n",
    "import warnings; warnings.filterwarnings('ignore')  # 경고 무시\n",
    "import sys,os \n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            <img src = \"\u001b[92mhttps://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F914ff162-e9aa-4454-80d2-30b702551154%2F30356fcc-4e9c-40ab-b2f7-7e0d2d868152%2FUntitled.png?table=block&id=e4ab956d-01f1-42af-95e9-d0893e96468e&spaceId=914ff162-e9aa-4454-80d2-30b702551154&width=1710&userId=d72aebc7-576c-4f0e-9c69-1d5d32da7874&cache=v2\u001b[0m\" width=\"400\" height=\"300\"/><br>\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "from Functions import NLP_Service as N\n",
    "N.imd(\"https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F914ff162-e9aa-4454-80d2-30b702551154%2F30356fcc-4e9c-40ab-b2f7-7e0d2d868152%2FUntitled.png?table=block&id=e4ab956d-01f1-42af-95e9-d0893e96468e&spaceId=914ff162-e9aa-4454-80d2-30b702551154&width=1710&userId=d72aebc7-576c-4f0e-9c69-1d5d32da7874&cache=v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\\\\ 2024.07.08 \\\\\n",
    "### 02. 텍스트 분류\n",
    "- 이진분류, 다중 범주 분류로 나눔. \n",
    "- 스팸분류 \n",
    "- 감정분류 \n",
    "- 키워드 분류\n",
    "\n",
    "### 지도학습 유형\n",
    "- 나이브베이즈 분류\n",
    "- 서포트 벡터 머신\n",
    "- 신경망\n",
    "- 선형 분류 \n",
    "- 로지스틱 분류\n",
    "- 랜덤 포레스트 \n",
    "\n",
    "### 03. 텍스트 유사도 \n",
    "- 자카드 유사도\n",
    "- 유클리디언 유사도\n",
    "- 맨해튼 유사도\n",
    "- 코사인 유사도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'갑작스런': 1.4054651081081644,\n",
      " '내일은': 1.4054651081081644,\n",
      " '놀러왔다가': 1.4054651081081644,\n",
      " '망연자실': 1.4054651081081644,\n",
      " '반가운': 1.4054651081081644,\n",
      " '서쪽을': 1.4054651081081644,\n",
      " '소식': 1.4054651081081644,\n",
      " '오늘도': 1.4054651081081644,\n",
      " '이어졋는데요': 1.4054651081081644,\n",
      " '인해': 1.4054651081081644,\n",
      " '있습니다': 1.0,\n",
      " '중심으로': 1.4054651081081644,\n",
      " '폭염을': 1.4054651081081644,\n",
      " '폭염이': 1.4054651081081644,\n",
      " '피해서': 1.4054651081081644,\n",
      " '하고': 1.4054651081081644,\n",
      " '휴일에': 1.4054651081081644,\n",
      " '휴일인': 1.4054651081081644}\n"
     ]
    }
   ],
   "source": [
    "## 유사도 측정 \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "sent = (\"휴일인 오늘도 서쪽을 중심으로 폭염이 이어졋는데요, 내일은 반가운 비 소식 이 있습니다.\",\n",
    "        \"폭염을 피해서 휴일에 놀러왔다가 갑작스런 비 로  인해 망연자실 하고 있습니다.\")\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sent)# 문장 벡터화 진행\n",
    "idf = tfidf_vectorizer.idf_\n",
    "from pprint import pprint \n",
    "pprint(dict(zip(tfidf_vectorizer.get_feature_names_out(),idf))) # 각 수치에 대한 값 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 자카드 유사도 (Jaccard Similarity)\n",
    "- 두집합의 교집합인 공통된 단어의 개수를 두 집합의 합집합(전체단어수) 으로 나눈다. \n",
    "\n",
    "### 코사인 유사도 \n",
    "- 두개의 벡터 값에서 코사인 각도를 구하는 방법. (-1~1), 방향성의 개념이 더해짐. '\n",
    "- 유사하지 않을수록 직교로 표현됨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m📌 - cosine 유사도 : [[0.05629716]]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(yellow(\"📌 - cosine 유사도 : {}\".format(cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 유클리디언 유사도 \n",
    "- 벡턱단의 거리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m📌 - 유클리디언 유사도 : [[1.37382884]]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "ed= euclidean_distances(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "print(yellow(\"📌 - 유클리디언 유사도 : {}\".format(ed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m📌 - L1 정규화 후 유클리디언 [[0.22387021]]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def l1_normalize(v):\n",
    "    norm = np.sum(v)\n",
    "    return v/norm\n",
    "\n",
    "tfidf_norm_l1= l1_normalize(tfidf_matrix)\n",
    "l1_ed =euclidean_distances(tfidf_norm_l1[0:1],tfidf_norm_l1[1:2])\n",
    "print(yellow(\"📌 - L1 정규화 후 유클리디언 {}\").format(l1_ed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 맨해튼 유사도 (Manhattan Similarity)\n",
    "- 거리를 계산할때 일직선이아니라 블록되어있는 맨해튼 거리처럼 되어있다고 가정하고 거리를 구하는 방식 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
