{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Chapter 3 \n",
    "- í…ìŠ¤íŠ¸ ë¶„ë¥˜\n",
    "- í…ìŠ¤íŠ¸ ìœ ì‚¬ë„\n",
    "- í…ìŠ¤íŠ¸ ìƒì„±\n",
    "- ê¸°ê³„ ì´í•´ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### ë‹¨ì–´ ì„ë² ë”© ( ë²¡í„°í™” ) ì— 4ëŒ€í•˜ì—¬ \n",
    "- one hot ì˜ ë‹¨ì  : ë‹¨ì–´ ë²¡í„°ì˜ í¬ê¸°ê°€ ë„ˆë¬´ í¬ê³  í¬ì†Œí•˜ë‹¤ëŠ” ë¬¸ì œ, ë‹¨ì–´ ë²¡í„°ê°€ ë‹¨ì–´ì˜ ì˜ë¯¸ë‚˜ íŠ¹ì„±ì„ ì „í˜€ í‘œí˜„í•  ìˆ˜ì—†ë‹¤ëŠ” ë¬¸ì œ ê°€ ìˆìŒ. \n",
    "- ë¶„í¬ê°€ì„¤( Distributed hypothesis) \n",
    "    : ë¹„ìŠ· í™˜ ìœ„ì¹˜ì— ë‚˜ì˜¤ëŠ” ë‹¨ì–´ëŠ” ë¹„ìŠ·í•œ ì˜ë¯¸ë¥¼ ê°€ì§„ë‹¤. \n",
    "    1. ì¹´ìš´íŠ¸ ê¸°ë°˜ ë°©ë²• (Co-occurrence)\n",
    "    2. ì˜ˆì¸¡ ë°©ë²• (ì‹ ê²½ë§ ì‚¬ìš© )\n",
    "        - Word2vec :\n",
    "            * CBOW(Continuous Bag of Words) : ì–´ë–¤ ë‹¨ì–´ë¥¼ ë¬¸ë§¥ ì•ˆì˜ ì£¼ë³€ ë‹¨ì–´ë“¤ì„ í†µí•´ ì˜ˆì¸¡ \n",
    "            * Skip-Gram  : ì–´ë–¤ ë‹¨ì–´ë¥¼ ê°€ì§€ê³  íŠ¹ì • ë¬¸ë§¥ì•ˆì˜ ì£¼ë³€ ë‹¨ì–´ë“¤ì„ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•\n",
    "            <img src = \"https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F914ff162-e9aa-4454-80d2-30b702551154%2F30356fcc-4e9c-40ab-b2f7-7e0d2d868152%2FUntitled.png?table=block&id=e4ab956d-01f1-42af-95e9-d0893e96468e&spaceId=914ff162-e9aa-4454-80d2-30b702551154&width=1710&userId=d72aebc7-576c-4f0e-9c69-1d5d32da7874&cache=v2\" width=\"400\" height=\"300\"/><br> \n",
    "\n",
    "            => word2Vec ì˜ ë‘ëª¨ë¸ì€ ê¸°ì¡´ì˜ ì¹´ìš´íŠ¸ ê¸°ë°˜ ë°©ë²•ìœ¼ë¡œ ë§Œë“  ë‹¨ì–´ ë²¡í„°ë³´ë‹¤ ë‹¨ì–´ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ì˜ ì¸¡ì •í•œë‹¤. ê·¸ë¦¬ê³  ë‹¨ì–´ë“¤ì˜ ë³µì¡í•œ íŠ¹ì§•ê¹Œì§€ë„ ì˜ ì¡ëŠ”ë‹¤. \n",
    "        - NNLM(Neural Network Language Model)\n",
    "        - RNNLM(Recurrent Neural Network Language Model )\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mğŸ“Œ - PROGRAM START \n",
      "\t\u001b[0m\n",
      "\u001b[93mğŸ“Œ - MPS ì¥ì¹˜ë¥¼ ì§€ì› Build ì—¬ë¶€ : \u001b[0m True\n",
      "\u001b[93mğŸ“Œ - MPS ì¥ì¹˜ ì‚¬ìš©ê°€ëŠ¥ ì—¬ë¶€ : \u001b[0m True\n"
     ]
    }
   ],
   "source": [
    "## Forrest Park's notion  ## Updated 2024.07.03\n",
    "### Service  Text Coloring option\n",
    "from Functions import Service as S\n",
    "def blue(str):return S.colored_text(str,'blue')\n",
    "def yellow(str):return S.colored_text(str,'yellow')\n",
    "def red(str):return S.colored_text(str,'red')\n",
    "def green(str):return S.colored_text(str,'green')\n",
    "def imd(str):return S.imd(green(str))\n",
    "## ìì—°ì–´ì²˜ë¦¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜ \n",
    "def NLPInstalls():\n",
    "    import subprocess,sys\n",
    "    import warnings ; warnings.filterwarnings('ignore')\n",
    "    # pipê°€ ì—†ìœ¼ë©´ pipë¥¼ ì„¤ì¹˜\n",
    "    try:import pip\n",
    "    except ImportError:\n",
    "        print(\"Install pip for python3\")\n",
    "        subprocess.call(['sudo', 'apt-get', 'install', 'python3-pip'])\n",
    "    \n",
    "    # tweepy ì—†ìœ¼ë©´ tweepy ì„¤ì¹˜\n",
    "    try:import tweepy        \n",
    "    except ModuleNotFoundError:\n",
    "        print(\"Install tweepy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'tweepy==3.10.0'])\n",
    "    finally:import tweepy \n",
    "    \n",
    "    # konlpy ì—†ìœ¼ë©´ konlpy ì„¤ì¹˜\n",
    "    try:import konlpy\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install konlpy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'konlpy'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # eunjeon ì—†ìœ¼ë©´ eunjeon ì„¤ì¹˜\n",
    "    try:import eunjeon\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install eunjeon : eunjeon\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'eunjeon'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # datasets ì—†ìœ¼ë©´ datasetsë¥¼ ì„¤ì¹˜\n",
    "    try:import datasets\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install datasets : datasets\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'datasets'])\n",
    "    finally:import datasets\n",
    "    \n",
    "    # pytorch ì—†ìœ¼ë©´ pytorch ì„¤ì¹˜\n",
    "    try:import torch\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install torch : pytorch\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'pytorch'])\n",
    "    finally:import torch\n",
    "    \n",
    "    # transformers ì—†ìœ¼ë©´ transformers ì„¤ì¹˜\n",
    "    try:import transformers\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install transformer : transformers\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'transformers'])\n",
    "    finally:import transformers\n",
    "        \n",
    "    # UMAP ì—†ìœ¼ë©´ UMAP ì„¤ì¹˜\n",
    "    try:import umap\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install umap : umap\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'umap'])\n",
    "    finally:import umap\n",
    "        \n",
    "    # UMAP ì—†ìœ¼ë©´ UMAP ì„¤ì¹˜\n",
    "    try:from umap import UMAP\n",
    "    except ImportError: \n",
    "        print(\"Install umap : umap-learn\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'umap-learn'])\n",
    "    finally:import umap\n",
    "   \n",
    "import torch\n",
    "# NLPInstalls()\n",
    "print(yellow(f\"ğŸ“Œ - PROGRAM START \\n\\t\"))\n",
    "## GPU setting (in MacOS)\n",
    "print(yellow(f\"ğŸ“Œ - MPS ì¥ì¹˜ë¥¼ ì§€ì› Build ì—¬ë¶€ : \"),torch.backends.mps.is_built())\n",
    "print(yellow(f\"ğŸ“Œ - MPS ì¥ì¹˜ ì‚¬ìš©ê°€ëŠ¥ ì—¬ë¶€ : \"),torch.backends.mps.is_available())\n",
    "# device = torch.device(\"mps\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#### Jupyter Basic Setting ####\n",
    "import pandas as pd,numpy as np\n",
    "import matplotlib.pyplot as plt,seaborn as sns  # ì‹œê°í™”\n",
    "import warnings; warnings.filterwarnings('ignore')  # ê²½ê³  ë¬´ì‹œ\n",
    "import sys,os \n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            <img src = \"\u001b[92mhttps://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F914ff162-e9aa-4454-80d2-30b702551154%2F30356fcc-4e9c-40ab-b2f7-7e0d2d868152%2FUntitled.png?table=block&id=e4ab956d-01f1-42af-95e9-d0893e96468e&spaceId=914ff162-e9aa-4454-80d2-30b702551154&width=1710&userId=d72aebc7-576c-4f0e-9c69-1d5d32da7874&cache=v2\u001b[0m\" width=\"400\" height=\"300\"/><br>\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "from Functions import NLP_Service as N\n",
    "N.imd(\"https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F914ff162-e9aa-4454-80d2-30b702551154%2F30356fcc-4e9c-40ab-b2f7-7e0d2d868152%2FUntitled.png?table=block&id=e4ab956d-01f1-42af-95e9-d0893e96468e&spaceId=914ff162-e9aa-4454-80d2-30b702551154&width=1710&userId=d72aebc7-576c-4f0e-9c69-1d5d32da7874&cache=v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\\\\ 2024.07.08 \\\\\n",
    "### 02. í…ìŠ¤íŠ¸ ë¶„ë¥˜\n",
    "- ì´ì§„ë¶„ë¥˜, ë‹¤ì¤‘ ë²”ì£¼ ë¶„ë¥˜ë¡œ ë‚˜ëˆ”. \n",
    "- ìŠ¤íŒ¸ë¶„ë¥˜ \n",
    "- ê°ì •ë¶„ë¥˜ \n",
    "- í‚¤ì›Œë“œ ë¶„ë¥˜\n",
    "\n",
    "### ì§€ë„í•™ìŠµ ìœ í˜•\n",
    "- ë‚˜ì´ë¸Œë² ì´ì¦ˆ ë¶„ë¥˜\n",
    "- ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ \n",
    "- ì‹ ê²½ë§\n",
    "- ì„ í˜• ë¶„ë¥˜ \n",
    "- ë¡œì§€ìŠ¤í‹± ë¶„ë¥˜\n",
    "- ëœë¤ í¬ë ˆìŠ¤íŠ¸ \n",
    "\n",
    "### 03. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ \n",
    "- ìì¹´ë“œ ìœ ì‚¬ë„\n",
    "- ìœ í´ë¦¬ë””ì–¸ ìœ ì‚¬ë„\n",
    "- ë§¨í•´íŠ¼ ìœ ì‚¬ë„\n",
    "- ì½”ì‚¬ì¸ ìœ ì‚¬ë„ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ê°‘ì‘ìŠ¤ëŸ°': 1.4054651081081644,\n",
      " 'ë‚´ì¼ì€': 1.4054651081081644,\n",
      " 'ë†€ëŸ¬ì™”ë‹¤ê°€': 1.4054651081081644,\n",
      " 'ë§ì—°ìì‹¤': 1.4054651081081644,\n",
      " 'ë°˜ê°€ìš´': 1.4054651081081644,\n",
      " 'ì„œìª½ì„': 1.4054651081081644,\n",
      " 'ì†Œì‹': 1.4054651081081644,\n",
      " 'ì˜¤ëŠ˜ë„': 1.4054651081081644,\n",
      " 'ì´ì–´ì¡‹ëŠ”ë°ìš”': 1.4054651081081644,\n",
      " 'ì¸í•´': 1.4054651081081644,\n",
      " 'ìˆìŠµë‹ˆë‹¤': 1.0,\n",
      " 'ì¤‘ì‹¬ìœ¼ë¡œ': 1.4054651081081644,\n",
      " 'í­ì—¼ì„': 1.4054651081081644,\n",
      " 'í­ì—¼ì´': 1.4054651081081644,\n",
      " 'í”¼í•´ì„œ': 1.4054651081081644,\n",
      " 'í•˜ê³ ': 1.4054651081081644,\n",
      " 'íœ´ì¼ì—': 1.4054651081081644,\n",
      " 'íœ´ì¼ì¸': 1.4054651081081644}\n"
     ]
    }
   ],
   "source": [
    "## ìœ ì‚¬ë„ ì¸¡ì • \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "sent = (\"íœ´ì¼ì¸ ì˜¤ëŠ˜ë„ ì„œìª½ì„ ì¤‘ì‹¬ìœ¼ë¡œ í­ì—¼ì´ ì´ì–´ì¡‹ëŠ”ë°ìš”, ë‚´ì¼ì€ ë°˜ê°€ìš´ ë¹„ ì†Œì‹ ì´ ìˆìŠµë‹ˆë‹¤.\",\n",
    "        \"í­ì—¼ì„ í”¼í•´ì„œ íœ´ì¼ì— ë†€ëŸ¬ì™”ë‹¤ê°€ ê°‘ì‘ìŠ¤ëŸ° ë¹„ ë¡œ  ì¸í•´ ë§ì—°ìì‹¤ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\")\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sent)# ë¬¸ì¥ ë²¡í„°í™” ì§„í–‰\n",
    "idf = tfidf_vectorizer.idf_\n",
    "from pprint import pprint \n",
    "pprint(dict(zip(tfidf_vectorizer.get_feature_names_out(),idf))) # ê° ìˆ˜ì¹˜ì— ëŒ€í•œ ê°’ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### ìì¹´ë“œ ìœ ì‚¬ë„ (Jaccard Similarity)\n",
    "- ë‘ì§‘í•©ì˜ êµì§‘í•©ì¸ ê³µí†µëœ ë‹¨ì–´ì˜ ê°œìˆ˜ë¥¼ ë‘ ì§‘í•©ì˜ í•©ì§‘í•©(ì „ì²´ë‹¨ì–´ìˆ˜) ìœ¼ë¡œ ë‚˜ëˆˆë‹¤. \n",
    "\n",
    "### ì½”ì‚¬ì¸ ìœ ì‚¬ë„ \n",
    "- ë‘ê°œì˜ ë²¡í„° ê°’ì—ì„œ ì½”ì‚¬ì¸ ê°ë„ë¥¼ êµ¬í•˜ëŠ” ë°©ë²•. (-1~1), ë°©í–¥ì„±ì˜ ê°œë…ì´ ë”í•´ì§. '\n",
    "- ìœ ì‚¬í•˜ì§€ ì•Šì„ìˆ˜ë¡ ì§êµë¡œ í‘œí˜„ë¨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mğŸ“Œ - cosine ìœ ì‚¬ë„ : [[0.05629716]]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(yellow(\"ğŸ“Œ - cosine ìœ ì‚¬ë„ : {}\".format(cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ìœ í´ë¦¬ë””ì–¸ ìœ ì‚¬ë„ \n",
    "- ë²¡í„±ë‹¨ì˜ ê±°ë¦¬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mğŸ“Œ - ìœ í´ë¦¬ë””ì–¸ ìœ ì‚¬ë„ : [[1.37382884]]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "ed= euclidean_distances(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "print(yellow(\"ğŸ“Œ - ìœ í´ë¦¬ë””ì–¸ ìœ ì‚¬ë„ : {}\".format(ed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mğŸ“Œ - L1 ì •ê·œí™” í›„ ìœ í´ë¦¬ë””ì–¸ [[0.22387021]]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def l1_normalize(v):\n",
    "    norm = np.sum(v)\n",
    "    return v/norm\n",
    "\n",
    "tfidf_norm_l1= l1_normalize(tfidf_matrix)\n",
    "l1_ed =euclidean_distances(tfidf_norm_l1[0:1],tfidf_norm_l1[1:2])\n",
    "print(yellow(\"ğŸ“Œ - L1 ì •ê·œí™” í›„ ìœ í´ë¦¬ë””ì–¸ {}\").format(l1_ed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ë§¨í•´íŠ¼ ìœ ì‚¬ë„ (Manhattan Similarity)\n",
    "- ê±°ë¦¬ë¥¼ ê³„ì‚°í• ë•Œ ì¼ì§ì„ ì´ì•„ë‹ˆë¼ ë¸”ë¡ë˜ì–´ìˆëŠ” ë§¨í•´íŠ¼ ê±°ë¦¬ì²˜ëŸ¼ ë˜ì–´ìˆë‹¤ê³  ê°€ì •í•˜ê³  ê±°ë¦¬ë¥¼ êµ¬í•˜ëŠ” ë°©ì‹ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
