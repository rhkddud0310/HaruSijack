"""
---
## ğŸ“Œ Project : í•˜ë£¨ì‹œì‘ í”„ë¡œì íŠ¸ Module functions  ğŸ“ŒğŸ”¸ğŸŸ¦âœ…ğŸ†•ğŸ‰
## ğŸ“Œ Description : 
    ğŸ”¸  Data ì •ì œë¥¼ ìœ„í•œ Fuction module
    ğŸ”¸ ë°±ì•¤ë“œ ì„œë¹„ìŠ¤ë¥¼ ìœ„í•œ ë°ì´í„° ë³€í™˜ ë° ë¨¸ì‹ ëŸ¬ë‹ ì„œë¹„ìŠ¤ function 
## ğŸ“Œ Author : Forrest Dpark (ë¶„ì„ ë‹´ë‹¹)
## ğŸ“Œ Date : 2024.05.31 ~
## ğŸ“Œ Detail : 
    ğŸ”¸ ëª¨ë“ˆ ì‚¬ìš© ë°©ë²• : 
        1. [ directory ê°€ ë‹¤ë¥¼ë•Œ Server ì—ì„œ ì‚¬ìš©ë²• ]--
            #> from Functions  import Service   # module importing 
            #> Service.dataInfoProcessing(df)  # Data information ì •ë³´ ì¶œë ¥ 
            #> Service.plotSetting()           # OS í•œê¸€í™” í•œ Matplotlib 
        2.[ directory ê°€ ë‹¤ë¥¼ë•Œ Server.py ì—ì„œ ì‚¬ìš©ë²• ]--
            #> import sys,os 
            #> parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            #> sys.path.append(parent_dir)
            #> from Module.Functions import Service
        3. [ directory ê°‡ ë‹¤ë¥¼ ë•Œ Jupyter ì—ì„œ ì‚¬ìš© ë²• ]
            #> import sys,os 
            #> parent_dir = os.path.dirname(os.getcwd())
            #> sys.path.append(parent_dir)
            #> from Module.Functions import Service
## ğŸ“Œ Update:  
    ğŸŸ¦ 2024.06.02 by pdg : multiprocessing import 
        âœ… Data frame column ì •ë³´ ( Null check, ì¤‘ë³µì²´í¬ )í”Œë 
    ğŸŸ¦ 2024.06.03 by pdg : datdaInfoProcessing í•¨ìˆ˜ ìƒì„±
        âœ… DataInfoProcessing í•¨ìˆ˜ì˜ printoutcolnumber í”Œëí•  ì¹¼ëŸ¼ ê°¯ìˆ˜ë¥¼ ì„ íƒí• ìˆ˜ìˆê²Œ ì„¤ì •í•¨. 
    ğŸŸ¦ 2024.06.05 by pdg : ê¸°íƒ€ í•¨ìˆ˜ ìƒì„± 
        âœ… plotSetting í•¨ìˆ˜ ì¶”ê°€ 
        âœ… reorder_columns í•¨ìˆ˜ ì¶”ê°€ -> ì¹¼ëŸ¼ì˜ ìˆœì„œë¥¼ ë°”ê¾¸ì–´ì¤Œ.
        âœ… currentPassengerCalc í•¨ìˆ˜ ì¶”ê°€ í˜„ì¬ íƒ‘ìŠ¹ê° ë° ëŸ‰ë‹¹ ë¹ˆìë¦¬ ì¶”ì¶œ(ë…¸ì¸ì„ ì œì™¸)
        âœ… stationDispatchBarplot í•¨ìˆ˜ ì¶”ê°€ -> ì§€í•˜ì²  ì—­ë³„ ë°°ì°¨ ì§€í•˜ì²  ìˆ˜ì¹˜ barplot check 
        âœ… dayToIntConvert  í•¨ìˆ˜ ì¶”ê°€
        âœ… date_Divid_Add_YMW_cols í•¨ìˆ˜ì¶”ê°€ 
        âœ… holidaysToIntConvert í•¨ìˆ˜ ì¶”ê°€ 
    ğŸŸ¦ 2024.06.07 by pdg : validation ì„ ìœ„í•œ ë°ì´í„° ì‹œê°í™” í•¨ìˆ˜ 
        âœ… station_name_to_code í•¨ìˆ˜ ì¶”ê°€
        âœ… sdtation_inout_lmplot í•¨ìˆ˜ ì¶”ê°€
    ğŸŸ¦ 2024.06.09 by pdg :  ì§€í•˜ì²  ì—­ëª… ì²˜ë¦¬ ë° ì½”ë“œ ì¤‘ë³µì²˜ë¦¬ ë¬¸ì œë¡œ ë°ì´í„° ëˆ„ë½ë˜ëŠ” ì´ìŠˆ í•´ê²° 
        âœ… subway_info_table í•¨ìˆ˜ì¶”ê°€ 
        âœ… í•¨ìˆ˜ ìˆœì„œ ë°”ê¿ˆ, ì£¼ì„ ì¶”ê°€
        âœ… í˜¸ì„ ë‹¹ì„œë¹„ìŠ¤ë¶ˆê°€ì—­ì´ë¦„ì¶”ì¶œ í•¨ìˆ˜ ì¶”ê°€
        
        %%% ê° í•¨ìˆ˜ë³„ë¡œ ì–´ë–¤ ì£¼í”¼í„°ì—ì„œ ì‘ì„±ë˜ì—ˆëŠ”ì§€ ë¶„ë¥˜ë‚˜ëˆŒê²ƒ
        
    ğŸŸ¦ 2024.06.10 by pdg : KNN regression model ì €ì¥ 
        âœ… í•¨ìˆ˜ ì €ì¥ í•˜ë„ë¡ ë°”ê¿ˆ
    ğŸŸ¦ 2024.06.12 by pdg : í•¨ìˆ˜ ì •ë¦¬ ë° ì£¼ì„ ì •ë¦¬ 
    ğŸŸ¦ 2024.06.13 by pdg : 
        âœ… color text í•¨ìˆ˜ ì¶”ê°€
        âœ… subwayInfo í•¨ìˆ˜ ìˆ˜ì • 
    * 2024.06.14 by pdg :
        ë¨¸ì‹ ëŸ¬ë‹ í†µí•© íŒŒì¼ì—ì„œ ì‚¬ìš©í•˜ëŠ” StationInfo íŒŒì¼ dict í™” í•¨ìˆ˜ ì¶”ê°€ 
        - ê°í•¨ìˆ˜ì—í”„ë¦°íŠ¸ë¥¼ ë„£ì–´ì„œ ë¬´ì—‡ì„ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜ì¸ì§€ print í•œí›„ ì‹¤í–‰ë ìˆ˜ìˆë„ë¡ í•¨. 
        - mlTableGení•¨ ìˆ˜ ì¶”ê°€ 
        - í†µí•© feature í…Œì´ë¸” í˜•ì„±í•˜ì—¬ npy ì €ì¥í•¨. 
    

---
"""
## project data processing functions 
# Service.Explaination(title,explain

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error, r2_score
class Service:
    
    def __init__(self) -> None:
        pass
    
#### ê¸°ë³¸ Setting í•¨ìˆ˜
    def colored_text(text, color='default', bold=False):
        '''
        #### ì˜ˆì‹œ ì‚¬ìš©ë²•
        print(colored_text('ì €ì¥ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.', 'red'))
        print(colored_text('ì €ì¥ í•©ë‹ˆë‹¤.', 'green'))
        default,red,green,yellow,blue, magenta, cyan, white, rest
        '''
        colors = {
            'default': '\033[99m',
            'red': '\033[91m',
            'green': '\033[92m',
            'yellow': '\033[93m',
            'blue': '\033[94m',
            'magenta': '\033[95m', #ë³´ë¼ìƒ‰
            'cyan': '\033[96m',
            'white': '\033[97m',
            'bright_black': '\033[90m',  # ë°ì€ ê²€ì •ìƒ‰ (íšŒìƒ‰)
            'bright_red': '\033[91m',  # ë°ì€ ë¹¨ê°„ìƒ‰
            'bright_green': '\033[92m',  # ë°ì€ ì´ˆë¡ìƒ‰
            'bright_yellow': '\033[93m',  # ë°ì€ ë…¸ë€ìƒ‰
            'bright_blue': '\033[94m',  # ë°ì€ íŒŒë€ìƒ‰
            'bright_magenta': '\033[95m',  # ë°ì€ ë³´ë¼ìƒ‰
            'bright_cyan': '\033[96m',  # ë°ì€ ì²­ë¡ìƒ‰
            'bright_white': '\033[97m',  # ë°ì€ í°ìƒ‰
            'reset': '\033[0m'
        }
        color_code = colors.get(color, colors['default'])
        bold_code = '\033[1m' if bold else ''
        reset_code = colors['reset']
        
        return f"{bold_code}{color_code}{text}{reset_code}"
    def Explaination(title,explain):
        title =str(title).upper()
        print(Service.colored_text(f"___ ğŸŸ¡ {title}. ",'green',bold=True))
        print(Service.colored_text(f"______ ğŸ“Œ {explain}",'yellow'))
    def plotSetting(pltStyle="seaborn-v0_8"):
        '''
        # Fucntion Description : Plot í•œê¸€í™” Setting
        # Date : 2024.06.05
        # Author : Forrest D Park 
        # update : 
        '''
        Service.Explaination("plotSetting","matplotlibn plot í•œê¸€í™” Setting")
        # graph style seaborn
        import matplotlib.pyplot as plt # visiulization
        import platform
        from matplotlib import font_manager, rc # rc : í°íŠ¸ ë³€ê²½ ëª¨ë“ˆfont_manager : í°íŠ¸ ê´€ë¦¬ ëª¨ë“ˆ
        plt.style.use(pltStyle)
        plt.rcParams['axes.unicode_minus'] = False# unicode ì„¤ì •
        if platform.system() == 'Darwin': rc('font', family='AppleGothic') # osê°€ macos
        elif platform.system() == 'Windows': # osê°€ windows
            path = 'c:/Windows/Fonts/malgun.ttf' 
            font_name = font_manager.FontProperties(fname=path).get_name()
            rc('font', family=font_name)
        else:
            print("Unknown System")
        print(Service.colored_text("___## OS platform í•œê¸€ ì„¸íŒ…ì™„ë£Œ ## ___",'magenta'))
    def indexFind(colnamelist, search_target_word):
        print(Service.colored_text("ğŸ“Œí•´ë‹¹ ë‹¨ì–´ê°€ ì¡´ì¬í•˜ëŠ” ì¹¼ëŸ¼ì˜ ì´ë¦„ì´ìˆëŠ” ì¹¼ëŸ¼ì˜ indxë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.",'yellow'))
        # í•´ë‹¹ ë‹¨ì–´ê°€ ì¡´ì¬í•˜ëŠ” ì¹¼ëŸ¼ì˜ ì´ë¦„ì´ìˆëŠ” ì¹¼ëŸ¼ì˜ indxë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. 
        import numpy as np
        indices = np.where([search_target_word in col for col in colnamelist])[0]
        return indices
####  ë°ì´í„° ì²´í¬ë° ì •ì œ ê´€ë ¨ í•¨ìˆ˜ë“¤ 
    def dataInfoProcessing(df, replace_Nan=False, PrintOutColnumber = 6,nanFillValue=0):
        ''' 
        ğŸ“Œ Fucntion Description :  Data frame ì˜ ì •ì œí•´ì•¼í•  ë¶€ë¶„ì„ ì²´í¬í•´ì£¼ëŠ” í•¨ìˆ˜ 
        ğŸ“Œ Date : 2024.06.02 
        ğŸ“Œ Author : Forrest D Park 
        ğŸ“Œ update : 
            ğŸŸ¦ 2024.06.02 by pdg: ì¼ë³„ ë°ì´í„° ì •ì œ 
                âœ… ë°ì´í„°ì— null ì´ ìˆìŒì„ ë°œê²¬, data ì •ì œ í•¨ìˆ˜ update 
                âœ… í•¨ìˆ˜ì—ì„œ replace_Nan ì•„ê·œ ë©˜íŠ¸ ë°›ì•„ì„œ true ì¼ê²½ìš° nan ì„ 0 ìœ¼ë¡œ ëŒ€ì²´ í•˜ê²Œ ë§Œë“¬. 
            ğŸŸ¦ 2024.06.04 by pdg : í•¨ìˆ˜ë³€ê²½
                âœ… ê´€ì‹¬ ì¹¼ëŸ¼ì´ ë§ì„ë•Œ ì¹¼ëŸ¼ ê°œìˆ˜ë¥¼ ì¡°ì •í• ìˆ˜ìˆê²Œ í•¨. 
        '''
        Service.Explaination("dataInfoProcessing","Data frame ì˜ ì •ì œí•´ì•¼í•  ë¶€ë¶„ì„ ì²´í¬í•´ì£¼ëŠ” í•¨ìˆ˜ ì…ë‹ˆë‹¤")
        
        print(Service.colored_text(f"  1ï¸âƒ£ Data row/colum numbers : {len(df.index)}/{len(df.columns)}",'red'))
        #print(subway.columns)
        #print(subway.info())
        null_message =f"ì´ {df.isnull().sum().sum()}ê°œì˜ null ì´ ìˆìŠµë‹ˆë‹¤!" if df.isnull().sum().sum() else "Null ì—†ëŠ” clean data!"
        print(Service.colored_text(f"  2ï¸âƒ£ null check ê²°ê³¼{null_message}",'red'))
        ### Null ì´ ìˆëŠ” ì¹¼ëŸ¼ ì¶”ì¶œ
        haveNullColumn =[]
        for idx, col in enumerate(df.columns):
            if df[f"{col}"].isnull().sum():
                print(f"   => {idx}ë²ˆì§¸.[{col}]ì»¬ëŸ¼ : ",f"null {df[f'{col}'].isnull().sum()} ê°œ,\t not null {df[f'{col}'].notnull().sum()} ê°œ")
                ## Null data fill
                if replace_Nan : ## nan ì„ 0 ìœ¼ë¡œ ëŒ€ì²´ 
                    df=df[col].fillna(value=nanFillValue, inplace=True)  
            
        
        print(Service.colored_text("  3ï¸âƒ£ Column  Information (ì¤‘ë³µì²´í¬)",'red'))
        print( "\tidx.columName |\t\t\t\t |Colum Info(dtype)|** ")
        print( "\t","--"*len("columIdx |\t\t\t\t **|Col(dtype)|** "))
        for idx, col in enumerate(df.dtypes.keys()):
            if idx< PrintOutColnumber:
                if len(f"\t{idx}.[{col}({df.dtypes[col]})]:")<20:
                    print(f"\t{idx}.[{col}({df.dtypes[col]})]:",\
                        f"{len(df[col].unique())}/{len(df[col])} [uniq/raw]", sep=" \t\t\t")
                else:
                        print(f"\t{idx}.[{col}({df.dtypes[col]})]:",\
                        f"{len(df[col].unique())}/{len(df[col])} [uniq/raw]", sep=" \t\t")

        else: 
            print(f"\t ...etc (ì¶”ê°€ë¡œ {len(df.dtypes.keys())-PrintOutColnumber}ê°œì˜ ì¹¼ëŸ¼ì´ ìˆìŠµë‹ˆë‹¤ )")
        return df
    def reorder_columns(df, col_name, target_idx):
        """
        ğŸ“Œ Description : Reorder columns in a DataFrame by moving a specific column to a target index.
        ğŸ“Œ Date : 2024.06.05
        ğŸ“Œ Author : Forrest Dpark
        # Detail:
            * df (pandas.DataFrame): The input DataFrame.
            * col_name (str): The name of the column to be moved.
            * target_idx (int): The target index where the column should be placed.
            * Returns: pandas.DataFrame: The DataFrame with the column reordered.
        """
        Service.Explaination('reorder_columns','ì¹¼ëŸ¼ì„ ì´ë™í•¨')
        print(Service.colored_text(f'{col_name}ì„ {target_idx}ë¡œ ì´ë™í•¨','yellow'))
        cols = list(df.columns)
        current_idx = cols.index(col_name)
        cols.pop(current_idx)
        cols.insert(target_idx, col_name)
        # print("--"*110)
        return df[cols]

#### ì§€í•˜ì²  ì—­ì‚¬ ì •ë³´ ì •ì œ í›„ ì €ì¥
    def  subway_info_table(subway, save=False,saveFileName=""):
        import pandas as pd, numpy as np
        """
        ğŸ“Œ Description :  ìŠ¹í•˜ì°¨ ì¸ì› ë°ì´í„°ì—ì„œ ê° ì—­ì—ëŒ€í•œ ì •ë³´ ( ì—­ì‚¬ì½”ë“œ í˜¸ì„  ë“±)ë¥¼ ì¶”ì¶œí•œ í…Œì´ë¸”ì„ ë°˜í™˜
        ğŸ“Œ Date : 2024.06.13
        ğŸ“Œ Author : Forrest Dpark
        ğŸ“Œ Detail:
            ğŸ”¸ Returns: 
        ğŸ“Œ Updates : 
            2024.06.13 by pdg : í”„ë¦°íŠ¸ì— ìƒ‰ê¹”ì…í˜. 
        """
        Service.Explaination('subway_info_table','ìŠ¹í•˜ì°¨ ì¸ì› ë°ì´í„°ì—ì„œ ê° ì—­ì—ëŒ€í•œ ì •ë³´ ( ì—­ì‚¬ì½”ë“œ í˜¸ì„  ë“±)ë¥¼ ì¶”ì¶œí•œ í…Œì´ë¸”ì„ ë°˜í™˜')
        # print(Service.colored_text("""\n ğŸ”¸ğŸ”¸ğŸ”¸ì§€í•˜ì²  ì—­ì •ë³´ í…Œì´ë¸” í•¨ìˆ˜ ì‹¤í–‰ğŸ”¸ğŸ”¸ğŸ”¸ """,'magenta'))
        print("  |- ì²« ìˆ˜ì†¡ì¼ì :",list(subway['ìˆ˜ì†¡ì¼ì'])[0])
        print("  |- ë§ˆì§€ë§‰ ìˆ˜ì†¡ì¼ì :",list(subway['ìˆ˜ì†¡ì¼ì'])[-1])
        ## ì—­ëª…ì—ì„œ () ë¹¼ë²„ë¦¬ê¸° 
        ì •ì œëœì—­ëª… = [i.split("(")[0] for i in subway['ì—­ì´ë¦„']]
        subway['ì—­ì´ë¦„']= ì •ì œëœì—­ëª…
        # if subway.reorder_columns 
        
        subway_test = subway.rename({'ê³ ìœ ì—­ë²ˆí˜¸(ì™¸ë¶€ì—­ì½”ë“œ)':'ì—­ì‚¬ì½”ë“œ'},axis=1)
        ### ì—­ì½”ë“œ obj -> int ë¡œ ë³€í™˜  ** ì•„ë¬´ê²ƒë„ ì—†ëŠ” ë°ì´í„°ëŠ” 000 ìœ¼ë¡œ ë³€í™˜ 
        new_stationCode = []
        issued_index =[]
        for i, code in enumerate(subway_test['ì—­ì‚¬ì½”ë“œ']):
            # print(str(i).replace(" ",""))
            try : 
                new_stationCode.append(int(str(code)))
            except ValueError : 
                print(f"{i}ë²ˆì§¸ ë°ì´í„° {code}" ,"<-value errer: ")
                new_stationCode.append(000)
                issued_index.append(i)
                continue
        print(f"{issued_index}ëŠ” ê°’ì—ëŸ¬ 0 ìœ¼ë¡œ ëŒ€ì²´í•¨" if len(new_stationCode)== len(subway_test) else "ëŒ€ì²´ ì•ˆë¨")
        #0,ê´‘ëª…ì‚¬ê±°ë¦¬,7,1 ì´ ì½”ë“œê°€ ë¬¸ì œë¨..
        subway_test['ì—­ì‚¬ì½”ë“œ'] = new_stationCode
        
        # ì—­ì‚¬ì½”ë“œì— í•´ë‹¹í•˜ëŠ” ì—­ì´ë¦„ê³¼ í˜¸ì„ ì„ í…Œì´ë¸”ë¡œ ë§Œë“¤ê³  ì‹¶ë‹¤.
        # ì¤‘ë³µ ì œê±° í›„ ì—­ ë²ˆí˜¸, ì—­ ì´ë¦„, í˜¸ì„  ì •ë³´ë¥¼ ì¶”ì¶œ
        unique_stations = subway_test.drop_duplicates(subset=['ì—­ì‚¬ì½”ë“œ', 'ì—­ì´ë¦„', 'í˜¸ì„ '])
        #ì—­ëª… ì½”ë“œê°€ 0 ì´ë©´ í–‰ drop 
        unique_stations = unique_stations[unique_stations['ì—­ì‚¬ì½”ë“œ'] != 0]
        subway_info =unique_stations[['ì—­ì‚¬ì½”ë“œ', 'ì—­ì´ë¦„', 'í˜¸ì„ ']]
        subway_info.reset_index(inplace=True,drop=True)

        ## í™˜ìŠ¹ì—­ ì—¬ë¶€ ì¹¼ëŸ¼ì„ ì¶”ê°€í•œ StationInfo data ë§Œë“¤ì .

        test1 = dict(subway_info['ì—­ì´ë¦„'].value_counts())
        to_merge_df_exchange = pd.DataFrame(
            {
            'ì—­ì´ë¦„':list(test1.keys()),
            'í™˜ìŠ¹ì—­ìˆ˜':list(test1.values())
            }
        )
        merged_table = pd.merge(
            subway_info,to_merge_df_exchange,
            on='ì—­ì´ë¦„'
        )
        to_saveDataframe = merged_table[['ì—­ì‚¬ì½”ë“œ','ì—­ì´ë¦„','í˜¸ì„ ','í™˜ìŠ¹ì—­ìˆ˜']]
        if save: 
        # to_saveDataframe.to_csv(f"../Data/StationInfo.csv",index=None)

            print(f'\033[92m >>{saveFileName}ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\033[0m') 
            to_saveDataframe.to_csv(f"../Data/{saveFileName}.csv",index=None)
        else:
            print('\033[91m >>ì €ì¥ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\033[0m')

        return to_saveDataframe

#### ì§€í•˜ì²  ë°°ì°¨í‘œ í˜¸ì„ ë³„ í…Œì´ë¸” ì •ì œ í•¨ìˆ˜ 
    def dispatch_table_forML(line_ë°°ì¹˜, save=False, saveFileName=""):
        """
        #### ğŸ“Œ Description : íŠ¹ì • í˜¸ì„ ì—ëŒ€í•œ ë°°ì¹˜í‘œ ì •ë³´ë¥¼ ë°›ì•„ì„œ pivotable ë¡œì‹œê°„ëŒ€ë³„ ì¹¼ëŸ¼ìƒì„±í›„ ë°°ì°¨ ìˆ˜ë¥¼ ê³„ì‚°
        #### ğŸ“Œ Date : 2024.06.09
        #### ğŸ“Œ Author : Forrest Dpark
        #### ğŸ“Œ Detail:
            * line_ë°°ì¹˜ (df)
            * Returns: pivotable for machine learning (df)
        """
        Service.Explaination('dispatch_table_forML','íŠ¹ì • í˜¸ì„ ì—ëŒ€í•œ ë°°ì¹˜í‘œ ì •ë³´ë¥¼ ë°›ì•„ì„œ pivotable ë¡œì‹œê°„ëŒ€ë³„ ì¹¼ëŸ¼ìƒì„±í›„ ë°°ì°¨ ìˆ˜ë¥¼ ê³„ì‚°')
        import warnings ; warnings.filterwarnings('ignore')
        # ìƒˆë¡œìš´ í…Œì´ë¸” ë§Œë“¤ê¸°
        line_ë°°ì¹˜['ì—´ì°¨ì‹œê°„ê³„ì‚°']=line_ë°°ì¹˜['ì—´ì°¨ë„ì°©ì‹œê°„'].str.split(':').str[0]
        # 'ì—­ì‚¬ëª…'ê³¼ 'ì‹œê°„'ì´ ê°™ì€ ë°ì´í„° ê·¸ë£¹í™”
        grouped = line_ë°°ì¹˜.groupby(['ì—­ì‚¬ì½”ë“œ', 'ì—´ì°¨ì‹œê°„ê³„ì‚°','ì£¼ì¤‘ì£¼ë§','ë°©í–¥'])
        # ê° ê·¸ë£¹ì˜ í¬ê¸°(ê°œìˆ˜) ê³„ì‚°
        count = grouped.size().rename('ì°¨ëŸ‰ìˆ˜')
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        interval = count.reset_index()
        # return interval['ì—­ì‚¬ì½”ë“œ'].unique()
        # ì—´ ì´ë¦„ ì§€ì •
        interval.columns = ['ì—­ì‚¬ì½”ë“œ', 'ì‹œê°„', 'ì£¼ì¤‘ì£¼ë§','ë°©í–¥','ë°°ì°¨ìˆ˜']
        interval['ì—­ì‚¬ì½”ë“œ'] = interval['ì—­ì‚¬ì½”ë“œ'].astype('int64')
        # ì—­ì‚¬ì½”ë“œ(=),ì£¼ì¤‘ì£¼ë§(=)ì„ ê¸°ì¤€ìœ¼ë¡œ ë°©í–¥ì´ ë‹¤ë¥¸ ë°°ì°¨ìˆ˜ë¥¼ í•©ì¹œ í›„ ìƒˆë¡œìš´ ë¡œìš° ìƒì„±í›„ ë°©í–¥ ì»¬ëŸ¼ ì‚­ì œí•œ ìƒˆë¡œìš´ ë°ì´í„° ì…‹ ë§Œë“¤ê¸°
        # ë°©í–¥ ë³„ë¡œ ë°°ì°¨ìˆ˜ í•©ì¹˜ê¸°
        
        interval = interval.groupby(['ì—­ì‚¬ì½”ë“œ', 'ì‹œê°„', 'ì£¼ì¤‘ì£¼ë§'])['ë°°ì°¨ìˆ˜'].sum().reset_index()
        interval['ë°°ì°¨ìˆ˜']=interval['ë°°ì°¨ìˆ˜']/2
        
        # í”¼ë²— í…Œì´ë¸” ìƒì„±
        pivot_df = interval.pivot_table(index=['ì—­ì‚¬ì½”ë“œ', 'ì£¼ì¤‘ì£¼ë§'], columns='ì‹œê°„', values='ë°°ì°¨ìˆ˜', aggfunc='mean')

        # # ì¸ë±ìŠ¤ë¥¼ ì—´ë¡œ ë¦¬ì…‹
        interval = pivot_df.reset_index()
        # return interval
        # # ì²« ë²ˆì§¸ ì¸ë±ìŠ¤ ì—´ì„ ì¶”ê°€í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        # interval['ì—­ì‚¬ì½”ë“œ2'] = interval['í˜¸ì„ ']
        # interval.drop(columns=['ì—­ì‚¬ì½”ë“œ2'],inplace=True)
        # interval.index = interval['ì—­ì‚¬ì½”ë“œ']
        interval.fillna(0, inplace=True)
        cols = interval.columns.tolist()
        cols.append(cols.pop(cols.index('00')))
        interval = interval[cols]

        interval.rename(columns={'00': '24'}, inplace=True)
        interval['í˜¸ì„ ']=line_ë°°ì¹˜['í˜¸ì„ '].unique()[0] 
        interval=Service.reorder_columns(col_name='í˜¸ì„ ',df=interval,target_idx=1)
        print(Service.colored_text(f" ğŸ”¸{line_ë°°ì¹˜['í˜¸ì„ '].unique() }í˜¸ì„  ì— ëŒ€í•œ ë°°ì°¨ í…Œì´ë¸” í‘œì •ì œ ê²°ê³¼",'green'))
        
        if save: 
            print(Service.colored_text('ë°°ì°¨ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.','red'))
            interval.to_csv(f'../Data/ì§€í•˜ì² ë°°ì°¨ì‹œê°„ë°ì´í„°/{saveFileName}_í˜¸ì„ ë°°ì°¨.csv',index =None)
        else:
            print(Service.colored_text('ë°°ì°¨ì •ë³´ë¥¼ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤','red'))
        return interval
    def table_merge_subwayInfo_dispatch(subwayInfo,line_ë°°ì¹˜,histPlot = False):
        """
        #### ğŸ“Œ Description : ì—­ì‚¬ì •ë³´ì™€ ë°°ì°¨í…Œì´ë¸”ì„ Merge í•©ë‹ˆë‹¤.
        #### ğŸ“Œ Date : 2024.06.09
        #### ğŸ“Œ Author : Forrest Dpark
        #### ğŸ“Œ Detail:
            * line_ë°°ì¹˜ (df)
            * save (Bool) : ì €ì¥í• ê²ƒì´ë©´ True
            * saveFileName (str) : ì €ì¥íŒŒì¼ ì´ë¦„ ì£¼ì†Œ 
            * Returns: pivotable for machine learning (df)
        """
        import pandas as pd 
        Service.Explaination('table_merge_subwayInfo_dispatch',"ì—­ì‚¬ì •ë³´ì™€ ë°°ì°¨í…Œì´ë¸”ì„ Merge í•©ë‹ˆë‹¤.")
        print(Service.colored_text('--- ë°°ì°¨ì‹œê°„í‘œ + ì—­ì‚¬ì •ë³´ ---','yellow'))
        print(Service.colored_text(f"{line_ë°°ì¹˜['í˜¸ì„ '].unique() }í˜¸ì„  ë°°ì°¨ì‹œê°„í‘œ ì—­ì‚¬ì½”ë“œ ê°œìˆ˜ :{len(line_ë°°ì¹˜['ì—­ì‚¬ì½”ë“œ'].unique())}",'yellow'))
        test_merged_interval= pd.merge(subwayInfo,line_ë°°ì¹˜, on= ['ì—­ì‚¬ì½”ë“œ','í˜¸ì„ '])
        print(Service.colored_text(f"{line_ë°°ì¹˜['í˜¸ì„ '].unique()}í˜¸ì„ í…Œì´ë¸” ë³‘í•©í›„ ì„œë¹„ìŠ¤ê°€ëŠ¥í•œ ì´ ì—­ ê°œìˆ˜",'yellow'),len(test_merged_interval['ì—­ì‚¬ì½”ë“œ'].unique()))
        ## ì£¼ì¤‘ ì£¼ë§  ì¹´í…Œê³ ë¦¬ë¥¼ 0,1 ë¡œ ë°”ê¾¸ì–´ì¤Œ ì£¼ë§ì¼ê²½ìš° 1 ì£¼ì¤‘ì¼ê²½ìš° 0  ->onehot encoding 
        test_mi = test_merged_interval.copy()
        # test_mi.rename({'ì£¼ì¤‘ì£¼ë§':'ì£¼ë§'}, axis=1,inplace=True)
        test_mi_week_dummies = pd.get_dummies(test_mi['ì£¼ì¤‘ì£¼ë§'])


        test_mi_week_dummies.head()
        test_ = pd.concat([test_mi,test_mi_week_dummies], axis=1)
        # ì£¼ë§ ì¹¼ëŸ¼ ì‚­ì œ , day -> ì£¼ì¤‘, sat -> ì£¼ë§ ë¡œ ë³€ê²½ 
        # test_.drop('ì£¼ë§', axis=1, inplace=True)
        # for idx, col in enumerate(list(test_.columns)):
        #     print(idx, col)
        # ì¸ë±ìŠ¤ 2ì˜ ê°’ì„ ì¸ë±ìŠ¤ 4ë¡œ ì´ë™

        test_ =Service.reorder_columns(test_,'SAT',4)
        test_ =Service.reorder_columns(test_,'DAY',5)
        ## ë°°ì°¨ì‹œê°„ ì¹¼ëŸ¼ ì´ë¦„ ë³€ê²½ 
        # t1=pd.concat([test_.columns[:8].to_series(),test_.columns[8:].to_series()+'ì‹œë°°ì°¨'])
        # test_.columns =t1
        test_.rename(
            {
                'SAT':'ì£¼ë§',
                'DAY':'ì£¼ì¤‘'
            }, axis=1, inplace=True
        )
        print(Service.colored_text('SAT,DAY -> ì£¼ë§,ì£¼ì¤‘'))
        if histPlot:
            print("ì˜ˆì‹œíˆìŠ¤í† ê·¸ë¨ 1ê°œë§Œ í”Œëí•©ë‹ˆë‹¤(ë‚˜ë¨¸ì§€ëŠ” ì €ì¥ë¨)")
            for i in range(0,len(test_[:2]),2): ## ì˜ˆì‹œë¡œ 2ê°œ
                Service.stationDispatchBarplot(test_,i, title_columnName='ì—­ì´ë¦„',startColNum=9)
        print(Service.colored_text("ìµœì¢… ë³‘í•©ëœ í…Œì´ë¸”ì„ ì¶œë ¥í•©ë‹ˆë‹¤",'yellow'))
        return test_
    def data_preprocessing_toAnalysis(data_dict,key_data):
        """
            # ğŸ“Œ Description : ë°ì´í„° í†µí•© ì •ì œ í•¨ìˆ˜!!!
            # ğŸ“Œ Date : 2024.06.13
            # ğŸ“Œ Author : Forrest Dpark
            # ğŸ“Œ Detail:
                * key_data(str) : ì˜ˆë¥¼ ë“¤ë©´ subway_23_0 ì´ë¼ëŠ”ë°ì´í„°ì—ì„œ 23_0 ì„ ì˜ë¯¸í•¨!
                * data_dict : ìŠ¹í•˜ì°¨ ë°ì´í„°ë¥¼ í¬í•¨í•˜ê³  ìˆëŠ” dictionary
                * ì‚¬ìš©ì‹œ ì´ìƒí•œë¶€ë¶„ ë¬¸ì˜ => 010-7722-15920
                * Returns: colum ì´ë¦„ë“¤ì„ ì •ì œí•˜ê³  Nanì„ ì œê±°í•œ ì •ì œ ë°ì´í„° table
        """
        Service.Explaination('data_preprocessing_toAnalysis','ë°ì´í„° í†µí•© ì •ì œ í•¨ìˆ˜!!!')
        import pandas as pd, numpy as np
        # í•„ìˆ˜ í•­ëª© check 
        # coloum check 
        saveFileName = "StationInfo_"+key_data.split("subway")[-1]
        test = data_dict[key_data] # ì˜ˆì‹œ-> subway_dict_22_23['subway23_0']
        print(Service.colored_text("columns ---ğŸ‘‡", 'green'))
        print(test.columns.tolist())
        # í˜¸ì„ , ì—­ì‚¬ë²ˆí˜¸,ì—­ëª…, ìŠ¹í•˜ì°¨êµ¬ë¶„
        # ì—°ë²ˆì€ drop í•œë‹¤. 
        if 'ì—°ë²ˆ' in test.columns.tolist():
            print(" 1. ì—°ë²ˆì„ ì‚­ì œí•©ë‹ˆë‹¤. ")
            test.drop('ì—°ë²ˆ',axis=1,inplace = True)
            # print(test.columns)
        # ì—­ëª… -> ì—­ì´ë¦„
        if 'ì—­ëª…' in test.columns.tolist():
            print(' 2."ì—­ëª…" ->"ì—­ì´ë¦„", "ì—­ë²ˆí˜¸"->"ì—­ì‚¬ì½”ë“œ ".')
            test.rename({
                'ë‚ ì§œ': 'ìˆ˜ì†¡ì¼ì',
                'ì—­ë²ˆí˜¸':'ì—­ì‚¬ì½”ë“œ',
                'ì—­ëª…':'ì—­ì´ë¦„'}
                ,axis = 1
                ,inplace = True 
                )
        # ì—­ë²ˆí˜¸ -> ì—­ì‚¬ë²ˆí˜¸ 
        # í˜¸ì„  ë°ì´í„°ê°€ integer ì¸ì§€ í™•ì¸ 
        if str(test['í˜¸ì„ '].dtype)=='object':
            print(' 3. í˜¸ì„  ë°ì´í„°ê°€ object ì…ë‹ˆë‹¤. ')
            for idx,line in enumerate(test['í˜¸ì„ '].unique()):
                print("   -",line)
                if idx==2:
                    print(" ..")
                    break
            line_int=[int(linename.split("í˜¸ì„ ")[0]) for linename in test['í˜¸ì„ ']]
            print(" ğŸ˜€í˜¸ì„ ì„ integer ë¡œ ë§Œë“­ë‹ˆë‹¤.")
            print(" 3-1. í˜¸ì„  ì„ ì œê±°í•œ ì´ë¦„ unique : ",*np.unique(line_int),sep=", ")
            test['í˜¸ì„ '] = line_int
            print(" âœ…ë³€ê²½ëœ í˜¸ì„  ì¹¼ëŸ¼ì˜ data type :",test['í˜¸ì„ '].dtype)
        else : 
            print('3. í˜¸ì„  ë°ì´í„°ê°€ integer ì…ë‹ˆë‹¤.')
            for idx,line in enumerate(test['í˜¸ì„ '].unique()):
                print(" -",line)
                if idx==2:
                    print(" ..")
                    break
        ## null check -> ì—†ë‹¤ê³  ê°€ì • 
        subway=Service.dataInfoProcessing(test,replace_Nan=True,nanFillValue=0 )
        #ì—­ì½”ë“œ ê°œìˆ˜ ì²´í¬ -> ìƒê´€ì—†ìŒ
        stationInfo = Service.subway_info_table(
            subway,
            save=True,
            saveFileName=saveFileName
            )
        print(subway.iloc[:4,:6])
        stationInfo

        station= pd.read_csv(f'../Data/{saveFileName}.csv')
        subway_dispatch = pd.read_csv("../Data/ì§€í•˜ì² ë°°ì°¨ì‹œê°„ë°ì´í„°/ì„œìš¸êµí†µê³µì‚¬_ì„œìš¸ ë„ì‹œì² ë„ ì—´ì°¨ìš´í–‰ì‹œê°í‘œ_20240305.csv", encoding='euc-kr')

        for i in range(1,8):
            _ = Service.í˜¸ì„ ë‹¹ì„œë¹„ìŠ¤ë¶ˆê°€ì—­ì´ë¦„ì¶”ì¶œ(i,station, subway_dispatch)
        print("ë°°ì°¨ ì‹œê°„ ì œê³µ ì—­ ê°œìˆ˜: ",len(subway_dispatch['ì—­ì‚¬ëª…'].unique())) # ì´ 394ê°œì˜ ì—­ì—ëŒ€í•œ ë°°ì°¨ ì‹œê°„ë°ì´í„°ê°€ ìˆë‹¤. 
        print(" í˜¸ì„  ->",*np.sort(subway_dispatch['í˜¸ì„ '].unique())) #1, 2, 3, 4, 5, 6, 7, 8, 9  -> 9í˜¸ì„  ë°ì´í„° ê¹Œì§€ ìˆìŒ

        ## line ë³„ë¡œ í…Œì´ë¸”ì„ ë”°ë¡œ ë§Œë“ ë‹¤, 
        # line1_ë°°ì¹˜= subway_dispatch[subway_dispatch['í˜¸ì„ ']==1]

        line_ë°°ì¹˜_dict = {}

        for i in range(1,9):
            line_ë°°ì¹˜_dict[f"{i}í˜¸ì„ "] =subway_dispatch[subway_dispatch['í˜¸ì„ ']==i]
            interval= Service.dispatch_table_forML(
                line_ë°°ì¹˜_dict[f"{i}í˜¸ì„ "],
                save=True,
                saveFileName=saveFileName+f"_{i}"
                )
            print(interval.iloc[0:3,:6].head(3))
        #ì •ì œí›„ ë°ì´í„° ì¶œë ¥
        return subway

#### í˜„ì¬íƒ‘ìŠ¹ê°ìˆ˜ ì¶”ì • ì•Œê³ ë¦¬ì¦˜
    def currentPassengerCalc(stations,pass_in,pass_out,dispached_subway_number):
        """
        # ğŸ“Œ Description : ê° ì—­ì—ì„œì˜ ì¶”ì • íƒ‘ìŠ¹ì¸ì› ìˆ˜ 
        # ğŸ“Œ Date : 2024.06.05
        # ğŸ“Œ Author : Forrest Dpark
        # ğŸ“Œ Detail:
            * stations (list): í•œ í˜¸ì„ ì˜ ì—­ì½”ë“œ or ì—­ ì´ë¦„ ë°°ì—´ 
            * pass_in (list): ê° ì—­ë‹¹ ìŠ¹ì°¨ ì¸ì›ìˆ˜ ë°°ì—´ 
            * pass_out (list): ê° ì—­ë‹¹ í•˜ì°¨ ì¸ì›ìˆ˜ ë°°ì—´
            * dispached_subway_number (int): ë°°ì°¨ëŒ€ìˆ˜
            * Returns: dataframe table
        """
        Service.Explaination('currentPassengerCalc',' ê° ì—­ì—ì„œì˜ ì¶”ì • íƒ‘ìŠ¹ì¸ì› ìˆ˜ ê³„ì‚° ')
        import pandas as pd , numpy as np
        # ìŠ¹í•˜ì°¨ ì •ë³´ ì—†ì„ë•Œ ëœë¤ ìŠ¹í•˜ì°¨ ì¸ì› ë°ì´í„° ìƒì„± 
        if pass_in ==[] and pass_out ==[]:
            pass_in = np.zeros(shape=(len(stations)), dtype=int)
            pass_out = np.zeros(shape=(len(stations)), dtype=int)
            presentPassenger= np.zeros(shape=(len(stations)), dtype=int)
            for i,station in enumerate(stations):
                    pass_in[i]= np.random.randint(1,100) if i !=len(stations)-1 else 0
                
                    if i >0:
                        pass_out[i]= np.random.randint(1,presentPassenger[i-1])
                        presentPassenger[i] = presentPassenger[i-1] +pass_in[i]-pass_out[i]
                    else:
                        presentPassenger[i] = pass_in[i]
                    # print(station, f"ì—­ => ìŠ¹ì°¨: {input_pasasengers_rand[i]} ,í•˜ì°¨ :{output_pasasengers_rand[i]}")
                    # print('í˜„ì¬íƒ‘ìŠ¹ì¸ì› : ',presentPassenger)
        #ì—­ë³„ ë³€ë™ì¸ì›
        
        diff_arr = np.asarray(pass_in) - np.asarray(pass_out)

        print(f"{dispached_subway_number}ê°œ ì§€í•˜ì² ì´ ë°°ì°¨ë˜ì—ˆì„ë•Œ ")
        result = pd.DataFrame(
            {
                'ì—­ì´ë¦„': stations,
                'ìŠ¹ì°¨ì¸ì›': pass_in,
                'í•˜ì°¨ì¸ì›': pass_out,
                'ë³€ë™ì¸ì›': diff_arr,
                'íƒ‘ìŠ¹ììˆ˜': presentPassenger,
                'ë°°ì°¨ë‹¹íƒ‘ìŠ¹ììˆ˜': presentPassenger/dispached_subway_number,
                'ëŸ‰ë‹¹ë¹ˆì¢Œì„ìˆ˜' :42 -(presentPassenger/dispached_subway_number)/8 #42 ê°œ 6*7 ë…¸ì•½ì ì œì™¸ , 7í˜¸ì„ ì€ 8ëŸ‰
            }
        )
        return result
    def stationDispatchBarplot(df,row,title_columnName,startColNum):
        """
        ### ğŸ“Œ Description : ì—­ë“¤ì˜ ì§€í•˜ì²  ë°°ì°¨ ìˆ˜(ì‹±í—¹ê³¼ í•˜í–‰ì´ ê±°ì˜ ë¹„ìŠ·í•˜ë‹¤ëŠ” ê°€ì •í•˜ì— ì¶”ì •ìˆ˜ì¹˜ì„)
        ### ğŸ“Œ Date : 2024.06.05
        ### ğŸ“Œ Author : Forrest Dpark
        ### ğŸ“Œ Detail:
            * df pd.DataFrame:(ì—­ì‚¬ì½”ë“œì™€ ì—­ì´ë¦„, í‰ê·  ë°°ì°¨ìˆ˜ ë¥¼ ê°€ì§€ê³  ìˆëŠ” ë°ì´í„° í”„ë ˆì„ )
            * row (int): ì£¼ì¤‘ í–‰ , row+1 ì€ ì£¼ë§ í–‰ì„. 
            * title_columnName (string) : ì—­ì´ë¦„ ì•Œìˆ˜ìˆëŠ” ì¹¼ëŸ¼. 
            * Returns: -
        """
        Service.Explaination('stationDispatchBarplot',' ì—­ë“¤ì˜ ì§€í•˜ì²  ë°°ì°¨ ìˆ˜(ì‹±í—¹ê³¼ í•˜í–‰ì´ ê±°ì˜ ë¹„ìŠ·í•˜ë‹¤ëŠ” ê°€ì •í•˜ì— ì¶”ì •ìˆ˜ì¹˜ì„)')
        import matplotlib.pyplot as plt, seaborn as sns
        # fig =plt.figure(figsize=(20,5))
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))
        bar1 = sns.barplot(
            data=df.iloc[row,startColNum:],
            color='orange',
            ax= ax1
        )
        ax1.set_title(f"{df[title_columnName].iloc[row]}ì—­ ì‹œê°„ëŒ€ë³„ ë°°ì°¨ ìˆ˜ ë¶„í¬[{'ì£¼ì¤‘' if df['ì£¼ì¤‘'].iloc[row] ==True else 'ì£¼ë§'}]")
        ax1.set_ylabel("ì§€í•˜ì²  ë°°ì°¨ ìˆ˜")
        bar1.bar_label(bar1.containers[0])
        
        bar2 = sns.barplot(
            data=df.iloc[row+1,startColNum:],
            color='green',
            ax= ax2,
            
        )
        bar2.bar_label(bar2.containers[0])
        
        ax2.set_title(f"{df[title_columnName].iloc[row+1]}ì—­ ì‹œê°„ëŒ€ë³„ ë°°ì°¨ ìˆ˜ ë¶„í¬[{'ì£¼ì¤‘' if df['ì£¼ì¤‘'].iloc[row+1] ==True else 'ì£¼ë§'}]")
        ax2.set_ylabel("ì§€í•˜ì²  ë°°ì°¨ ìˆ˜")
        maxlim=(max((df.iloc[row,startColNum:]).to_numpy()))
        # print(maxlim)
        ax2.set_ylim([0,maxlim])
        # bar2.set_ylim =[0,maxlim]
        plt.show()

#### ë‚ ì§œ ë¥¼ ì •ì œí•˜ëŠ” í•¨ìˆ˜
    def dayToIntConvert(df, dateColName):
        """
        ### ğŸ“Œ Description : STring type ì˜ ë‚ ì§œ (ex 2024-11-23)ë¥¼ ìš”ì¼ë¡œ ë°”ê¾¸ê³  0~6ì— í•´ë‹¹í•˜ëŠ” ìˆ«ìë¡œ ì¹¼ëŸ¼ì„ ìƒì„±í•´ ë°˜í™˜
        ### ğŸ“Œ Date : 2024.06.05
        ### ğŸ“Œ Author : Forrest Dpark
        ### ğŸ“Œ Detail:
            * df pd.DataFrame: ë‚ ì§œì¹¼ëŸ¼ì„ í¬í•¨í•˜ëŠ” ë°ì´í„° í”„ë ˆì„ 
            * dateColName : ë‚ ì§œì¹¼ëŸ¼ ì´ë¦„
            * Returns: 'ìš”ì¼' ì¹¼ëŸ¼ì´ ìƒì„±ë˜ì–´ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
        """
        Service.Explaination('dayToIntConvert','STring type ì˜ ë‚ ì§œ (ex 2024-11-23)ë¥¼ ìš”ì¼ë¡œ ë°”ê¾¸ê³  0~6ì— í•´ë‹¹í•˜ëŠ” ìˆ«ìë¡œ ì¹¼ëŸ¼ì„ ìƒì„±í•´ ë°˜í™˜')
        # ìˆ˜ì†¡ì¼ì ë‚ ì§œí˜•ìœ¼ë¡œ ë³€í™˜
        import pandas as pd
        ## ìš”ì¼ ì»¬ëŸ¼ ìƒì„±
        df['ìš”ì¼'] = pd.to_datetime(df[dateColName], format='%Y-%m-%d').dt.day_name().values
        # ìš”ì¼ì„ ì˜ì–´ì—ì„œ í•œêµ­ì–´ë¡œ ë³€í™˜
        day_name_mapping = {
            'Sunday': 0,
            'Monday': 1,
            'Tuesday': 2,
            'Wednesday': 3,
            'Thursday': 4,
            'Friday': 5,
            'Saturday': 6
        }
        
        from datetime import datetime, timedelta
        # Service.Explaination(title,explain)
        years = []
        weeks = []
        months = []
        for data in df[dateColName] :
            date_obj = pd.to_datetime(data)
            year, week, _ = date_obj.isocalendar()
            month = date_obj.month
            years.append(year)
            weeks.append(week)
            months.append(month)
            
        import holidays
        kr_holidays = holidays.KR()
        df['ì£¼ì¤‘ì£¼ë§'] = df['ìš”ì¼'].apply(lambda x: 'SAT' if x in [0, 6] else 'DAY')
        df['ë…„ë„'] = years
        df['ì›”'] = months
        df['ì£¼ì°¨'] = weeks
        df['ìš”ì¼'] = df['ìš”ì¼'].map(day_name_mapping)
        df['ê³µíœ´ì¼'] = df[dateColName].apply(lambda x: 0 if x in kr_holidays else 1)

        return df
    def date_Divid_Add_YMW_cols(df,DateColName):
        """
        ### ğŸ“Œ Description : ë‚ ì§œì¹¼ëŸ¼ì´ ë“¤ì–´ê°„ ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„ì„œ ë…„ë„, ì›”, ì£¼ì°¨ ì¹¼ëŸ¼ì„ ìƒì„±í•œë’¤ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
        ### ğŸ“Œ Date : 2024.06.05
        ### ğŸ“Œ Author : Forrest Dpark
        ### ğŸ“Œ Detail:
            * df pd.DataFrame: ë‚ ì§œì¹¼ëŸ¼ì„ í¬í•¨í•˜ëŠ” ë°ì´í„° í”„ë ˆì„ 
            * dateColName : ë‚ ì§œì¹¼ëŸ¼ ì´ë¦„
            * Returns: 'ë…„ë„,ì›”, ì£¼ì°¨' ì¹¼ëŸ¼ì´ ìƒì„±ë˜ì–´ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
        """
        Service.Explaination('date_Divid_Add_YMW_cols','ë‚ ì§œì¹¼ëŸ¼ì´ ë“¤ì–´ê°„ ë°ì´í„°í”„ë ˆì„ì„ ë°›ì•„ì„œ ë…„ë„, ì›”, ì£¼ì°¨ ì¹¼ëŸ¼ì„ ìƒì„±í•œë’¤ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜')
        import pandas as pd
        from datetime import datetime, timedelta
        # Service.Explaination(title,explain)
        years = []
        weeks = []
        months = []
        for data in df[DateColName] :
            date_obj = pd.to_datetime(data)
            year, week, _ = date_obj.isocalendar()
            month = date_obj.month
            years.append(year)
            weeks.append(week)
            months.append(month)
        df['ë…„ë„'] = years
        df['ì›”'] = months
        df['ì£¼ì°¨'] = weeks
        return df
    def date_string_to_MonthWeekHolyDayname(date_str):
        """
        ### ğŸ“Œ Description : ë¨¸ì‹ ëŸ¬ë‹ ì„ ìœ„í•´ ì•±ì—ì„œ ê°€ì ¸ì˜¨ ë‚ ì§œ string í•˜ë‚˜ë¥¼ ì›”,ì£¼ì°¨,íœ´ì¼,ìš”ì¼ ë°ì´í„°ë¡œ ë°˜í™˜
        ### ğŸ“Œ Date : 2024.06.10
        ### ğŸ“Œ Author : Forrest Dpark
        ### ğŸ“Œ Detail:
            * date_str: ë‚ ì§œ string ex) 1988-10-27
            * Returns: month_number, week_number, is_holi,dayname_code
        """
        Service.Explaination('date_string_to_MonthWeekHolyDayname','ë¨¸ì‹ ëŸ¬ë‹ ì„ ìœ„í•´ ì•±ì—ì„œ ê°€ì ¸ì˜¨ ë‚ ì§œ string í•˜ë‚˜ë¥¼ ì›”,ì£¼ì°¨,íœ´ì¼,ìš”ì¼ ë°ì´í„°ë¡œ ë°˜í™˜')
        from datetime import datetime,timedelta
        # ë‚ ì§œ ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ ë³€í™˜
        date_object = datetime.strptime(date_str, '%Y-%m-%d')
        year = date_object.year
        # í•´ë‹¹ ë‚ ì§œì˜ ì²« ë²ˆì§¸ ë‚ ì´ ì†í•œ ì£¼ì˜ ì²« ë²ˆì§¸ ë‚ ì§œë¥¼ ì°¾ìŒ
        first_day_of_year = datetime(year, 1, 1)
        first_day_of_year_weekday = first_day_of_year.weekday()  # í•´ë‹¹ ë…„ë„ì˜ 1ì›” 1ì¼ì˜ ìš”ì¼
        first_week_start_date = first_day_of_year - timedelta(days=first_day_of_year_weekday)
        
        # í•´ë‹¹ ë‚ ì§œê°€ ëª‡ ë²ˆì§¸ ì£¼ì¸ì§€ ê³„ì‚°
        week_number = ((date_object - first_week_start_date).days // 7) + 1
        import holidays
        kr_holidays = holidays.KR()
        is_holi =  1 if date_object in kr_holidays else 0
        day_name = date_object.strftime('%A')
        month_number = date_object.month
        day_name_mapping = {
            'Sunday': 0,
            'Monday': 1,
            'Tuesday': 2,
            'Wednesday': 3,
            'Thursday': 4,
            'Friday': 5,
            'Saturday': 6
        }
        dayname_code = day_name_mapping.get(day_name)
        return month_number, week_number, is_holi,dayname_code
    def holidaysToIntConvert(df,DateColName):
        Service.Explaination('holidaysToIntConvert','ê³µíœ´ì¼ ì¹¼ëŸ¼ ìƒì„± ')
        # !pip install holidays
        import holidays
        kr_holidays = holidays.KR()
        df['ê³µíœ´ì¼'] = df[DateColName].apply(lambda x: 0 if x in kr_holidays else 1)
        return df

####  ë¨¸ì‹ ëŸ¬ë‹ ê´€ë ¨ í•¨ìˆ˜ 
    def MultiOutputRegressorFunc_KNN(training_table, target_table,saveFileName) :
    
        """
        # Description : train, targetë°ì´í„°ì— ëŒ€í•œ MultiOutputRegressor model
        # Date : 2024.06.05
        # Author : Shin Nara + pdg
        # Detail:
            * training_table (df): train data
            * target_table (df): target data
            * Returns: - 
        # Updata:
            2024.06.07 by pdg :ë¨¸ì‹ ëŸ¬ë‹ í•¨ìˆ˜ ì—…ë°ì´íŠ¸ 
                * ì£¼ì„ ë‹¬ì•˜ìŒ. 
            2024.06.09 by pdg : 
                * í•¨ìˆ˜í™” ì™„ë£Œ
        """
        import pandas as pd, numpy as np
        import matplotlib.pyplot as plt 
        from sklearn.model_selection import train_test_split
        from sklearn.multioutput import MultiOutputRegressor
        from sklearn.neighbors import KNeighborsRegressor

        train_input, test_input, train_target, test_target = \
            train_test_split(training_table,
                            target_table, 
                            test_size=0.2,
                            random_state=42)
        ## KNN regression model 
        knn_regressor = KNeighborsRegressor(n_neighbors=3)
        ## Multi Output Setting
        multi_output_regressor = MultiOutputRegressor(knn_regressor)
        multi_output_regressor.fit(train_input, train_target)
        
        score = multi_output_regressor.score(test_input, test_target)
        print(f'Model score: {score}')
        
        predictions = multi_output_regressor.predict(test_input)
        # print(test_target.columns)
        # print(predictions[:5])
        print("ì£¼ì°¨     ìš”ì¼ ì‹œê°„ëŒ€ë³„ ì˜ˆì¸¡ :",*[f"{i}ì‹œ" for i in range(5,25)], sep='\t')
        for idx,ì‹œê°„ëŒ€ë³„ì˜ˆì¸¡ in enumerate(predictions):
            ì£¼ì°¨ = test_input.to_numpy()[idx][1]
            ìš”ì¼ =test_input.to_numpy()[idx][3]
            ì‹¤ì œì¹˜ = test_target.to_numpy()[idx]
            match ìš”ì¼:
                case ìš”ì¼ if ìš”ì¼ == 0: ìš”ì¼_str = 'ì¼'; 
                case ìš”ì¼ if ìš”ì¼ == 1: ìš”ì¼_str = 'ì›”'; 
                case ìš”ì¼ if ìš”ì¼ == 2: ìš”ì¼_str = 'í™”'; 
                case ìš”ì¼ if ìš”ì¼ == 3: ìš”ì¼_str = 'ìˆ˜'; 
                case ìš”ì¼ if ìš”ì¼ == 4: ìš”ì¼_str = 'ëª©'; 
                case ìš”ì¼ if ìš”ì¼ == 5: ìš”ì¼_str = 'ê¸ˆ'; 
                case ìš”ì¼ if ìš”ì¼ == 6: ìš”ì¼_str = 'í† '; 
                case _:print()
            print(f"{ì£¼ì°¨}ì£¼ì°¨ {ìš”ì¼_str}ìš”ì¼ ì‹œê°„ëŒ€ë³„ ì˜ˆì¸¡ :", *list(map(int,(ì‹œê°„ëŒ€ë³„ì˜ˆì¸¡))), sep='\t')
            print(f"{ì£¼ì°¨}ì£¼ì°¨ {ìš”ì¼_str}ìš”ì¼ ì‹œê°„ëŒ€ë³„ ì‹¤ì œ :", *ì‹¤ì œì¹˜, sep='\t')
            print("---"*200)
        import joblib ## model ì €ì¥ ìš© í•¨ìˆ˜ 
        filename = f'../Server/MLModels/{saveFileName}.h5'
        print(f"ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€{filename} ì„ ì €ì¥í•©ë‹ˆë‹¤ ğŸ˜€ğŸ˜€ğŸ˜€")
        joblib.dump(multi_output_regressor, filename)
        
        return multi_output_regressor
    def station_name_to_code(line,station_name):
        """
            # Description : ì—­ì´ë¦„ì„ ì½”ë“œë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
            # Date : 2024.06.07
            # Author : pdg
            # Detail:
                * line, station_name : '7í˜¸ì„ ', 'ì¤‘ê³¡'
                * Returns: í•´ë‹¹ ì§€í•˜ì²  ì—­ì‚¬ ì½”ë“œ 
            # Updata:
                * 2024.06.07 by pdg : ì—­ì‚¬ì½”ë“œ ë°˜í™˜í•¨ìˆ˜ 
                * 2024.06.09 by pdg : ì¤‘ë³µ ì—­ì‚¬ì½”ë“œì¼ê²½ìš° ë°°ì—´ ë°˜í™˜?
                    - ë§Œì•½ì— ì¢…ë¡œ3ê°€ì²˜ëŸ¼ ì½”ë“œê°€ ì—¬ëŸ¬ê°œì¸ ì—­ì‚¬ì¸ê²½ìš° 
                * 2024.06.10 by pdg : swift ë¡œ api service í• ë•Œ ì½”ë“œ ë°˜í™˜ì•ˆë˜ëŠ” ë¬¸ì œ í•´ê²° 
                    -ê¸°ì¡´ì˜ StationInfo.csv ì—ì„œ í˜¸ì„  ì¹¼ëŸ¼ì´ ìˆ«ìê°€ì•„ë‹ˆë¼ ~í˜¸ì„  ìœ¼ë¡œ ë°ì´í„°ê°€ ë°”ë€Œì–´ ì •ì œë˜ì–´ìˆìŒ.
                    - ê²°ê³¼ ë°˜ì˜í•˜ì—¬ ìˆ˜ì •í•¨. 
                2024.06.11 by pdg :  ë””ë ‰í† ë¦¬ ë³€ê²½í•œí›„ì— subwayInfo.csv íŒŒì¼ì„ ì°¾ì„ìˆ˜ ì—†ë‹¤ëŠ” ì—ëŸ¬ê°€ëœ¸..
                    - ìƒëŒ€ê²½ë¡œë¥¼ ì¸ì‹í•  ìˆ˜ìˆë„ë¡ datapath ì„¤ì • ë³€ê²½ 
                
        """
        import pandas as pd
        import os

        # í˜„ì¬ íŒŒì¼(Functions.py)ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ í´ë” ê²½ë¡œë¥¼ ì°¾ëŠ”ë‹¤.
        module_dir = os.path.dirname(os.path.abspath(__file__))
        project_dir = os.path.dirname(module_dir)
        data_path = os.path.join(project_dir, 'Data', 'StationInfo.csv')
        
        # print("ì•„í•˜ ë¼ì¸ í…ŒìŠ¤íŠ¸ type : ",type(line),line)
        stations = pd.read_csv(data_path) ## ì—­ì •ë³´ csv 
        # print(stations['í˜¸ì„ '])
        target_line_stations = stations[stations['í˜¸ì„ ']==line] ## line select
        #print(target_line_stations)
        row = target_line_stations[station_name == target_line_stations['ì—­ì´ë¦„']]
        # print(f"{station_name}ì˜ ì—­ì‚¬ ì½”ë“œëŠ” {row['ì—­ì‚¬ì½”ë“œ'].values[0]}ì…ë‹ˆë‹¤")
        print("rowì˜ ë‚´ìš©: ",row.to_numpy())
        if len(row.to_numpy().tolist()) > 1:
            print('í™˜ìŠ¹ì—­ì…ë‹ˆë‹¤')
            print(f"{station_name}ì˜ ì—­ì‚¬ ì½”ë“œëŠ” {row['ì—­ì‚¬ì½”ë“œ']}ì…ë‹ˆë‹¤")
            return row['ì—­ì‚¬ì½”ë“œ'].tolist()
        if len(row.to_numpy().tolist())==0:
            print('ì°¾ì„ìˆ˜ ì—†ëŠ” ì—­ì…ë‹ˆë‹¤')
        if len(row.to_numpy().tolist())==1:
            print(f"ë‹¨ì¼ì—­ì…ë‹ˆë‹¤.{row['ì—­ì‚¬ì½”ë“œ'].tolist()}")
            return row['ì—­ì‚¬ì½”ë“œ'].values[0]
        
        print('ì–´ë””ì„œë˜ í˜¸ì¶œë˜ë‹ˆ?')
    def sdtation_inout_lmplot(mlTable, line, station_name, time_passenger):
        """
            # Description : train, targetë°ì´í„°ì— ëŒ€í•œ íšŒê·€ ëª¨ë¸ 
            # Date : 2024.06.07
            # Author : pdg
            # Detail:
                * mlTable : training + target column concated table 
                line, station_name : í˜¸ì„  ,ì´ë¦„ 
                time_passenger ('string): ì‹œê°„ëŒ€ ì´ë¦„ target colomn ì´ë¦„ 
                ex) 7í˜¸ì„ ', 'ì¤‘ê³¡', '08ì‹œì¸ì›'
                * Returns: - 
            # Updata:
                2024.06.07 by pdg :íšŒê·€í•¨ìˆ˜ í•¨ìˆ˜ ì—…ë°ì´íŠ¸  
        """
        
        import pandas as pd
        import matplotlib.pyplot as plt
        import seaborn as sns
        from sklearn.linear_model import LinearRegression
        from sklearn.metrics import r2_score
        # ì½”ë“œì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , ì„œë¹„ìŠ¤ë‚˜ ë‹¤ë¥¸ í´ë˜ìŠ¤ë“¤ì€ ì¸ì‹í•˜ì§€ ëª»í•´ì„œ ê·¸ëŒ€ë¡œ ë‚¨ê²¨ë‘ì—ˆìŠµë‹ˆë‹¤.
        code = Service.station_name_to_code(line, station_name)
        test = mlTable[mlTable['ì—­ì‚¬ì½”ë“œ'] == code]
        
        # ìˆ«ìë¡œ ëœ ìš”ì¼ì„ ìš”ì¼ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘
        day_mapping = {
            0: 'ì¼ìš”ì¼',
            1: 'ì›”ìš”ì¼',
            2: 'í™”ìš”ì¼',
            3: 'ìˆ˜ìš”ì¼',
            4: 'ëª©ìš”ì¼',
            5: 'ê¸ˆìš”ì¼',
            6: 'í† ìš”ì¼',
            7: 'ì¼ìš”ì¼'  # 0ê³¼ 7ì´ ëª¨ë‘ ì¼ìš”ì¼ì´ë¼ê³  ê°€ì •
        }

        # 'ìš”ì¼' ì»¬ëŸ¼ì„ ìš”ì¼ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘
        test['ìš”ì¼'] = test['ìš”ì¼'].map(day_mapping)
        
        # ìš”ì¼ë³„ë¡œ ìƒ‰ê¹”ì„ ì§€ì •í•˜ê¸° ìœ„í•´ íŒ”ë ˆíŠ¸ë¥¼ ì„¤ì •
        unique_days = test['ìš”ì¼'].unique()
        palette = sns.color_palette("hls", 8)

        day_to_color = dict(zip(unique_days, palette))
        # print(day_to_color)
        # DataFrameì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±
        regression_lines = []
        
        # ìš”ì¼ë³„ë¡œ í”Œë¡¯ì„ ë‚˜ëˆ„ê¸° ìœ„í•´ FacetGrid ì‚¬ìš©
        g = sns.FacetGrid(test, col='ìš”ì¼', col_wrap=4, height=4, aspect=1, palette=palette)
        g.map_dataframe(sns.scatterplot, 'ì£¼ì°¨', time_passenger, hue='ìš”ì¼', palette=palette)

        for ax in g.axes.flatten():
                day = ax.get_title().split('=')[-1].strip()
                day_data = test[test['ìš”ì¼'] == day]
                sns.regplot(
                    x='ì£¼ì°¨',
                    y=time_passenger,
                    data=day_data,
                    scatter=False,
                    ax=ax,
                    color=palette[list(day_mapping.values()).index(day)]
                )
                day_data = test[test['ìš”ì¼'] == day]
                # íšŒê·€ ëª¨ë¸ í•™ìŠµ
                X = day_data[['ì£¼ì°¨']]
                y = day_data[time_passenger]
                reg = LinearRegression().fit(X, y)
                
                # íšŒê·€ ëª¨ë¸ì˜ ê²°ì • ê³„ìˆ˜ (R-squared) ê³„ì‚°
                r2 = 1 - r2_score(y, reg.predict(X))
                
                # íšŒê·€ ëª¨ë¸ì˜ ê³„ìˆ˜ì™€ ì ˆí¸
                coef = reg.coef_[0]
                intercept = reg.intercept_
                
                # íšŒê·€ì‹ì„ ë¬¸ìì—´ë¡œ ì €ì¥
                equation = f'y = {coef:.2f}x + {intercept:.2f}'
                
                # íšŒê·€ ëª¨ë¸ì˜ ìˆ˜ì‹ì„ DataFrameì— ì¶”ê°€
                regression_lines.append({'ìš”ì¼': day, 'ê³„ìˆ˜': coef, 'ì ˆí¸': intercept, 'R2 ìŠ¤ì½”ì–´': r2})
                # íšŒê·€ ëª¨ë¸ì˜ ìˆ˜ì‹ í”Œë¡¯

                ax.text(0.5, 0.9, f'R2 Score: {r2:.2f}\n{equation}', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes, fontsize=10)
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        regression_df = pd.DataFrame(regression_lines)
        
        # ì œëª© ì„¤ì •
        g.set_titles(col_template="{col_name}")
        g.set_axis_labels('ì£¼ì°¨', 'ì¸ì›ìˆ˜(ë‹¨ìœ„ : ëª…)')
        title = f'{line} {station_name}ì—­ : ìš”ì¼ ë³„ {time_passenger} ì£¼ì°¨ vs ì¸ì›ìˆ˜'
        plt.subplots_adjust(top=0.9)
        g.fig.suptitle(title)
        
        plt.show()
        
        # DataFrame ë°˜í™˜
        return regression_df
    def regression_predict(mlTable,line, station_name, week_index, dayName_int,target_colName= '08ì‹œì¸ì›'):
        """
        # Description : train, targetë°ì´í„°ì— ëŒ€í•œ íšŒê·€ ëª¨ë¸  ì˜ˆì¸¡ 
        # Date : 2024.06.07
        # Author : pdg
        # Detail:
            * mlTable : training + target column concated table 
            line, station_name : í˜¸ì„  ,ì´ë¦„ 
            time_passenger ('string): ì‹œê°„ëŒ€ ì´ë¦„ target colomn ì´ë¦„ 
            ex) 7í˜¸ì„ ', 'ì¤‘ê³¡', '08ì‹œì¸ì›'
            * Returns: ì£¼ì°¨ 10ì— ì›”ìš”ì¼ 8ì‹œ ëŒ€í•œ íšŒê·€ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’
        # Updata:
            2024.06.07 by pdg :íšŒê·€í•¨ìˆ˜ í•¨ìˆ˜ ì—…ë°ì´íŠ¸  
            - ì‚¬ìš© ì˜ˆì‹œ : pred_result = regression_predict(test,'7í˜¸ì„ ', 'ì¤‘ê³¡',10,1,'08ì‹œì¸ì›')
        """
        print(line, station_name, week_index)
        from Project.HaruSijack.DataAnalysis.Module.Functions import Service
        test_code= Service.station_name_to_code(line,station_name)
        print(test_code)
        
        print(f'{line} {station_name}ì—­ [{test_code}] {week_index}ì£¼ì°¨ ìš”ì¼ ë³„ {target_colName} ')
        test_ì¤‘ê³¡ = mlTable[mlTable['ì—­ì‚¬ì½”ë“œ']== test_code]
        
        regression_df = Service.sdtation_inout_lmplot(mlTable, line, station_name, target_colName)
        regression_equation = regression_df.loc[regression_df.index[dayName_int]]  # ë§ˆì§€ë§‰ í–‰ì˜ íšŒê·€ì‹
        # íšŒê·€ì‹ì—ì„œ ê³„ìˆ˜ì™€ ì ˆí¸ ì¶”ì¶œ
        intercept = regression_equation['ì ˆí¸']
        slope = regression_equation['ê³„ìˆ˜']
        # ì£¼ì–´ì§„ ì£¼ì°¨ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ ê³„ì‚°
        prediction = intercept + slope * week_index
        print(f"ì£¼ì°¨ {week_index}ì— ì›”ìš”ì¼ 8ì‹œ ëŒ€í•œ íšŒê·€ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’:", prediction)
        target_table = test_ì¤‘ê³¡[test_ì¤‘ê³¡['ì£¼ì°¨']==week_index][['ìš”ì¼',target_colName]]
        print(" ----ì‹¤ì œ ì¸ì› ------")
        print(target_table.loc[target_table.index[dayName_int]])

        return prediction

### ë°ì´í„° ì‹ ë¢°ì„± íŒë‹¨ ê´€ë ¨ í•¨ìˆ˜
    def í˜¸ì„ ë‹¹ì„œë¹„ìŠ¤ë¶ˆê°€ì—­ì´ë¦„ì¶”ì¶œ(line,ìŠ¹í•˜ì°¨_ì—­ì •ë³´í…Œì´ë¸”, ë°°ì°¨ì—­ì •ë³´_í…Œì´ë¸”):
        """
        # ğŸ“Œ Description :  ìŠ¹í•˜ì°¨ ë°ì´í„°ì— ì¡´ì¬í•˜ì§€ì•ŠëŠ” ì„œë¹„ìŠ¤ë¶ˆê°€ ì—­ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•¨. 
        # ğŸ“Œ Date : 2024.06.09
        # ğŸ“Œ Author : pdg
        # ğŸ“Œ Detail:
            ğŸ”¸ line (int)
            ğŸ”¸ ìŠ¹í•˜ì°¨_ì—­ì •ë³´í…Œì´ë¸” (df)
            ğŸ”¸ ë°°ì°¨ì—­ì •ë³´_í…Œì´ë¸”(df)
            ğŸ”¸ Returns: ì„œë¹„ìŠ¤ë¶ˆê°€ ì—­ì˜ ë¦¬ìŠ¤íŠ¸
        # ğŸ“Œ Update:

        """

        result =[]
        try :
            ìŠ¹í•˜ì°¨_ì—­ì‚¬ì½”ë“œ = ìŠ¹í•˜ì°¨_ì—­ì •ë³´í…Œì´ë¸”[ìŠ¹í•˜ì°¨_ì—­ì •ë³´í…Œì´ë¸”['í˜¸ì„ ']==line]['ì—­ì‚¬ì½”ë“œ']
            ë°°ì°¨ì—­_ì—­ì‚¬ì½”ë“œ = ë°°ì°¨ì—­ì •ë³´_í…Œì´ë¸”[ë°°ì°¨ì—­ì •ë³´_í…Œì´ë¸”['í˜¸ì„ ']==line]['ì—­ì‚¬ì½”ë“œ']
            service_disable_station =list(map(int,list(set(ë°°ì°¨ì—­_ì—­ì‚¬ì½”ë“œ)- set(ìŠ¹í•˜ì°¨_ì—­ì‚¬ì½”ë“œ)))) ## service ë¶ˆê°€ ì§€ì—­ ë¦¬ìŠ¤íŠ¸ 
            print(service_disable_station)
            uniq_ë°°ì°¨=ë°°ì°¨ì—­ì •ë³´_í…Œì´ë¸”[['ì—­ì‚¬ì½”ë“œ','ì—­ì‚¬ëª…','í˜¸ì„ ']].drop_duplicates().reset_index(drop=True)
            target_line_subway= uniq_ë°°ì°¨[uniq_ë°°ì°¨['í˜¸ì„ ']==line]
            print(service_disable_station)
            if service_disable_station !=[]:
                print(Service.colored_text(f"â¬‡--{line}í˜¸ì„  ì„œë¹„ìŠ¤ë¶ˆê°€ ì—­ì‚¬ì½”ë“œ . ë° ì—­ì‚¬ëª…--â¬‡", 'red'))
                i = 0
                for idx, row in enumerate(target_line_subway.to_numpy()):
                    for j in service_disable_station:
                        if  row[0] == j :
                            print(f" {i+1}.{int(row[0])} {row[1]} ì—­")
                            result.append([int(row[0]), row[1], row[2]])
                            i +=1
                print("-"*20)
        except:
            pass
        finally :return result
        ''' í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì‹œ!!
        for i in range(1,8):
            _ = Service.í˜¸ì„ ë‹¹ì„œë¹„ìŠ¤ë¶ˆê°€ì—­ì´ë¦„ì¶”ì¶œ(i,station, subway_dispatch) 
        '''

### í†µí•© ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ feature table ì •ì œ 
    def from_StationInfo_csv_latlang_dispatchTable_merge(parent_dir):
        """
        # ğŸ“Œ Description : ê¸°ì´ˆì ì¸ ì—­ì •ë³´ë°ì´í„°(ì—­ì´ë¦„,ì—­ì½”ë“œ,í˜¸ì„ )ì— ìœ„ë„ê²½ë„ë°°ì°¨ì‹œê°„í‘œë¥¼ ë¨¸ì§€í•˜ëŠ” ì‘ì—…
        # ğŸ“Œ Date : 2024.06.09
        # ğŸ“Œ Author : pdg
        # ğŸ“Œ Detail:
            * StationInfo íŒŒì¼ì—ëŒ€í•œ ë°°ì°¨í…Œì´ë¸”ì„ ì œì‘ 
            ğŸ”¸ parent : /Users/forrestdpark/Desktop/PDG/Python_/Project/HaruSijack/DataAnalysis

            ğŸ”¸ Returns: -> Save files 
                table_merge_subwayInfo_dispatch í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ë¨¸ì§€í›„ ì €ì¥í•¨. 
                : 
        # ğŸ“Œ Update:

        """
        Service.Explaination('from_StationInfo_csv_latlang_dispatchTable_merge','ê¸°ì´ˆì ì¸ ì—­ì •ë³´ë°ì´í„°(ì—­ì´ë¦„,ì—­ì½”ë“œ,í˜¸ì„ )ì— ìœ„ë„ê²½ë„ë°°ì°¨ì‹œê°„í‘œë¥¼ ë¨¸ì§€í•˜ëŠ” ì‘ì—…')
        import pandas as pd, numpy as np, os
        ##ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•´ í•„ìš”í•œê²ƒ = feature table
        ## feature table ì„ ë§Œë“¤ê¸° ìœ„í•´ í•„ìš”í•œê²ƒ -> ì§€í•˜ì²  ì—­ì •ë³´(ì—­ì‚¬ì½”ë“œ,ì—­ì‚¬ì´ë¦„, í˜¸ì„ , ë°°ì°¨ì •ë³´) 
        # ì—­ì‚¬ ì •ë³´ ì •ì œíŒŒì¼ Fetch
        # ë…„ë„ë³„ë¡œ ì—­ì‚¬ì •ë³´(StationInfo_) ê°€ Data í´ë” ë‚´ì— ìˆë‹¤. 
        # ì´í´ë”ë¥¼ list dir í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ì½ì–´ë“¤ì—¬ì„œ ê°ë…„ë„ë³„ ì—­ì‚¬ì •ë³´ë¥¼ dicitionary ë¡œ ë³€ìˆ˜ì €ì¥í•œë‹¤. 
        StationInfo_dict = {}
        print(Service.colored_text("Parent Directory : "+parent_dir,'green'))
        for i in os.listdir(parent_dir):
            # print(i)
            file_order = 0 # file ìˆœì„œ 
            if i =='Data': # Data í´ë” ì´ë©´ ì‹¤í–‰ 
                print(Service.colored_text("  |-Data í´ë”ì—ì„œ ì—­ì‚¬ ì •ë³´ë¥¼ ê°€ì§„ StationInfo  csv íŒŒì¼ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.",'yellow'))
                for idx, filename in enumerate(os.listdir(os.path.join(parent_dir,i))):
                    # print(" |-",j)
                    if 'StationInfo' in filename: # Station info ë§Œ ì¶”ì¶œ
                        file_order += 1
                        print(f" {file_order}. -> ",filename)
                        key_name=filename.split(".csv")[0]
                        # print(key_name)
                        StationInfo_dict[f'{key_name}'] = pd.read_csv(os.path.join(parent_dir,i,filename))
        print(Service.colored_text("  >> ğŸ“Œ Data folder ì— ìˆëŠ” ë…„ë„ë³„ Station Info ë¥¼  StationInfo_dict ì— ì €ì¥í•©ë‹ˆë‹¤.", 'blue'))
        print("[[ğŸ”¹ğŸ”¹ğŸ”¹ StationInfo keys ê°’ ì •ë³´ğŸ”¹ğŸ”¹ğŸ”¹]]")
        for i in StationInfo_dict.keys():
            print("  |-",Service.colored_text(i,'cyan'))
        
        print(Service.colored_text("  >> ğŸ“Œ ê°ì—­ì—ì„œì˜ ìœ„ë„ê²½ë„ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ë°°ì°¨ì‹œê°„í‘œë¥¼ ë³‘í•©í•˜ì—¬ ì§€í•˜ì²  ë°°ì°¨ì‹œê°„ë°ì´í„°í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤.", 'blue'))
        for key in StationInfo_dict.keys():
            ## ì—­ì •ë³´ ë°ì´í„°ì˜  ì´ë¦„ (ex. StationInfo_18) 
            data_name = key
            print(Service.colored_text(f"âœ… {data_name} :ì—­ì‚¬ì •ë³´ \n",'yellow'),StationInfo_dict[data_name].head(3))
            latlng = pd.read_csv("../Data/seoul_subway_latlon_zenzen.csv")
            latlng.rename( {'ê³ ìœ ì—­ë²ˆí˜¸(ì™¸ë¶€ì—­ì½”ë“œ)':'ì—­ì‚¬ì½”ë“œ'}, inplace=True, axis=1)
            latlng.drop(['ì—­ëª…','í˜¸ì„ ','í™˜ìŠ¹ì—­ìˆ˜'], axis=1,inplace=True)
            print(Service.colored_text(f"âœ… {data_name} : ì—­ì‚¬ë³„ ìœ„ë„ê²½ë„ : \n",'yellow'),latlng.head(3))

            ## ìœ„ë„ ê²½ë„ ë°ì´í„° merge 
            StationInfo_dict[data_name] = pd.merge(StationInfo_dict[data_name],latlng, on='ì—­ì‚¬ì½”ë“œ',how='inner' )
            print(Service.colored_text('âœ… Merged data check(tail)','yellow'))
            print(StationInfo_dict[data_name].tail(3))

            # í˜¸ì„ ë³„ ë°°ì°¨ì‹œê°„ë°ì´í„°  ì €ì¥ 
            savefilename_indexName = data_name.split('StationInfo')[-1]
            line_ë°°ì¹˜_dict ={}
            for i in range(1,9):
                try:
                    line_ë°°ì¹˜_dict[f'{i}í˜¸ì„ '] = pd.read_csv(f'../Data/ì§€í•˜ì² ë°°ì°¨ì‹œê°„ë°ì´í„°/StationInfo{savefilename_indexName}_{i}_í˜¸ì„ ë°°ì°¨.csv')
                    line_ë°°ì¹˜_dict[f'{i}í˜¸ì„ '] = \
                        Service.table_merge_subwayInfo_dispatch(
                            StationInfo_dict[data_name],
                            line_ë°°ì¹˜_dict[f'{i}í˜¸ì„ '],
                            histPlot=False
                            )
                except: 
                    print(f"{key}ë°ì´í„°ì˜{i}í˜¸ì„ ì— ë¬¸ì œ ê°€ìˆìŠµë‹ˆë‹¤")
                    continue
            # line_ë°°ì¹˜_dict['7í˜¸ì„ '].tail()
        # return StationInfo_dict ## dictionary ë°˜í™˜ 
    def mlTableGen(subway_dict, save_mlTable_dict_fileName):
        """
                # ğŸ“Œ Description : ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ Feature table ìƒì„±, ë‚ ì§œë³„ ìŠ¹í•˜ì°¨ì •ë³´ì™€ ë°°ì°¨ì •ë³´, ë‚ ì§œì  íŠ¹ì§•ì„ ë³´ìœ í•œ í…Œì´ë¸” ìƒì„±
                # ğŸ“Œ Date : 2024.06.14
                # ğŸ“Œ Author : pdg
                # ğŸ“Œ Detail:
                    03-2.ë¨¸ì‹ ëŸ¬ë‹ í†µí•©.ipynb ì—ì„œ í™œìš©ë˜ëŠ” í•¨ìˆ˜ 
                    ìŠ¹í•˜ì°¨ ë°ì´í„° dictionaryì—ì„œ ìŠ¹í•˜ì°¨ ì¸ì› ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³  ë…„ë„ë³„ í˜¸ì„ ë³„ ë°°ì°¨ì‹œê°„í‘œë°ì´í„°ì™€ ì¡°í•©í•˜ì—¬
                    ë¨¸ì‹ ëŸ¬ë‹ì´ ëŒì•„ê°ˆìˆ˜ì‡ëŠ” Feature table ì„ ìƒì„±í•¨.
                    ğŸ”¸ Returns: -> Save files 

                # ğŸ“Œ Update:

        """
        import pandas as pd, numpy as np, os
        Service.Explaination('ml_Table_Generator','ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ Feature table ìƒì„±, ë‚ ì§œë³„ ìŠ¹í•˜ì°¨ì •ë³´ì™€ ë°°ì°¨ì •ë³´, ë‚ ì§œì  íŠ¹ì§•ì„ ë³´ìœ í•œ í…Œì´ë¸” ìƒì„±')
        # ì „ì²´í•™ìŠµë°ì´í„° ìƒì„± 
        # ê¸°ë³¸ ìŠ¹í•˜ì°¨ë°ì´í„°ì˜ ìŠ¹í•˜ì°¨ ì¹¼ëŸ¼ë“¤ì„ ë‹¤ì‹œ ì •ì œ í•´ì•¼í•¨. 
        mlTable_dict = {}
        for i,key in enumerate(subway_dict.keys()):
            print(Service.colored_text(f'ğŸ”¹ {i} key : {key}','cyan'))
            mlTable_dict[key]= Service.data_preprocessing_toAnalysis(subway_dict,key)

        print(Service.colored_text("########### ì •ì œëœ ë°ì´í„°ì—ì„œ Feature Engineering ì„ ì‹œì‘í•©ë‹ˆë‹¤ #################",'yellow'))

        for i,key in enumerate(mlTable_dict.keys()):
            print(Service.colored_text(f'ğŸ”¹ {i} key : {key}','cyan'))
            # print(Service.colored_text(f">> ğŸ“Œ{key}data ì˜ ìˆ˜ì†¡ì¼ì ì¹¼ëŸ¼ì—ì„œ ìš”ì¼(int)ì„ ì¶”ì¶œí•œë’¤ 4ë²ˆì§¸ ì¹¼ëŸ¼ìœ¼ë¡œ ì´ë™",'yellow'))
            print(Service.colored_text(f'ğŸ”¹ mlTable ì— ë‚ ì§œë¥¼ ì •ì œí•˜ì—¬ ë‚ ì§œê´€ë ¨ feature ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ','cyan'))
            mlTable_dict[key]= Service.dayToIntConvert(mlTable_dict[key], "ìˆ˜ì†¡ì¼ì")
            mlTable_dict[key] = Service.reorder_columns(mlTable_dict[key],col_name="ìš”ì¼",target_idx=4)
            ##ë‚ ì§œì—ì„œ ë…„ë„,ì›”, ì£¼ì°¨
            mlTable_dict[key] = Service.date_Divid_Add_YMW_cols(mlTable_dict[key] ,'ìˆ˜ì†¡ì¼ì')
            ## ë‚ ì§œì—ì„œ ê³µíœ´ì¼ ë°ì´í„° ì¶”ê°€
            mlTable_dict[key]= Service.holidaysToIntConvert(mlTable_dict[key],DateColName='ìˆ˜ì†¡ì¼ì')
            ## ìˆ˜ì†¡ì¼ì , ì—°ë²ˆ ì‚­ì œ ì‹œê°„ê´€ë ¨ë°ì´í„° ì•ìœ¼ë¡œ ì´ë™ 
            for idx, col in enumerate(["ë…„ë„","ì›”","ì£¼ì°¨","ê³µíœ´ì¼"]):
                mlTable_dict[key] =Service.reorder_columns(col_name=col,df=mlTable_dict[key] ,target_idx=idx)
            mlTable_dict[key]['ì£¼ì¤‘ì£¼ë§'] = ['SAT' if day in [5, 6] else 'DAY' for day in mlTable_dict[key]['ìš”ì¼']]
            mlTable_dict[key]=Service.reorder_columns(col_name='ì£¼ì¤‘ì£¼ë§',df= mlTable_dict[key],target_idx=4)

        # ì‹œê°„ëŒ€ ì¹¼ëŸ¼ ì´ë¦„ ë³€ê²½ ~ì‹œ ì¸ì›ìœ¼ë¡œ 
        print(Service.colored_text("ì‹œê°„ëŒ€ ì¹¼ëŸ¼ ì´ë¦„ ë³€ê²½ ~ì‹œ ì¸ì›ìœ¼ë¡œ",'yellow'))
        for key in  mlTable_dict.keys():
            colnamelist =mlTable_dict[key].columns.tolist()
            ì‹œê°„ëŒ€ì‹œì‘index=Service.indexFind(colnamelist,'06')[0]
            # print(*colnamelist[ì‹œê°„ëŒ€ì‹œì‘index:])
            for colname in colnamelist[ì‹œê°„ëŒ€ì‹œì‘index:]:
                # print(f'{colname[:2]}ì‹œì¸ì›')
                if '06ì‹œì´ì „' == colname:
                    mlTable_dict[key].rename({colname:f'05ì‹œì¸ì›'}, inplace=True, axis=1)    
                else:
                    mlTable_dict[key].rename({colname:f'{colname[:2]}ì‹œì¸ì›'}, inplace=True, axis=1)
        print(Service.colored_text("########### Feature Engineering ì™„ë£Œ #################",'yellow'))
        integrated_mltable_line_dict ={}
        # ë°°ì°¨ì‹œê°„í‘œëŠ” Line ë³„ë¡œë˜ì–´ìˆê¸°ë•Œë¬¸ì— ë‚˜ëˆ ì„œ ë¨¸ì‹ ëŸ¬ë‹ ë§Œë“¬... 
        for key in mlTable_dict.keys():

            data_name=key # 'subway19'
            print(Service.colored_text(f"#___ data name = {data_name}",'yellow'))
            savefilename_indexName = data_name.split('subway')[-1]
            mlTable=mlTable_dict[key]
            
            mlTable_line_dict  ={}
            for line in range(1,9):
                # print(mlTable[mlTable['í˜¸ì„ ']==line])
                try: 
                    mlt= mlTable[mlTable['í˜¸ì„ ']==line]
                    # print(mlt.columns)
                    line_ë°°ì¹˜ = pd.read_csv(f'../Data/ì§€í•˜ì² ë°°ì°¨ì‹œê°„ë°ì´í„°/StationInfo_{savefilename_indexName}_{i}_í˜¸ì„ ë°°ì°¨.csv')
                    mlTable_line_dict[f'{key}_{line}í˜¸ì„ ']= pd.merge(line_ë°°ì¹˜,mlt,on = ['ì—­ì‚¬ì½”ë“œ','ì£¼ì¤‘ì£¼ë§','í˜¸ì„ '])
                    
                except: continue
            # integrated_mltable_line_dict[f'{key}_line_dict']=mlTable_line_dict
            mlTable_dict[key]=mlTable_line_dict
        print(Service.colored_text("########### í˜¸ì„ ë³„ mlTable ìƒì„± ì™„ë£Œ #################",'yellow'))
        # return integrated_mltable_line_dict
        # return mlTable_dict
        ## ë°°ì°¨ ì‹œê°„ëŒ€ ì¹¼ëŸ¼ ì´ë¦„ ~ë°°ì°¨ë¡œ ë°”ê¾¸ê¸° 
        for key in mlTable_dict.keys():
            for line in mlTable_dict[key].keys():
                table = mlTable_dict[key][line]
                colnamelist = table.columns
                ë°°ì°¨StartIndex = Service.indexFind(colnamelist=colnamelist.tolist(),search_target_word='05')[0]
                ë°°ì°¨FinalIndex = Service.indexFind(colnamelist=colnamelist.tolist(),search_target_word='24')[0]
                for colname in colnamelist[ë°°ì°¨StartIndex:ë°°ì°¨FinalIndex+1]:
                    # print(f'{colname[:2]}ì‹œì¸ì›')
                    table.rename({colname:f'{colname[:2]}ë°°ì°¨'}, inplace=True, axis=1)
                mlTable_dict[key][line]=table
                print(mlTable_dict[key][line])
        print(Service.colored_text("###########ë°°ì°¨ ì‹œê°„ëŒ€ ì¹¼ëŸ¼ ì´ë¦„ ~ë°°ì°¨ë¡œ ë°”ê¾¸ê¸° ì™„ë£Œ #################",'yellow'))
        # print("#"*20)   
        # print(mlTable_dict)
        np.save(f'../Data/mlTables/mlTable_dict_{save_mlTable_dict_fileName}.npy',mlTable_dict, allow_pickle=True)
        return mlTable_dict
    def grid_search(X_train,X_test,y_train,y_test,params, reg = DecisionTreeRegressor(random_state=2)):
        from sklearn.model_selection import GridSearchCV
        import numpy as np
        params = {'max_depth':[None,2,3,4,6,8,10,20]}
        reg = DecisionTreeRegressor(random_state=2)
        grid_reg = GridSearchCV(reg,params, scoring='neg_mean_squared_error',
                                cv=5,
                                return_train_score=True,
                                n_jobs=-1
                                )
        grid_reg.fit(X_train,y_train)
        best_params= grid_reg.best_params_
        print("ìµœìƒì˜ ë§¤ê°œë³€ìˆ˜: ",best_params)
        best_score = np.sqrt(-grid_reg.best_score_)
        print(f"í›ˆë ¨ì ìˆ˜ : {best_score:.3f}")
        y_pred =grid_reg.predict(X_test)
        rmse_test = mean_squared_error(y_test,y_pred)**0.5
        print(f'í…ŒìŠ¤íŠ¸ ì ìˆ˜: {rmse_test:.3f}')

if __name__ == '__main__':  print("main stdart")
    



