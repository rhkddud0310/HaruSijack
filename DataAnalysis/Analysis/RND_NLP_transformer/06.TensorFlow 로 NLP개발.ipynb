{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ë„ì„œ : [tensorflow 2 ë¡œ ìì—°ì²˜ë¦¬]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "Tensorflow \n",
    "drop out\n",
    "Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mğŸ“Œ - PROGRAM START \n",
      "\t\u001b[0m\n",
      "\u001b[93mğŸ“Œ - MPS ì¥ì¹˜ë¥¼ ì§€ì› Build ì—¬ë¶€ : \u001b[0m True\n",
      "\u001b[93mğŸ“Œ - MPS ì¥ì¹˜ ì‚¬ìš©ê°€ëŠ¥ ì—¬ë¶€ : \u001b[0m True\n",
      "\u001b[93mğŸ“Œ - GPU ì‚¬ìš©Start\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Forrest Park's notion  ## Updated 2024.07.03\n",
    "### Service  Text Coloring option\n",
    "from Functions import Service as S\n",
    "def blue(str):return S.colored_text(str,'blue')\n",
    "def yellow(str):return S.colored_text(str,'yellow')\n",
    "def red(str):return S.colored_text(str,'red')\n",
    "def green(str):return S.colored_text(str,'green')\n",
    "def imd(str):return S.imd(green(str))\n",
    "## ìì—°ì–´ì²˜ë¦¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜ \n",
    "def NLPInstalls():\n",
    "    import subprocess,sys\n",
    "    import warnings ; warnings.filterwarnings('ignore')\n",
    "    # pipê°€ ì—†ìœ¼ë©´ pipë¥¼ ì„¤ì¹˜\n",
    "    try:import pip\n",
    "    except ImportError:\n",
    "        print(\"Install pip for python3\")\n",
    "        subprocess.call(['sudo', 'apt-get', 'install', 'python3-pip'])\n",
    "    \n",
    "    # tweepy ì—†ìœ¼ë©´ tweepy ì„¤ì¹˜\n",
    "    try:import tweepy        \n",
    "    except ModuleNotFoundError:\n",
    "        print(\"Install tweepy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'tweepy==3.10.0'])\n",
    "    finally:import tweepy \n",
    "    \n",
    "    # konlpy ì—†ìœ¼ë©´ konlpy ì„¤ì¹˜\n",
    "    try:import konlpy\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install konlpy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'konlpy'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # eunjeon ì—†ìœ¼ë©´ eunjeon ì„¤ì¹˜\n",
    "    try:import eunjeon\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install eunjeon : eunjeon\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'eunjeon'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # datasets ì—†ìœ¼ë©´ datasetsë¥¼ ì„¤ì¹˜\n",
    "    try:import datasets\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install datasets : datasets\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'datasets'])\n",
    "    finally:import datasets\n",
    "    \n",
    "    # pytorch ì—†ìœ¼ë©´ pytorch ì„¤ì¹˜\n",
    "    try:import torch\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install torch : pytorch\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'pytorch'])\n",
    "    finally:import torch\n",
    "    \n",
    "    # transformers ì—†ìœ¼ë©´ transformers ì„¤ì¹˜\n",
    "    try:import transformers\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install transformer : transformers\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'transformers'])\n",
    "    finally:import transformers\n",
    "        \n",
    "    # UMAP ì—†ìœ¼ë©´ UMAP ì„¤ì¹˜\n",
    "    try:import umap\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install umap : umap\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'umap'])\n",
    "    finally:import umap\n",
    "        \n",
    "    # UMAP ì—†ìœ¼ë©´ UMAP ì„¤ì¹˜\n",
    "    try:from umap import UMAP\n",
    "    except ImportError: \n",
    "        print(\"Install umap : umap-learn\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'umap-learn'])\n",
    "    finally:import umap\n",
    "   \n",
    "NLPInstalls()\n",
    "print(yellow(f\"ğŸ“Œ - PROGRAM START \\n\\t\"))\n",
    "## GPU setting (in MacOS)\n",
    "import torch\n",
    "print(yellow(f\"ğŸ“Œ - MPS ì¥ì¹˜ë¥¼ ì§€ì› Build ì—¬ë¶€ : \"),torch.backends.mps.is_built())\n",
    "print(yellow(f\"ğŸ“Œ - MPS ì¥ì¹˜ ì‚¬ìš©ê°€ëŠ¥ ì—¬ë¶€ : \"),torch.backends.mps.is_available())\n",
    "print(yellow(f\"ğŸ“Œ - GPU ì‚¬ìš©Start\"))\n",
    "# device = torch.device(\"mps\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#### Jupyter Basic Setting ####\n",
    "import pandas as pd,numpy as np\n",
    "import matplotlib.pyplot as plt,seaborn as sns  # ì‹œê°í™”\n",
    "import warnings; warnings.filterwarnings('ignore')  # ê²½ê³  ë¬´ì‹œ\n",
    "import sys,os \n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Tensor flow ê°„ë‹¨í•œ ìì—°ì–´ ì²˜ë¦¬ ì˜ˆì‹œ 01 page 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.legacy.preprocessing.text.Tokenizer object at 0x3209956d0>\n",
      "\u001b[93mğŸ“Œ - text =>sequences\u001b[0m\n",
      "[' ë„ˆ ì˜¤ëŠ˜ ì´ë» ë³´ì¸ë‹¤ => [4, 1, 5, 6]',\n",
      " 'ë‚˜ëŠ” ì˜¤ëŠ˜ ê¸°ë¶„ì´ ë”ëŸ¬ì›Œ  => [7, 1, 8, 9]',\n",
      " 'ëë‚´ì£¼ëŠ”ë°, ì¢‹ì€ ì¼ì´ ìˆë‚˜ë´ => [10, 2, 3, 11]',\n",
      " 'ë‚˜ ì¢‹ì€ ì¼ì´ ìƒê²¼ì–´ => [12, 2, 3, 13]',\n",
      " 'ì•„ ì˜¤ëŠ˜ ì§„ì§œ ì§œì¦ë‚˜ => [14, 1, 15, 16]',\n",
      " 'í™˜ìƒì ì¸ë°, ì •ë§ ì¢‹ì€ ê±° ê°™ì•„  => [17, 18, 2, 19, 20]']\n",
      "\u001b[93m\n",
      "ğŸ“Œ - word index\u001b[0m\n",
      "{'ê°™ì•„': 20,\n",
      " 'ê±°': 19,\n",
      " 'ê¸°ë¶„ì´': 8,\n",
      " 'ëë‚´ì£¼ëŠ”ë°': 10,\n",
      " 'ë‚˜': 12,\n",
      " 'ë‚˜ëŠ”': 7,\n",
      " 'ë„ˆ': 4,\n",
      " 'ë”ëŸ¬ì›Œ': 9,\n",
      " 'ë³´ì¸ë‹¤': 6,\n",
      " 'ìƒê²¼ì–´': 13,\n",
      " 'ì•„': 14,\n",
      " 'ì˜¤ëŠ˜': 1,\n",
      " 'ì´ë»': 5,\n",
      " 'ì¼ì´': 3,\n",
      " 'ìˆë‚˜ë´': 11,\n",
      " 'ì •ë§': 18,\n",
      " 'ì¢‹ì€': 2,\n",
      " 'ì§„ì§œ': 15,\n",
      " 'ì§œì¦ë‚˜': 16,\n",
      " 'í™˜ìƒì ì¸ë°': 17}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing \n",
    "\n",
    "\n",
    "samples = [' ë„ˆ ì˜¤ëŠ˜ ì´ë» ë³´ì¸ë‹¤',\n",
    "           'ë‚˜ëŠ” ì˜¤ëŠ˜ ê¸°ë¶„ì´ ë”ëŸ¬ì›Œ ',\n",
    "           'ëë‚´ì£¼ëŠ”ë°, ì¢‹ì€ ì¼ì´ ìˆë‚˜ë´',\n",
    "           'ë‚˜ ì¢‹ì€ ì¼ì´ ìƒê²¼ì–´',\n",
    "           'ì•„ ì˜¤ëŠ˜ ì§„ì§œ ì§œì¦ë‚˜',\n",
    "           'í™˜ìƒì ì¸ë°, ì •ë§ ì¢‹ì€ ê±° ê°™ì•„ ',\n",
    "           ]\n",
    "## labeling \n",
    "labels = [[1],[0],[1],[1],[0],[1]]\n",
    "## tokenize\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "print(yellow(f\"ğŸ“Œ - text =>sequences\"))\n",
    "pprint([(f\"{i} => {j}\") for i,j in zip(samples,sequences)])\n",
    "word_index = tokenizer.word_index\n",
    "print(yellow(f\"\\nğŸ“Œ - word index\"))\n",
    "pprint(word_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ì¶”ê°€ë¡œ ëª¨ë¸ êµ¬ì¶• ë° ëª¨ë¸ í•™ìŠµì— í”¼ìš”í•œ ë³€ìˆ˜ ì •ì˜ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_epochs = 100\n",
    "vocab_size =len(word_index) +1\n",
    "emb_size = 128\n",
    "hidden_dimension = 256\n",
    "output_dimension = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ë°ì´í„°ë¥¼ í†µê³¼ ì‹œí‚¬ ëª¨ë¸ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(vocab_size,emb_size,input_length= 4))\n",
    "model.add(layers.Lambda(lambda x: tf.reduce_mean(x,axis= 1)))\n",
    "model.add(layers.Dense(hidden_dimension, activation='relu'))\n",
    "model.add(layers.Dense(output_dimension,activation =\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
