{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### NLP chapter 3. Transformer deep 하게 이해하기.\n",
    "\n",
    "# 3.1 transformer architecture\n",
    "- 인코더 : 입력토큰의 시퀀스를 은닉상태 또는 문맥(context) 라 부르는 임베딩 벡터의 시퀀스로 반환\n",
    "- 디코더 :\" \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br><img src = \"https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F914ff162-e9aa-4454-80d2-30b702551154%2F099316f3-3caa-4843-83c2-8c85ecd87382%2FUntitled.png?table=block&id=52e74767-4875-4af9-aab4-571a9ecd0bb1&spaceId=914ff162-e9aa-4454-80d2-30b702551154&width=1710&userId=d72aebc7-576c-4f0e-9c69-1d5d32da7874&cache=v2\" width=\"500\" height=\"300\"/><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m📌 - PROGRAM START \n",
      "\t\u001b[0m\n",
      "\u001b[93m📌 - MPS 장치를 지원 Build 여부 : \u001b[0m True\n",
      "\u001b[93m📌 - MPS 장치 사용가능 여부 : \u001b[0m True\n",
      "\u001b[93m📌 - GPU 사용Start\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Forrest Park's notion  ## Updated 2024.07.03\n",
    "### Service  Text Coloring option\n",
    "from Functions import Service as S\n",
    "def blue(str):return S.colored_text(str,'blue')\n",
    "def yellow(str):return S.colored_text(str,'yellow')\n",
    "def red(str):return S.colored_text(str,'red')\n",
    "def green(str):return S.colored_text(str,'green')\n",
    "def imd(str):return S.imd(green(str))\n",
    "## 자연어처리 패키지 설치 \n",
    "def NLPInstalls():\n",
    "    import subprocess,sys\n",
    "    import warnings ; warnings.filterwarnings('ignore')\n",
    "    # pip가 없으면 pip를 설치\n",
    "    try:import pip\n",
    "    except ImportError:\n",
    "        print(\"Install pip for python3\")\n",
    "        subprocess.call(['sudo', 'apt-get', 'install', 'python3-pip'])\n",
    "    \n",
    "    # tweepy 없으면 tweepy 설치\n",
    "    try:import tweepy        \n",
    "    except ModuleNotFoundError:\n",
    "        print(\"Install tweepy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'tweepy==3.10.0'])\n",
    "    finally:import tweepy \n",
    "    \n",
    "    # konlpy 없으면 konlpy 설치\n",
    "    try:import konlpy\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install konlpy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'konlpy'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # eunjeon 없으면 eunjeon 설치\n",
    "    try:import eunjeon\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install eunjeon : eunjeon\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'eunjeon'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # datasets 없으면 datasets를 설치\n",
    "    try:import datasets\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install datasets : datasets\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'datasets'])\n",
    "    finally:import datasets\n",
    "    \n",
    "    # pytorch 없으면 pytorch 설치\n",
    "    try:import torch\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install torch : pytorch\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'pytorch'])\n",
    "    finally:import torch\n",
    "    \n",
    "    # transformers 없으면 transformers 설치\n",
    "    try:import transformers\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install transformer : transformers\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'transformers'])\n",
    "    finally:import transformers\n",
    "        \n",
    "    # UMAP 없으면 UMAP 설치\n",
    "    try:import umap\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install umap : umap\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'umap'])\n",
    "    finally:import umap\n",
    "        \n",
    "    # UMAP 없으면 UMAP 설치\n",
    "    try:from umap import UMAP\n",
    "    except ImportError: \n",
    "        print(\"Install umap : umap-learn\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'umap-learn'])\n",
    "    finally:import umap\n",
    "NLPInstalls()\n",
    "print(yellow(f\"📌 - PROGRAM START \\n\\t\"))\n",
    "## GPU setting (in MacOS)\n",
    "import torch\n",
    "print(yellow(f\"📌 - MPS 장치를 지원 Build 여부 : \"),torch.backends.mps.is_built())\n",
    "print(yellow(f\"📌 - MPS 장치 사용가능 여부 : \"),torch.backends.mps.is_available())\n",
    "print(yellow(f\"📌 - GPU 사용Start\"))\n",
    "# device = torch.device(\"mps\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#### Jupyter Basic Setting ####\n",
    "import pandas as pd,numpy as np\n",
    "import matplotlib.pyplot as plt,seaborn as sns  # 시각화\n",
    "import warnings; warnings.filterwarnings('ignore')  # 경고 무시\n",
    "import sys,os \n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<br><img src = \"https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F914ff162-e9aa-4454-80d2-30b702551154%2F099316f3-3caa-4843-83c2-8c85ecd87382%2FUntitled.png?table=block&id=52e74767-4875-4af9-aab4-571a9ecd0bb1&spaceId=914ff162-e9aa-4454-80d2-30b702551154&width=1710&userId=d72aebc7-576c-4f0e-9c69-1d5d32da7874&cache=v2\" width=\"500\" height=\"300\"/><br>\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "#<img src = \"\" width=\"300\" height=\"300\"/><br>\n",
    "def imd(image_address,width =500, height=300):\n",
    "    print(f'<br><img src = \"{image_address}\" width=\"{width}\" height=\"{height}\"/><br>')\n",
    "    \n",
    "#imd(\"https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F914ff162-e9aa-4454-80d2-30b702551154%2F099316f3-3caa-4843-83c2-8c85ecd87382%2FUntitled.png?table=block&id=52e74767-4875-4af9-aab4-571a9ecd0bb1&spaceId=914ff162-e9aa-4454-80d2-30b702551154&width=1710&userId=d72aebc7-576c-4f0e-9c69-1d5d32da7874&cache=v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Transformer 의 유형\n",
    "- 인코더 유형 : \n",
    "    * 텍스트 시퀀스 입력을 풍부한 수치표현으로 변환 \n",
    "    * 텍스트 분류나 개체명 인식 같은 작업에 잘맞음. \n",
    "    * Bert, RoBert\n",
    "- 디코더 유형 :\n",
    "    * 시작 텍스트가 주어지면 가장 가능성 있는 다음 단어를 반복해 예측하는 식으로 시퀀스 자동완성\n",
    "    * GPT , causal attention, autoregressive attention\n",
    "    * 한 토큰에 대해 계산한 표현은 오직 왼쪽 문맥에 따라 달라짐. \n",
    "\n",
    "- 인코더-디코더 유형: \n",
    "    * 한텍스트의 시퀀스를 다른 시퀀스로 매핑하는 복잡한 모델링에 사용 \n",
    "    * 기계번역과 요약작업에 적합. \n",
    "    * BART, T5 모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.2 인코더\n",
    ": 인코더층은 임베딩 시퀀스를 받아 다음 두 층에 통과시킨다.      \n",
    ": 임베딩이란 자연어처리에서 사람이 쓰는 자연어를 기계가 이해할 수 있도록 숫자형태인 vector로 바꾸는 과정 혹은 일련의 전체 과정을 의미\n",
    "- multihead self attention layer\n",
    "- fully connected feed forward layer (각각의 입력 임베딩에 적용되는 완전 연결 피드 포워드층 )\n",
    "<br><img src = \"https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F914ff162-e9aa-4454-80d2-30b702551154%2F09d456af-00b9-4ab3-8a84-7fd2c463d27e%2FUntitled.png?table=block&id=eec10382-9a45-4f26-ae3f-9787fa035e64&spaceId=914ff162-e9aa-4454-80d2-30b702551154&width=1710&userId=d72aebc7-576c-4f0e-9c69-1d5d32da7874&cache=v2\" width=\"500\" height=\"300\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### 3.2.1  self attention \n",
    "- 텍스 시퀀스에서 원소는 토큰 임베딩임. 각 토큰은 고정차원의 벡터에 매핑됨. \n",
    "- 각 토큰에 대해 고정된 임베딩을 사용하는 대신 전체 시퀀스를 사용해  각 임베딩의 가중평균을 계산하는것이 셀프 어텐션의 기본 개념 \n",
    "\n",
    "- 토큰임베딩 시퀀스 x1,x2,...,xn -> 새로운 임베딩 시퀀스 x'1,x'2,...\n",
    "- 계수 wji -> 어텐션 가중치  전체합은 1 \n",
    "\n",
    "- 토큰 임베딩의 평균을 구하는 이유?\n",
    "    : 문맥 고려 임베딩 (contextualized embadding)\n",
    "    * ELMo 언어 모델에서 시작 됨. \n",
    "    <br><img src = \"https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F914ff162-e9aa-4454-80d2-30b702551154%2Fd8492d8f-8127-4900-a162-e70dc7f2ce84%2FUntitled.png?table=block&id=61f37201-01a3-4515-bea4-161b2153733c&spaceId=914ff162-e9aa-4454-80d2-30b702551154&width=1710&userId=d72aebc7-576c-4f0e-9c69-1d5d32da7874&cache=v2\" width=\"500\" height=\"300\"/><br>\n",
    "\n",
    "\n",
    "### 스케일드 점곱 어텐션 \n",
    "- scaled dot-product attention \n",
    ": \n",
    "- 각 토큰 임베딩을 쿼리(query) , 키(Key), 값(Value) 세개의 벡터로 투영합니다. \n",
    "- 어텐션 점수를 계산 , 유사도 함수를 사용해 쿼리 벡터와 키벡터가 서로 얼마나 관련되는지 계산\n",
    "attention score = 어텐션 점수 행렬 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bertviz\n",
    "from transformers import AutoTokenizer\n",
    "from bertviz.transformers_neuron_view import BertModel\n",
    "from bertviz.neuron_view import show\n",
    "\n",
    "\n",
    "model_ckpt =\"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = BertModel.from_pretrained(model_ckpt)\n",
    "text = 'time flies like an arrow'\n",
    "show(model, 'bert', tokenizer, text, display_mode='light', layer=0, head=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, add_special_token \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m inputs\u001b[38;5;241m.\u001b[39minput_ids\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensor = 'pt', add_special_token =False)\n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "token_emb = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "token_emb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
