{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd \n",
    "import re\n",
    "import tensorflow as tf\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"NewsData/경제_20240704_15시07분.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data2 = data.copy() # data2에 data 복제\n",
    "data2.head()\n",
    "data2.tail()\n",
    "\n",
    "newContent = []\n",
    "\n",
    "# \\n, \\t 불필요한 내용 제거를 위한 함수\n",
    "def pad_punctuation(s):\n",
    "    s = re.sub(r'\\n', '', s)\n",
    "    s = re.sub(r'\\t', '', s)\n",
    "    s = re.sub(r'\\[', '', s)\n",
    "    s = re.sub(r'\\]', '', s)\n",
    "    s = re.sub(' +', ' ', s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "# for문 돌리면서 기호 제거 \n",
    "for i in data2['content'] :\n",
    "    newContent.append(pad_punctuation(i))\n",
    "\n",
    "\n",
    "# 일단은 df에 제거된 newContent리스트 추가 \n",
    "data2['newContent'] = newContent\n",
    "data2.head()\n",
    "\n",
    "data2['newContent'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.tail()\n",
    "data2['newContent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델이 너무 무거워서 돌리는데 시간이 오래걸림 \n",
    "\n",
    "# import os\n",
    "# import torch\n",
    "# from transformers import MarianMTModel, MarianTokenizer\n",
    "# import pandas as pd  # data2가 DataFrame이라고 가정합니다\n",
    "\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
    "# model = MarianMTModel.from_pretrained(model_name).to(device)\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# def translate_chunk(text):\n",
    "#     encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "#     input_ids = encoded.input_ids.to(device)\n",
    "#     attention_mask = encoded.attention_mask.to(device)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         output = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=512)\n",
    "    \n",
    "#     return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# def translate_ko_to_en(text):\n",
    "#     sentences = text.split('.')\n",
    "#     translated_sentences = []\n",
    "\n",
    "#     for sentence in sentences:\n",
    "#         if sentence.strip():  # 빈 문장 제외\n",
    "#             translated = translate_chunk(sentence.strip())\n",
    "#             translated_sentences.append(translated)\n",
    "\n",
    "#     return ' '.join(translated_sentences)\n",
    "\n",
    "# # data2['newContent']의 각 항목을 번역하고 결과를 리스트에 저장\n",
    "# translated_list = []\n",
    "# for content in data2['newContent']:\n",
    "#     translated = translate_ko_to_en(content)\n",
    "#     translated_list.append(translated)\n",
    "#     print(f\"Original: {content[:50]}...\")  # 원문의 처음 50자만 출력\n",
    "#     print(f\"Translated: {translated[:50]}...\")  # 번역문의 처음 50자만 출력\n",
    "#     print(\"---\")\n",
    "\n",
    "# # 번역 결과를 DataFrame에 새로운 열로 추가\n",
    "# data2['translated_content'] = translated_list\n",
    "\n",
    "# # 결과 확인\n",
    "# print(data2[['newContent', 'translated_content']])\n",
    "\n",
    "# # 결과를 CSV 파일로 저장 (선택사항)\n",
    "# # data2.to_csv('translated_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
    "# model = MarianMTModel.from_pretrained(model_name).to(device)\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# def translate_chunk(text):\n",
    "#     encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "#     input_ids = encoded.input_ids.to(device)\n",
    "#     attention_mask = encoded.attention_mask.to(device)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         output = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=512)\n",
    "    \n",
    "#     return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# def translate_ko_to_en(text):\n",
    "#     # 텍스트를 문장으로 분리 -> model의 번역 글자 수 제한을 피하기 위한 방법임\n",
    "#     sentences = text.split('.')\n",
    "#     translated_sentences = []\n",
    "\n",
    "#     for sentence in sentences:\n",
    "#         if sentence.strip():  # 빈 문장 제외\n",
    "#             translated = translate_chunk(sentence.strip())\n",
    "#             translated_sentences.append(translated)\n",
    "\n",
    "#     return ' '.join(translated_sentences)\n",
    "\n",
    "# # 사용 예시\n",
    "# korean_text = \"\"\"\n",
    "# [서울=뉴시스] 추상철 기자 = 20일 오후 서울 시내 상가에 임대문의 게시물이 부착돼 있다. 소상공인의 폐업으로 인한 '노란우산 공제금' 지급액이 크게 늘고 있는 것으로 나타났다. 2024.05.20. scchoo@newsis.com규제합리화 방안 추진 및 사회안전망 가입독려소상공인의 영업환경 개선을 위한 규제 합리화 방안도 도입한다. 소상공인의 금융접근성 개선을 위해선 기존에 사업주의 신용 또는 담보 중심으로 평가하던 신용평가체제를 매출액 등 사업장 정보 중심으로 개편해 개인사업자의 자금 조달을 원활하게 돕는다는 구상이다.또 개인사업자에 대한 신용평가를 고도화하기 위해 다양한 공공정보를 제공하기로 했다. 현재 국세청의 소득세 표본자료에는 근로소득세 15개 항목, 종합소득세 관련 정보 18개 항목을 제공하는데 이를 확대한다는 계획이다. 이외에도 ▲소매상인의 비축물가 판매 허용 ▲소상공인 대상 도로점용료 25% 감면 ▲무료 법률지원 서비스 대상 확대 ▲간이과세자 매출 기준 확대 및 수수료 감면 등을 통해 영업환경을 개선해 나간다는 방침이다. 두터운 생계안전망 구축을 위해선 노란우산공제, 고용보험 등 사회안전망 가입을 독려한다. 노란우산공제 납입부금에 대해 소득공제 한도를 연간 600만원으로 상향 조정하고 고용보험료 지원신청 절차를 간소화해 가입률을 높인다.\n",
    "# \"\"\"\n",
    "\n",
    "# translated_text = translate_ko_to_en(korean_text)\n",
    "\n",
    "# print(\"원문:\", korean_text)\n",
    "# print(\"번역:\", translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# # \n",
    "# model_id= \"pulpilisory/distilbert-base-uncased-finetuned-emotion\"\n",
    "# classifier = pipeline(\"text-classification\", model = model_id)\n",
    "# # 0 Greys sadness\n",
    "# # 1 Blues joy\n",
    "# # 2 Oranges love\n",
    "# # 3 Reds anger\n",
    "# # 4 Purples fear\n",
    "# # 5 Greens surprise\n",
    "# #'韓 경제침탈 주도' 얼굴 박힌 1만엔 신권, 일본에 풀렸다\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# custom_tweet=translated_text\n",
    "# preds = classifier(custom_tweet,return_all_scores=True)\n",
    "# preds_df = pd.DataFrame(preds[0])\n",
    "# labels = [i for i in range(1,7)]\n",
    "# print(preds_df)\n",
    "# plt.bar(labels, 100*preds_df['score'], color ='C0')\n",
    "# plt.title(f\"{custom_tweet}\")\n",
    "# plt.ylabel(\"Class probability (%)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 감정 분석 모델 설정\n",
    "model_id = \"pulpilisory/distilbert-base-uncased-finetuned-emotion\"\n",
    "classifier = pipeline(\"text-classification\", model=model_id, max_length=512, truncation=True)\n",
    "\n",
    "# 감정 분석 함수\n",
    "def analyze_emotion(text):\n",
    "    # 텍스트를 512 토큰 단위로 나누기\n",
    "    chunks = [text[i:i+512] for i in range(0, len(text), 512)]\n",
    "    results = []\n",
    "    # 512토큰으로 나눈 텍스트 감정분류\n",
    "    for chunk in chunks:\n",
    "        preds = classifier(chunk, return_all_scores=True)[0]\n",
    "        results.append({pred['label']: pred['score'] for pred in preds})\n",
    "    \n",
    "    # 각 레이블에 대한 평균 점수 계산(chunk로 나눈 점수를 평균화 하는거)\n",
    "    avg_results = {}\n",
    "    for label in results[0].keys():\n",
    "        avg_results[label] = sum(result[label] for result in results) / len(results)\n",
    "    \n",
    "    return avg_results\n",
    "\n",
    "# 데이터 로드 (예시, 실제 데이터에 맞게 수정하세요)\n",
    "# data2 = pd.read_csv('your_translated_data.csv')\n",
    "\n",
    "# 감정 분석 실행 및 결과 추가(DataFrame에 추가 )\n",
    "emotion_results = []\n",
    "for text in tqdm(data2['translated_content'], desc=\"Analyzing emotions\"):\n",
    "    try:\n",
    "        result = analyze_emotion(text)\n",
    "        emotion_results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text[:50]}... Error: {str(e)}\")\n",
    "        emotion_results.append({label: 0 for label in ['LABEL_0', 'LABEL_1', 'LABEL_2', 'LABEL_3', 'LABEL_4', 'LABEL_5']})\n",
    "\n",
    "# 감정 분석 결과를 DataFrame에 새로운 열로 추가\n",
    "for label in ['LABEL_0', 'LABEL_1', 'LABEL_2', 'LABEL_3', 'LABEL_4', 'LABEL_5']:\n",
    "    data2[f'emotion_{label}'] = [result[label] for result in emotion_results]\n",
    "\n",
    "# 결과 확인\n",
    "print(data2[['translated_content'] + [f'emotion_LABEL_{i}' for i in range(6)]].head())\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "# data2.to_csv('emotion_analyzed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/3 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 3/3 [36:04<00:00, 721.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          newContent  \\\n",
      "0  월요일 밤 귀갓길 덮친 역주행 차량'급발진' 아닌 정황…스키드마크 혼선사고 사흘만에...   \n",
      "1  \"지나친 자신감에 부주의·태만…75세 미만도 면허 갱신 때 교육 필요\"안전펜스 설치...   \n",
      "2  음주 단속 안내판/사진=연합뉴스4번째 음주운전을 하다 신호를 위반해 교통사고를 낸 ...   \n",
      "3  1일 밤 서울 중구 시청역 부근에서 한 남성이 몰던 차가 인도로 돌진해 최소 15명...   \n",
      "4  이 사진은 기사내용과 관련이 없습니다. /TV조선 방송화면 캡처작년 기준 65세 이...   \n",
      "\n",
      "                                  translated_content   sadness       joy  \\\n",
      "0  On Monday night, shortly after the death of an...  0.374782  0.090533   \n",
      "1  An average of more than 156 percent of drivers...  0.506792  0.069327   \n",
      "2  A drunk-in-a-divorced driver, a 40-year-old dr...  0.369596  0.032880   \n",
      "3  One night in Seoul’s mid-Court Office, a man w...  0.195954  0.047232   \n",
      "4  According to an average of 651% of drivers age...  0.745798  0.032878   \n",
      "\n",
      "       love     anger      fear  surprise  \n",
      "0  0.021096  0.318191  0.165324  0.030073  \n",
      "1  0.018666  0.153711  0.232517  0.018986  \n",
      "2  0.014931  0.524553  0.045994  0.012046  \n",
      "3  0.018428  0.571343  0.145797  0.021246  \n",
      "4  0.011483  0.095116  0.100908  0.013817  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# csv에 있는 파일을 불러와서 번역후 감정분류하고 DataFrame에 추가하고 결과를 csv로 저장하는 코드(번역, 감정분류의 토큰 수가 작아서 나눠서 진행)\n",
    "import os\n",
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer, pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "data = pd.read_csv(\"NewsData/사고_20240707_16시03분.csv\")\n",
    "data2 = data.copy() # data2에 data 복제\n",
    "data2.head()\n",
    "data2.tail()\n",
    "\n",
    "newContent = []\n",
    "\n",
    "# \\n, \\t 불필요한 내용 제거를 위한 함수\n",
    "def pad_punctuation(s):\n",
    "    s = re.sub(r'\\n', '', s)\n",
    "    s = re.sub(r'\\t', '', s)\n",
    "    s = re.sub(r'\\[', '', s)\n",
    "    s = re.sub(r'\\]', '', s)\n",
    "    s = re.sub(' +', ' ', s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "# for문 돌리면서 기호 제거 \n",
    "for i in data2['content'] :\n",
    "    newContent.append(pad_punctuation(i))\n",
    "\n",
    "\n",
    "# 일단은 df에 제거된 newContent리스트 추가 \n",
    "data2['newContent'] = newContent\n",
    "\n",
    "\n",
    "data2['newContent'][0]\n",
    "# 주석필요\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 번역 모델 설정\n",
    "translate_model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
    "translate_model = MarianMTModel.from_pretrained(translate_model_name).to(device)\n",
    "translate_tokenizer = MarianTokenizer.from_pretrained(translate_model_name)\n",
    "\n",
    "# 감정 분석 모델 설정\n",
    "emotion_model_id = \"pulpilisory/distilbert-base-uncased-finetuned-emotion\"\n",
    "classifier = pipeline(\"text-classification\", model=emotion_model_id, device=device)\n",
    "\n",
    "# 번역의 최대 토큰수가 512 라서 512 이상 되는 기사들은 512 토큰으로 잘라서 번역함\n",
    "def translate_batch(texts):\n",
    "    encoded = translate_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    input_ids = encoded.input_ids.to(device)\n",
    "    attention_mask = encoded.attention_mask.to(device)\n",
    "    ## 그래디언트 저장 안하게 하기 Autograd(미분) 비활성화 코드 -> 속도를 위해 사용 \n",
    "    with torch.no_grad():\n",
    "        outputs = translate_model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=512)\n",
    "    \n",
    "    return [translate_tokenizer.decode(out, skip_special_tokens=True) for out in outputs]\n",
    "# 번역모델( \n",
    "def translate_and_analyze(texts, batch_size=32):\n",
    "    translated_texts = []\n",
    "    emotion_results = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        \n",
    "        # 번역\n",
    "        translated_batch = translate_batch(batch)\n",
    "        translated_texts.extend(translated_batch)\n",
    "        \n",
    "        # 감정 분석\n",
    "        for text in translated_batch:\n",
    "            try:\n",
    "                preds = classifier(text, return_all_scores=True)[0]\n",
    "                emotion_results.append({pred['label']: pred['score'] for pred in preds})\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing text: {text[:50]}... Error: {str(e)}\")\n",
    "                emotion_results.append({f'LABEL_{i}': 0 for i in range(6)})\n",
    "    \n",
    "    return translated_texts, emotion_results\n",
    "\n",
    "# 데이터 로드 (예시, 실제 데이터에 맞게 수정하세요)\n",
    "# data2 = pd.read_csv('your_data.csv')\n",
    "\n",
    "# 번역 및 감정 분석 실행\n",
    "translated_texts, emotion_results = translate_and_analyze(data2['newContent'].tolist())\n",
    "# 0 Greys sadness\n",
    "# 1 Blues joy\n",
    "# 2 Oranges love\n",
    "# 3 Reds anger\n",
    "# 4 Purples fear\n",
    "# 5 Greens surprise\n",
    "# 감정 레이블 매핑\n",
    "label_to_emotion = {\n",
    "    'LABEL_0': 'sadness',\n",
    "    'LABEL_1': 'joy',\n",
    "    'LABEL_2': 'love',\n",
    "    'LABEL_3': 'anger',\n",
    "    'LABEL_4': 'fear',\n",
    "    'LABEL_5': 'surprise'\n",
    "}\n",
    "\n",
    "# 번역 결과 및 감정 분석 결과를 DataFrame에 추가\n",
    "data2['translated_content'] = translated_texts\n",
    "for label, emotion in label_to_emotion.items():\n",
    "    data2[emotion] = [result[label] for result in emotion_results]\n",
    "\n",
    "# 결과 확인\n",
    "print(data2[['newContent', 'translated_content'] + list(label_to_emotion.values())].head())\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "data2.to_csv('translated_and_emotion_analyzed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "      <th>newContent</th>\n",
       "      <th>translated_content</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-07 06:00:00</td>\n",
       "      <td>'시청 역주행 사고' 주요장면…급발진 어긋나는 정황들</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/003/001...</td>\n",
       "      <td>[\\n월요일 밤 귀갓길 덮친 역주행 차량'급발진' 아닌 정황…스키드마크 혼선사고 사...</td>\n",
       "      <td>월요일 밤 귀갓길 덮친 역주행 차량'급발진' 아닌 정황…스키드마크 혼선사고 사흘만에...</td>\n",
       "      <td>On Monday night, shortly after the death of an...</td>\n",
       "      <td>0.374782</td>\n",
       "      <td>0.090533</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.318191</td>\n",
       "      <td>0.165324</td>\n",
       "      <td>0.030073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-07 07:40:01</td>\n",
       "      <td>베테랑 운전자가 초보보다 사고 더 많이 낸다…'15년 이상' 60%</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/001/001...</td>\n",
       "      <td>[\\n\"지나친 자신감에 부주의·태만…75세 미만도 면허 갱신 때 교육 필요\"\\n\\n...</td>\n",
       "      <td>\"지나친 자신감에 부주의·태만…75세 미만도 면허 갱신 때 교육 필요\"안전펜스 설치...</td>\n",
       "      <td>An average of more than 156 percent of drivers...</td>\n",
       "      <td>0.506792</td>\n",
       "      <td>0.069327</td>\n",
       "      <td>0.018666</td>\n",
       "      <td>0.153711</td>\n",
       "      <td>0.232517</td>\n",
       "      <td>0.018986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-07 09:13:07</td>\n",
       "      <td>벌써 4번째 음주운전…신호 위반해 사고낸 40대 징역 1년</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/057/000...</td>\n",
       "      <td>[\\n\\n\\n\\n\\n음주 단속 안내판/사진=연합뉴스4번째 음주운전을 하다 신호를 위...</td>\n",
       "      <td>음주 단속 안내판/사진=연합뉴스4번째 음주운전을 하다 신호를 위반해 교통사고를 낸 ...</td>\n",
       "      <td>A drunk-in-a-divorced driver, a 40-year-old dr...</td>\n",
       "      <td>0.369596</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.014931</td>\n",
       "      <td>0.524553</td>\n",
       "      <td>0.045994</td>\n",
       "      <td>0.012046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-07 08:54:01</td>\n",
       "      <td>시청 사고 유족에게 80만원 청구서…\"시신 운구, 현장 수습비 명목\"</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/421/000...</td>\n",
       "      <td>[\\n\\n\\n\\n\\n1일 밤 서울 중구 시청역 부근에서 한 남성이 몰던 차가 인도로...</td>\n",
       "      <td>1일 밤 서울 중구 시청역 부근에서 한 남성이 몰던 차가 인도로 돌진해 최소 15명...</td>\n",
       "      <td>One night in Seoul’s mid-Court Office, a man w...</td>\n",
       "      <td>0.195954</td>\n",
       "      <td>0.047232</td>\n",
       "      <td>0.018428</td>\n",
       "      <td>0.571343</td>\n",
       "      <td>0.145797</td>\n",
       "      <td>0.021246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-07 09:58:20</td>\n",
       "      <td>고령 운전자, 사고 13% 더 내…피해자 중상 비율도 높아</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/448/000...</td>\n",
       "      <td>[\\n\\n\\n\\n\\n이 사진은 기사내용과 관련이 없습니다. /TV조선 방송화면 캡처...</td>\n",
       "      <td>이 사진은 기사내용과 관련이 없습니다. /TV조선 방송화면 캡처작년 기준 65세 이...</td>\n",
       "      <td>According to an average of 651% of drivers age...</td>\n",
       "      <td>0.745798</td>\n",
       "      <td>0.032878</td>\n",
       "      <td>0.011483</td>\n",
       "      <td>0.095116</td>\n",
       "      <td>0.100908</td>\n",
       "      <td>0.013817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                   title  \\\n",
       "0  2024-07-07 06:00:00           '시청 역주행 사고' 주요장면…급발진 어긋나는 정황들   \n",
       "1  2024-07-07 07:40:01   베테랑 운전자가 초보보다 사고 더 많이 낸다…'15년 이상' 60%   \n",
       "2  2024-07-07 09:13:07        벌써 4번째 음주운전…신호 위반해 사고낸 40대 징역 1년   \n",
       "3  2024-07-07 08:54:01  시청 사고 유족에게 80만원 청구서…\"시신 운구, 현장 수습비 명목\"   \n",
       "4  2024-07-07 09:58:20        고령 운전자, 사고 13% 더 내…피해자 중상 비율도 높아   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://n.news.naver.com/mnews/article/003/001...   \n",
       "1  https://n.news.naver.com/mnews/article/001/001...   \n",
       "2  https://n.news.naver.com/mnews/article/057/000...   \n",
       "3  https://n.news.naver.com/mnews/article/421/000...   \n",
       "4  https://n.news.naver.com/mnews/article/448/000...   \n",
       "\n",
       "                                             content  \\\n",
       "0  [\\n월요일 밤 귀갓길 덮친 역주행 차량'급발진' 아닌 정황…스키드마크 혼선사고 사...   \n",
       "1  [\\n\"지나친 자신감에 부주의·태만…75세 미만도 면허 갱신 때 교육 필요\"\\n\\n...   \n",
       "2  [\\n\\n\\n\\n\\n음주 단속 안내판/사진=연합뉴스4번째 음주운전을 하다 신호를 위...   \n",
       "3  [\\n\\n\\n\\n\\n1일 밤 서울 중구 시청역 부근에서 한 남성이 몰던 차가 인도로...   \n",
       "4  [\\n\\n\\n\\n\\n이 사진은 기사내용과 관련이 없습니다. /TV조선 방송화면 캡처...   \n",
       "\n",
       "                                          newContent  \\\n",
       "0  월요일 밤 귀갓길 덮친 역주행 차량'급발진' 아닌 정황…스키드마크 혼선사고 사흘만에...   \n",
       "1  \"지나친 자신감에 부주의·태만…75세 미만도 면허 갱신 때 교육 필요\"안전펜스 설치...   \n",
       "2  음주 단속 안내판/사진=연합뉴스4번째 음주운전을 하다 신호를 위반해 교통사고를 낸 ...   \n",
       "3  1일 밤 서울 중구 시청역 부근에서 한 남성이 몰던 차가 인도로 돌진해 최소 15명...   \n",
       "4  이 사진은 기사내용과 관련이 없습니다. /TV조선 방송화면 캡처작년 기준 65세 이...   \n",
       "\n",
       "                                  translated_content   sadness       joy  \\\n",
       "0  On Monday night, shortly after the death of an...  0.374782  0.090533   \n",
       "1  An average of more than 156 percent of drivers...  0.506792  0.069327   \n",
       "2  A drunk-in-a-divorced driver, a 40-year-old dr...  0.369596  0.032880   \n",
       "3  One night in Seoul’s mid-Court Office, a man w...  0.195954  0.047232   \n",
       "4  According to an average of 651% of drivers age...  0.745798  0.032878   \n",
       "\n",
       "       love     anger      fear  surprise  \n",
       "0  0.021096  0.318191  0.165324  0.030073  \n",
       "1  0.018666  0.153711  0.232517  0.018986  \n",
       "2  0.014931  0.524553  0.045994  0.012046  \n",
       "3  0.018428  0.571343  0.145797  0.021246  \n",
       "4  0.011483  0.095116  0.100908  0.013817  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translatedCsv = pd.read_csv(\"translated_and_emotion_analyzed_data.csv\")\n",
    "translatedCsv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'news_analysis_db' created or already exists.\n",
      "New data structure:\n",
      "date                   object\n",
      "title                  object\n",
      "link                   object\n",
      "content                object\n",
      "newContent             object\n",
      "translated_content     object\n",
      "sadness               float64\n",
      "joy                   float64\n",
      "love                  float64\n",
      "anger                 float64\n",
      "fear                  float64\n",
      "surprise              float64\n",
      "dtype: object\n",
      "                  date                                 title  \\\n",
      "0  2024-07-08 09:22:54  '폭우의 시대'…기상청 \"더 많은 비 더 짧은 시간에 쏟아질 것\"   \n",
      "1  2024-07-08 07:19:07    충청권 천둥·번개 동반 강한 비…중대본 호우경보 '주의' 상향   \n",
      "2  2024-07-08 04:00:00  '천둥·번개' 강한 비에도 더위는 안 꺾여…최고 31도[오늘날씨]   \n",
      "3  2024-07-08 13:31:08     1시간에 50mm 이상 강한 비...옥천서 산사태 1명 실종   \n",
      "4  2024-07-08 00:13:35             출근길, 중부지방 강한 비 주의 [마감 날씨]   \n",
      "\n",
      "                                                link  \\\n",
      "0  https://n.news.naver.com/mnews/article/001/001...   \n",
      "1  https://n.news.naver.com/mnews/article/656/000...   \n",
      "2  https://n.news.naver.com/mnews/article/003/001...   \n",
      "3  https://n.news.naver.com/mnews/article/057/000...   \n",
      "4  https://n.news.naver.com/mnews/article/056/001...   \n",
      "\n",
      "                                             content  \\\n",
      "0  [ 경북 안동·영양에 비수도권 첫 '호우 긴급재난문자'폭좁은 비구름대·하층제트, '...   \n",
      "1  [ 대전일보 DB 충청권과 경북권을 중심으로 호우 특보가 발효되면서 행정안전부는 8...   \n",
      "2  [ 아침 최저 22~27도, 낮 최고 26~31도미세먼지 전 권역에서 '좋음' 수준...   \n",
      "3  [ \\t\\t\\t중부지방과 충청·경북권에 강한 비가 쏟아지면서 침수 피해가 속출하고 ...   \n",
      "4  [  현재  충청과 경북 지역에 걸쳐 긴 띠 형태의 강한 비구름이 지나고 있습니다....   \n",
      "\n",
      "                                          newContent  \\\n",
      "0   경북 안동·영양에 비수도권 첫 '호우 긴급재난문자'폭좁은 비구름대·하층제트, '1...   \n",
      "1   대전일보 DB 충청권과 경북권을 중심으로 호우 특보가 발효되면서 행정안전부는 8일...   \n",
      "2   아침 최저 22~27도, 낮 최고 26~31도미세먼지 전 권역에서 '좋음' 수준 ...   \n",
      "3   중부지방과 충청·경북권에 강한 비가 쏟아지면서 침수 피해가 속출하고 있습니다. 사...   \n",
      "4   현재 충청과 경북 지역에 걸쳐 긴 띠 형태의 강한 비구름이 지나고 있습니다. 특히...   \n",
      "\n",
      "                                  translated_content   sadness       joy  \\\n",
      "0  If the rainfall of the upper half of the lower...  0.489337  0.031466   \n",
      "1  The first stage of the security security cente...  0.225394  0.469955   \n",
      "2  From mid-thirty to mid-thirty to mid-thirty to...  0.177070  0.174322   \n",
      "3  If the population is in the mid-thirty-thirty-...  0.331772  0.147191   \n",
      "4  There is now a long band of heavy rain clouds ...  0.292578  0.121337   \n",
      "\n",
      "       love     anger      fear  surprise  \n",
      "0  0.015947  0.271054  0.176513  0.015683  \n",
      "1  0.030181  0.068449  0.176410  0.029613  \n",
      "2  0.033452  0.365770  0.208918  0.040468  \n",
      "3  0.021171  0.113447  0.359510  0.026908  \n",
      "4  0.026765  0.363654  0.160414  0.035253  \n",
      "Data inserted successfully\n",
      "Table structure:\n",
      "('seq', 'int', 'NO', 'PRI', None, 'auto_increment')\n",
      "('date', 'date', 'YES', '', None, '')\n",
      "('title', 'varchar(255)', 'YES', '', None, '')\n",
      "('link', 'varchar(255)', 'YES', '', None, '')\n",
      "('content', 'text', 'YES', '', None, '')\n",
      "('newContent', 'text', 'YES', '', None, '')\n",
      "('translated_content', 'text', 'YES', '', None, '')\n",
      "('sadness', 'float', 'YES', '', None, '')\n",
      "('joy', 'float', 'YES', '', None, '')\n",
      "('love', 'float', 'YES', '', None, '')\n",
      "('anger', 'float', 'YES', '', None, '')\n",
      "('fear', 'float', 'YES', '', None, '')\n",
      "('surprise', 'float', 'YES', '', None, '')\n",
      "Existing data in the table:\n",
      "(1, datetime.date(2024, 7, 7), \"'시청 역주행 사고' 주요장면…급발진 어긋나는 정황들\", 'https://n.news.naver.com/mnews/article/003/0012651091?sid=102', '[\\n월요일 밤 귀갓길 덮친 역주행 차량\\'급발진\\' 아닌 정황…스키드마크 혼선사고 사흘만에 피의자 신문 \"급발진\"\\n\\n\\n\\n[서울=뉴시스] 김명년 기자 = 4일 중구 시청역 교차로 인근에서 발생한 차량 인도 돌진사고 현장에서 한 시민이 희생자들을 추모하고 있다. ... (3594 characters truncated) ... 원 이하의 벌금에 처하도록 규정하고 있다. 대법원 양형위원회는 교통사고 치사 사건에 대해 기본적으로 징역 8월~징역 2년을 선고하도록 권고하고 있다. 다만 차씨가 인명 피해를 줄이려는 노력을 한 점이 인정되면 양형기준에 따라 선고되는 형량은 더 낮아질 수 있다.\\n]', '월요일 밤 귀갓길 덮친 역주행 차량\\'급발진\\' 아닌 정황…스키드마크 혼선사고 사흘만에 피의자 신문 \"급발진\"서울=뉴시스 김명년 기자 = 4일 중구 시청역 교차로 인근에서 발생한 차량 인도 돌진사고 현장에서 한 시민이 희생자들을 추모하고 있다. 2024.07.04.  ... (3534 characters truncated) ... 00만원 이하의 벌금에 처하도록 규정하고 있다. 대법원 양형위원회는 교통사고 치사 사건에 대해 기본적으로 징역 8월~징역 2년을 선고하도록 권고하고 있다. 다만 차씨가 인명 피해를 줄이려는 노력을 한 점이 인정되면 양형기준에 따라 선고되는 형량은 더 낮아질 수 있다.', 'On Monday night, shortly after the death of an HCCCB post-run, a New York Post post-op post-op post-op post-op post-operous post post-op post-op post ... (58 characters truncated) ... p post-op post-op post-op post-op post-op post-op post-op post-op post-op post-op post-op post-op post-op post-op post-op post-op post-op post-optun.', 0.374782, 0.0905325, 0.0210961, 0.318191, 0.165324, 0.0300733)\n",
      "(2, datetime.date(2024, 7, 7), \"베테랑 운전자가 초보보다 사고 더 많이 낸다…'15년 이상' 60%\", 'https://n.news.naver.com/mnews/article/001/0014791554?sid=102', '[\\n\"지나친 자신감에 부주의·태만…75세 미만도 면허 갱신 때 교육 필요\"\\n\\n\\n\\n안전펜스 설치된 거리(서울=연합뉴스) 김도훈 기자 = 시청역 교차로 교통사고로 안전펜스에 대한 중요성이 재조명되고 있다.    3일 서울 시내의 한 도로와 인도 사이에 안전펜스가 ... (1162 characters truncated) ... 듣게 하는 것도 방법\"이라며 \"제도적 보완이 필요하다\"고 지적했다.    한편 지난 1일 밤 시청역 인근에서 인도로 돌진해 9명의 사망자를 낸 사고 운전자는 68세 남성으로, 40여년 운전 경력을 가진 버스 기사로 확인됐다.    already@yna.co.kr\\n]', '\"지나친 자신감에 부주의·태만…75세 미만도 면허 갱신 때 교육 필요\"안전펜스 설치된 거리(서울=연합뉴스) 김도훈 기자 = 시청역 교차로 교통사고로 안전펜스에 대한 중요성이 재조명되고 있다. 3일 서울 시내의 한 도로와 인도 사이에 안전펜스가 설치돼 있다. 2024. ... (1106 characters truncated) ...  교통안전교육을 듣게 하는 것도 방법\"이라며 \"제도적 보완이 필요하다\"고 지적했다. 한편 지난 1일 밤 시청역 인근에서 인도로 돌진해 9명의 사망자를 낸 사고 운전자는 68세 남성으로, 40여년 운전 경력을 가진 버스 기사로 확인됐다. already@yna.co.kr', 'An average of more than 156 percent of drivers under 75 years of age have been re-enabled to safety fences for 152 years. An average of more than 156 percent of drivers under 156 years of age are under-involved in driver-in-laws.', 0.506792, 0.0693269, 0.0186664, 0.153711, 0.232517, 0.0189862)\n",
      "(3, datetime.date(2024, 7, 7), '벌써 4번째 음주운전…신호 위반해 사고낸 40대 징역 1년', 'https://n.news.naver.com/mnews/article/057/0001828119?sid=102', '[\\n\\n\\n\\n\\n음주 단속 안내판/사진=연합뉴스4번째 음주운전을 하다 신호를 위반해 교통사고를 낸 40대 운전자가 실형을 선고받았습니다.오늘(7일) 인천지법 형사11단독 김샛별 판사는 도로교통법상 음주운전과 교통사고처리 특례법상 치상 혐의로 기소된 A(42) 씨에 ... (394 characters truncated) ... 지 몇 개월 만에 다시 음주운전을 하다가 신호위반으로 사고를 냈다\"며 \"범행 당시 혈중알코올농도도 매우 높았다\"고 지적했습니다.다만 \"잘못을 인정하면서 반성하고 있다\"며 \"심하게 다치지 않은 피해자와 원만하게 합의한 점 등을 고려했다\"고 양형 이유를 밝혔습니다.\\n]', '음주 단속 안내판/사진=연합뉴스4번째 음주운전을 하다 신호를 위반해 교통사고를 낸 40대 운전자가 실형을 선고받았습니다.오늘(7일) 인천지법 형사11단독 김샛별 판사는 도로교통법상 음주운전과 교통사고처리 특례법상 치상 혐의로 기소된 A(42) 씨에게 징역 1년을 선고 ... (380 characters truncated) ... 끝난 지 몇 개월 만에 다시 음주운전을 하다가 신호위반으로 사고를 냈다\"며 \"범행 당시 혈중알코올농도도 매우 높았다\"고 지적했습니다.다만 \"잘못을 인정하면서 반성하고 있다\"며 \"심하게 다치지 않은 피해자와 원만하게 합의한 점 등을 고려했다\"고 양형 이유를 밝혔습니다.', 'A drunk-in-a-divorced driver, a 40-year-old driver, who was sentenced to death in a traffic accident at the end of a 12-year term, was sentenced to death by a drunken driver, who was sentenced to one year in prison for attempted drunk driving and attempted to kill himself.', 0.369596, 0.0328802, 0.0149308, 0.524553, 0.045994, 0.0120461)\n",
      "(4, datetime.date(2024, 7, 7), '시청 사고 유족에게 80만원 청구서…\"시신 운구, 현장 수습비 명목\"', 'https://n.news.naver.com/mnews/article/421/0007647597?sid=102', '[\\n\\n\\n\\n\\n1일 밤 서울 중구 시청역 부근에서 한 남성이 몰던 차가 인도로 돌진해 최소 15명 사상자가 발생, 경찰이 사고차량을 수습하고 있다. 2024.7.2/뉴스1 ⓒ News1 구윤성 기자(서울=뉴스1) 김학진 기자 = 시청역 역주행 사고로 숨진 유가족 ... (520 characters truncated) ... 결국 억울하게 세상을 떠난 사고 피해자들의 유족이 일단 \\'현장 수습 비용\\'을 내게 된 것이라고 MBN은 전했다.앞서 지난 1일 밤 서울 시청역 인근에서 운전자 차 모 씨(68)가 제네시스 차를 인도로 돌진해 9명이 사망하고, 7명의 부상자가 발생했다.\\n\\t\\t]', '1일 밤 서울 중구 시청역 부근에서 한 남성이 몰던 차가 인도로 돌진해 최소 15명 사상자가 발생, 경찰이 사고차량을 수습하고 있다. 2024.7.2/뉴스1 ⓒ News1 구윤성 기자(서울=뉴스1) 김학진 기자 = 시청역 역주행 사고로 숨진 유가족들이 장례식장에서 시 ... (502 characters truncated) ... 를 호출했다.결국 억울하게 세상을 떠난 사고 피해자들의 유족이 일단 \\'현장 수습 비용\\'을 내게 된 것이라고 MBN은 전했다.앞서 지난 1일 밤 서울 시청역 인근에서 운전자 차 모 씨(68)가 제네시스 차를 인도로 돌진해 9명이 사망하고, 7명의 부상자가 발생했다.', 'One night in Seoul’s mid-Court Office, a man who had been accused of being killed and killed in an emergency accident in India, was charged with deat ... (146 characters truncated) ... sed of being killed and killed in an accident, was charged with an accident and was charged with the death of an extra-invasive member of the family.', 0.195954, 0.0472322, 0.0184284, 0.571343, 0.145797, 0.0212458)\n",
      "(5, datetime.date(2024, 7, 7), '고령 운전자, 사고 13% 더 내…피해자 중상 비율도 높아', 'https://n.news.naver.com/mnews/article/448/0000466059?sid=102', '[\\n\\n\\n\\n\\n이 사진은 기사내용과 관련이 없습니다. /TV조선 방송화면 캡처작년 기준 65세 이상 고령 운전자가 낸 사고율이 65세 미만 운전자보다 13% 높은 것으로 나타났다.7일 보험개발원에 따르면 작년 보험에 가입된 주피보험자 기준 65세 이상 운전자의  ... (555 characters truncated) ...  이상 운전자에 대한 손해율은 80.2%로, 65세 미만 운전자(76.3%)에 비해 4%포인트(p) 가까이 높았다.65세 이상 운전자의 평균 사고가액(손해액/사고건수)은 481만2천659원, 65세 미만 운전자의 평균 사고가액은 446만6천566원이었다.\\n\\t\\t]', '이 사진은 기사내용과 관련이 없습니다. /TV조선 방송화면 캡처작년 기준 65세 이상 고령 운전자가 낸 사고율이 65세 미만 운전자보다 13% 높은 것으로 나타났다.7일 보험개발원에 따르면 작년 보험에 가입된 주피보험자 기준 65세 이상 운전자의 계약 건수는 258만 ... (537 characters truncated) ...  기준 65세 이상 운전자에 대한 손해율은 80.2%로, 65세 미만 운전자(76.3%)에 비해 4%포인트(p) 가까이 높았다.65세 이상 운전자의 평균 사고가액(손해액/사고건수)은 481만2천659원, 65세 미만 운전자의 평균 사고가액은 446만6천566원이었다.', 'According to an average of 651% of drivers aged 651% or older, an average of 465 percent of drivers aged 656 percent or older (insults aged 656 perce ... (588 characters truncated) ... f the age of the age of 653 who were killed at the age of 653). The average age of the age of the age of 653 was more than the age of the age of 653.', 0.745798, 0.0328775, 0.0114827, 0.0951161, 0.100908, 0.0138174)\n",
      "Data successfully updated in MySQL table: translated_news\n",
      "Total rows in the table after update: 96\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# MySQL 연결 정보\n",
    "username = 'admin'\n",
    "password = 'qwer1234'\n",
    "host = 'harusijak-database.c30iq62oq32a.ap-northeast-2.rds.amazonaws.com'\n",
    "port = 3306\n",
    "\n",
    "# 새로운 데이터베이스 이름\n",
    "new_database = 'news_analysis_db'\n",
    "\n",
    "# 먼저 MySQL 서버에 연결 (특정 데이터베이스 지정 없이)\n",
    "engine = create_engine(f\"mysql+pymysql://{username}:{password}@{host}:{port}\")\n",
    "\n",
    "# 새 데이터베이스 생성\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(f\"CREATE DATABASE IF NOT EXISTS {new_database}\"))\n",
    "    print(f\"Database '{new_database}' created or already exists.\")\n",
    "\n",
    "# 새로운 데이터베이스에 연결\n",
    "engine = create_engine(f\"mysql+pymysql://{username}:{password}@{host}:{port}/{new_database}\")\n",
    "\n",
    "# CSV 파일 읽기\n",
    "translatedCsv = pd.read_csv(\"translated_and_emotion_analyzed_data.csv\")\n",
    "\n",
    "# DataFrame을 MySQL 테이블로 저장\n",
    "table_name = 'translated_news'\n",
    "translatedCsv.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Data successfully saved to MySQL table: {table_name} in database: {new_database}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 크롤링 (dataframe 반환)\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def install_dependencies():\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    dependencies = ['selenium', 'webdriver_manager', 'tqdm', 'pandas', 'requests', 'beautifulsoup4']\n",
    "    for package in dependencies:\n",
    "        try:\n",
    "            __import__(package)\n",
    "        except ImportError:\n",
    "            print(f\"Installing {package}\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "def make_url(search_word, start_page, end_page):\n",
    "    base_url = \"https://search.naver.com/search.naver?where=news&sm=tab_pge&query=\"\n",
    "    urls = [f\"{base_url}{search_word}&start={1 + (i - 1) * 10}\" for i in range(start_page, end_page + 1)]\n",
    "    print(\"Generated URLs:\", urls)\n",
    "    return urls\n",
    "\n",
    "def get_news_links(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/98.0.4758.102\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    news_links = soup.select(\"div.group_news > ul.list_news > li div.news_area > div.news_info > div.info_group > a.info\")\n",
    "    return [link['href'] for link in news_links if \"news.naver.com\" in link['href']]\n",
    "\n",
    "def extract_news_content(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/98.0.4758.102\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    title = soup.select_one(\"#ct > div.media_end_head.go_trans > div.media_end_head_title > h2\")\n",
    "    if not title:\n",
    "        title = soup.select_one(\"#content > div.end_ct > div > h2\")\n",
    "    \n",
    "    content = soup.select(\"article#dic_area\")\n",
    "    if not content:\n",
    "        content = soup.select(\"#articeBody\")\n",
    "    \n",
    "    date = soup.select_one(\"div#ct> div.media_end_head.go_trans > div.media_end_head_info.nv_notrans > div.media_end_head_info_datestamp > div > span\")\n",
    "    if date:\n",
    "        date = date['data-date-time']\n",
    "    else:\n",
    "        date = soup.select_one(\"#content > div.end_ct > div > div.article_info > span > em\")\n",
    "        \n",
    "    title = re.sub('<[^>]*>', '', str(title))\n",
    "    content = re.sub('<[^>]*>', '', ''.join(str(content)))\n",
    "    content = re.sub(r'\\n+', ' ', content)\n",
    "    date = re.sub('<[^>]*>', '', str(date))\n",
    "\n",
    "    return title.strip(), content.strip(), date.strip()\n",
    "\n",
    "def crawl_news(search_word, start_page=1, end_page=2):\n",
    "    install_dependencies()\n",
    "\n",
    "    urls = make_url(search_word, start_page, end_page)\n",
    "    all_news_links = []\n",
    "    for url in urls:\n",
    "        all_news_links.extend(get_news_links(url))\n",
    "        time.sleep(random.uniform(0.5, 1.5))\n",
    "\n",
    "    news_data = []\n",
    "    for link in tqdm(all_news_links):\n",
    "        title, content, date = extract_news_content(link)\n",
    "        news_data.append({\n",
    "            'date': date,\n",
    "            'title': title,\n",
    "            'link': link,\n",
    "            'content': content\n",
    "        })\n",
    "        time.sleep(random.uniform(0.5, 1.5))\n",
    "\n",
    "    news_df = pd.DataFrame(news_data)\n",
    "    news_df = news_df.drop_duplicates(subset=['title', 'link'], keep='first')\n",
    "\n",
    "    # now = datetime.datetime.now()\n",
    "    # filename = f\"./NewsData/{search_word}_{now.strftime('%Y%m%d_%H시%M분')}.csv\"\n",
    "    # news_df.to_csv(filename, encoding='utf-8-sig', index=False)\n",
    "\n",
    "    # print(f\"검색된 기사 갯수: 총 {len(news_df)}개\")\n",
    "    # print(f\"결과가 {filename}에 저장되었습니다.\")\n",
    "\n",
    "    return news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing beautifulsoup4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(35541) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Generated URLs: ['https://search.naver.com/search.naver?where=news&sm=tab_pge&query=반도체&start=1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-08 12:28:12</td>\n",
       "      <td>삼성전자노조 “파업에 6540명 참여…반도체 생산 차질 있을 것”</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/028/000...</td>\n",
       "      <td>[ 8일부터 사흘간 총파업 8일 오전 경기도 화성시 삼성전자 화성사업장 앞에서 열린...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                 title  \\\n",
       "0  2024-07-08 12:28:12  삼성전자노조 “파업에 6540명 참여…반도체 생산 차질 있을 것”   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://n.news.naver.com/mnews/article/028/000...   \n",
       "\n",
       "                                             content  \n",
       "0  [ 8일부터 사흘간 총파업 8일 오전 경기도 화성시 삼성전자 화성사업장 앞에서 열린...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = crawl_news(search_word=\"반도체\",end_page=1)\n",
    "news_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-08 12:28:12</td>\n",
       "      <td>삼성전자노조 “파업에 6540명 참여…반도체 생산 차질 있을 것”</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/028/000...</td>\n",
       "      <td>[ 8일부터 사흘간 총파업 8일 오전 경기도 화성시 삼성전자 화성사업장 앞에서 열린...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-08 05:01:00</td>\n",
       "      <td>삼성전자 노조 수천명 오늘부터 총파업…반도체 생산라인 경고등</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/421/000...</td>\n",
       "      <td>[ 전삼노 \"5000명 이상 참여\"…사흘 파업 후 사측 대응 따라 무기한 파업 경고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-07 09:00:00</td>\n",
       "      <td>반도체·이차전지 '신병 훈련소', 42개 대학으로 늘었다</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/003/001...</td>\n",
       "      <td>[ 교육부, 첨단산업 인재양성 부트캠프 선정 결과 발표지난해 반도체 10개교 운영…...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-07 09:56:13</td>\n",
       "      <td>美 찾은 최태원 회장… SK 미래사업 바이오·반도체 현장 점검</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/366/000...</td>\n",
       "      <td>[ \\t\\t\\t        미국 출장 중인 최태원 SK그룹 회장이 SK바이오팜과 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-08 07:35:08</td>\n",
       "      <td>최태원 SK그룹 회장, 바이오·반도체 '미래 사업' 현장 점검</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/629/000...</td>\n",
       "      <td>[ SK바이오팜 미국 법인·SKC 자회사 생산 공장 방문 최태원 SK그룹 회장이 지...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                 title  \\\n",
       "0  2024-07-08 12:28:12  삼성전자노조 “파업에 6540명 참여…반도체 생산 차질 있을 것”   \n",
       "1  2024-07-08 05:01:00     삼성전자 노조 수천명 오늘부터 총파업…반도체 생산라인 경고등   \n",
       "2  2024-07-07 09:00:00       반도체·이차전지 '신병 훈련소', 42개 대학으로 늘었다   \n",
       "3  2024-07-07 09:56:13    美 찾은 최태원 회장… SK 미래사업 바이오·반도체 현장 점검   \n",
       "4  2024-07-08 07:35:08    최태원 SK그룹 회장, 바이오·반도체 '미래 사업' 현장 점검   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://n.news.naver.com/mnews/article/028/000...   \n",
       "1  https://n.news.naver.com/mnews/article/421/000...   \n",
       "2  https://n.news.naver.com/mnews/article/003/001...   \n",
       "3  https://n.news.naver.com/mnews/article/366/000...   \n",
       "4  https://n.news.naver.com/mnews/article/629/000...   \n",
       "\n",
       "                                             content  \n",
       "0  [ 8일부터 사흘간 총파업 8일 오전 경기도 화성시 삼성전자 화성사업장 앞에서 열린...  \n",
       "1  [ 전삼노 \"5000명 이상 참여\"…사흘 파업 후 사측 대응 따라 무기한 파업 경고...  \n",
       "2  [ 교육부, 첨단산업 인재양성 부트캠프 선정 결과 발표지난해 반도체 10개교 운영…...  \n",
       "3  [ \\t\\t\\t        미국 출장 중인 최태원 SK그룹 회장이 SK바이오팜과 ...  \n",
       "4  [ SK바이오팜 미국 법인·SKC 자회사 생산 공장 방문 최태원 SK그룹 회장이 지...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# csv에 있는 파일을 불러와서 번역후 감정분류하고 DataFrame에 추가하고 결과를 csv로 저장하는 코드(번역, 감정분류의 토큰 수가 작아서 나눠서 진행)\n",
    "import os\n",
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer, pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "def translate_emotion_toCSV(news_df):\n",
    "    # news_df = crawl_news(search_word=\"반도체\",end_page=1)\n",
    "    data = news_df\n",
    "    data2 = data.copy() # data2에 data 복제\n",
    "\n",
    "    newContent = []\n",
    "\n",
    "    # \\n, \\t 불필요한 내용 제거를 위한 함수\n",
    "    def pad_punctuation(s):\n",
    "        s = re.sub(r'\\n', '', s)\n",
    "        s = re.sub(r'\\t', '', s)\n",
    "        s = re.sub(r'\\[', '', s)\n",
    "        s = re.sub(r'\\]', '', s)\n",
    "        s = re.sub(' +', ' ', s)\n",
    "        \n",
    "        return s\n",
    "\n",
    "    # for문 돌리면서 기호 제거 \n",
    "    for i in data2['content'] :\n",
    "        newContent.append(pad_punctuation(i))\n",
    "\n",
    "\n",
    "    # 일단은 df에 제거된 newContent리스트 추가 \n",
    "    data2['newContent'] = newContent\n",
    "\n",
    "\n",
    "    data2['newContent'][0]\n",
    "    # 주석필요\n",
    "    # os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # print(f\"Using device: {device}\")\n",
    "\n",
    "    # 번역 모델 설정\n",
    "    translate_model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
    "    translate_model = MarianMTModel.from_pretrained(translate_model_name).to(device)\n",
    "    translate_tokenizer = MarianTokenizer.from_pretrained(translate_model_name)\n",
    "\n",
    "    # 감정 분석 모델 설정\n",
    "    emotion_model_id = \"pulpilisory/distilbert-base-uncased-finetuned-emotion\"\n",
    "    classifier = pipeline(\"text-classification\", model=emotion_model_id, device=device)\n",
    "\n",
    "    # 번역의 최대 토큰수가 512 라서 512 이상 되는 기사들은 512 토큰으로 잘라서 번역함\n",
    "    def translate_batch(texts):\n",
    "        encoded = translate_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        input_ids = encoded.input_ids.to(device)\n",
    "        attention_mask = encoded.attention_mask.to(device)\n",
    "        ## 그래디언트 저장 안하게 하기 Autograd(미분) 비활성화 코드 -> 속도를 위해 사용 \n",
    "        with torch.no_grad():\n",
    "            outputs = translate_model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=512)\n",
    "        \n",
    "        return [translate_tokenizer.decode(out, skip_special_tokens=True) for out in outputs]\n",
    "    # 번역모델( \n",
    "    def translate_and_analyze(texts, batch_size=32):\n",
    "        translated_texts = []\n",
    "        emotion_results = []\n",
    "        \n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing\"):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            \n",
    "            # 번역\n",
    "            translated_batch = translate_batch(batch)\n",
    "            translated_texts.extend(translated_batch)\n",
    "            \n",
    "            # 감정 분석\n",
    "            for text in translated_batch:\n",
    "                try:\n",
    "                    preds = classifier(text, return_all_scores=True)[0]\n",
    "                    emotion_results.append({pred['label']: pred['score'] for pred in preds})\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing text: {text[:50]}... Error: {str(e)}\")\n",
    "                    emotion_results.append({f'LABEL_{i}': 0 for i in range(6)})\n",
    "        \n",
    "        return translated_texts, emotion_results\n",
    "\n",
    "\n",
    "    # 번역 및 감정 분석 실행\n",
    "    translated_texts, emotion_results = translate_and_analyze(data2['newContent'].tolist())\n",
    "    # 감정 레이블 매핑\n",
    "    label_to_emotion = {\n",
    "        'LABEL_0': 'sadness',\n",
    "        'LABEL_1': 'joy',\n",
    "        'LABEL_2': 'love',\n",
    "        'LABEL_3': 'anger',\n",
    "        'LABEL_4': 'fear',\n",
    "        'LABEL_5': 'surprise'\n",
    "    }\n",
    "\n",
    "    # 번역 결과 및 감정 분석 결과를 DataFrame에 추가\n",
    "    data2['translated_content'] = translated_texts\n",
    "    for label, emotion in label_to_emotion.items():\n",
    "        data2[emotion] = [result[label] for result in emotion_results]\n",
    "\n",
    "    data2.head()\n",
    "    # 결과 확인\n",
    "    # print(data2[['newContent', 'translated_content'] + list(label_to_emotion.values())].head())\n",
    "\n",
    "    # 결과를 CSV 파일로 저장\n",
    "    print(\"데이터 csv 저장 실행\")\n",
    "    data2.to_csv('translated_and_emotion_analyzed_data_test.csv', index=False)\n",
    "    print(\"데이터 csv 저장 실행\")\n",
    "    print(\"결과 확인\")\n",
    "    print(pd.read_csv(\"translated_and_emotion_analyzed_data_test.csv\").head())\n",
    "    print(\"결과 확인#####################\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing beautifulsoup4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(88920) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Generated URLs: ['https://search.naver.com/search.naver?where=news&sm=tab_pge&query=날씨&start=1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'title', 'link', 'content'], dtype='object')\n",
      "                  date                                    title  \\\n",
      "0  2024-07-08 04:00:00     '천둥·번개' 강한 비에도 더위는 안 꺾여…최고 31도[오늘날씨]   \n",
      "1  2024-07-08 09:00:01       [내일날씨] 전국 곳곳 강한 장맛비…이틀간 최대 120㎜ 이상   \n",
      "2  2024-07-08 00:13:35                출근길, 중부지방 강한 비 주의 [마감 날씨]   \n",
      "3  2024-07-08 00:52:43     [날씨] '폭우'·'폭염' 공존한 한반도...오늘 중부 또 장맛비   \n",
      "4  2024-07-08 06:00:00  수도권·전북 100㎜ 이상 물폭탄…돌풍·번개 동반 강한 비[오늘 날씨]   \n",
      "\n",
      "                                                link  \\\n",
      "0  https://n.news.naver.com/mnews/article/003/001...   \n",
      "1  https://n.news.naver.com/mnews/article/001/001...   \n",
      "2  https://n.news.naver.com/mnews/article/056/001...   \n",
      "3  https://n.news.naver.com/mnews/article/052/000...   \n",
      "4  https://n.news.naver.com/mnews/article/421/000...   \n",
      "\n",
      "                                             content  \n",
      "0  [ 아침 최저 22~27도, 낮 최고 26~31도미세먼지 전 권역에서 '좋음' 수준...  \n",
      "1  [ 남부지방·제주도, 최고체감온도 33도 내외…열대야 나타나는 곳도 장마(서울=연합...  \n",
      "2  [  현재  충청과 경북 지역에 걸쳐 긴 띠 형태의 강한 비구름이 지나고 있습니다....  \n",
      "3  [ \\t\\t\\t[앵커]충청과 경북에는 폭우가 쏟아졌지만, 제주와 남부 내륙에는 찜통...  \n",
      "4  [ 아침 최저기온 22~27도, 낮 최고기온 26~31도 장맛비가 내리는 2일 서울...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 1/1 [02:28<00:00, 148.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 csv 저장 실행\n",
      "데이터 csv 저장 실행\n",
      "결과 확인\n",
      "                  date                                    title  \\\n",
      "0  2024-07-08 04:00:00     '천둥·번개' 강한 비에도 더위는 안 꺾여…최고 31도[오늘날씨]   \n",
      "1  2024-07-08 09:00:01       [내일날씨] 전국 곳곳 강한 장맛비…이틀간 최대 120㎜ 이상   \n",
      "2  2024-07-08 00:13:35                출근길, 중부지방 강한 비 주의 [마감 날씨]   \n",
      "3  2024-07-08 00:52:43     [날씨] '폭우'·'폭염' 공존한 한반도...오늘 중부 또 장맛비   \n",
      "4  2024-07-08 06:00:00  수도권·전북 100㎜ 이상 물폭탄…돌풍·번개 동반 강한 비[오늘 날씨]   \n",
      "\n",
      "                                                link  \\\n",
      "0  https://n.news.naver.com/mnews/article/003/001...   \n",
      "1  https://n.news.naver.com/mnews/article/001/001...   \n",
      "2  https://n.news.naver.com/mnews/article/056/001...   \n",
      "3  https://n.news.naver.com/mnews/article/052/000...   \n",
      "4  https://n.news.naver.com/mnews/article/421/000...   \n",
      "\n",
      "                                             content  \\\n",
      "0  [ 아침 최저 22~27도, 낮 최고 26~31도미세먼지 전 권역에서 '좋음' 수준...   \n",
      "1  [ 남부지방·제주도, 최고체감온도 33도 내외…열대야 나타나는 곳도 장마(서울=연합...   \n",
      "2  [  현재  충청과 경북 지역에 걸쳐 긴 띠 형태의 강한 비구름이 지나고 있습니다....   \n",
      "3  [ \\t\\t\\t[앵커]충청과 경북에는 폭우가 쏟아졌지만, 제주와 남부 내륙에는 찜통...   \n",
      "4  [ 아침 최저기온 22~27도, 낮 최고기온 26~31도 장맛비가 내리는 2일 서울...   \n",
      "\n",
      "                                          newContent  \\\n",
      "0   아침 최저 22~27도, 낮 최고 26~31도미세먼지 전 권역에서 '좋음' 수준 ...   \n",
      "1   남부지방·제주도, 최고체감온도 33도 내외…열대야 나타나는 곳도 장마(서울=연합뉴...   \n",
      "2   현재 충청과 경북 지역에 걸쳐 긴 띠 형태의 강한 비구름이 지나고 있습니다. 특히...   \n",
      "3   앵커충청과 경북에는 폭우가 쏟아졌지만, 제주와 남부 내륙에는 찜통더위가 나타나며 ...   \n",
      "4   아침 최저기온 22~27도, 낮 최고기온 26~31도 장맛비가 내리는 2일 서울 ...   \n",
      "\n",
      "                                  translated_content   sadness       joy  \\\n",
      "0  From mid-thirty to mid-thirty to mid-thirty to...  0.177070  0.174322   \n",
      "1  In the mid-thirty-thirty-thirty-thirty-thirty-...  0.266073  0.176094   \n",
      "2  There is now a long band of heavy rain clouds ...  0.292578  0.121337   \n",
      "3  In the middle of the night, there will be heav...  0.369018  0.212005   \n",
      "4  The mid-thirty-thirty-thirty-thirty-thirty-thi...  0.188349  0.291916   \n",
      "\n",
      "       love     anger      fear  surprise  \n",
      "0  0.033452  0.365770  0.208918  0.040468  \n",
      "1  0.028322  0.321799  0.167855  0.039857  \n",
      "2  0.026765  0.363654  0.160414  0.035253  \n",
      "3  0.041564  0.193791  0.153005  0.030617  \n",
      "4  0.037867  0.195536  0.239443  0.046889  \n",
      "결과 확인#####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "news_df = crawl_news(search_word=\"날씨\",end_page=1)\n",
    "\n",
    "translate_emotion_toCSV(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분석한 DataFrame을 Mysql에 추가\n",
    "def DataFrame_to_mysql():\n",
    "    import pandas as pd\n",
    "    from sqlalchemy import create_engine, text, inspect\n",
    "\n",
    "    # MySQL 연결 정보\n",
    "    username = 'admin'\n",
    "    password = 'qwer1234'\n",
    "    host = 'harusijak-database.c30iq62oq32a.ap-northeast-2.rds.amazonaws.com'\n",
    "    port = 3306\n",
    "    database = 'news_analysis_db'\n",
    "\n",
    "    # 먼저 MySQL 서버에 연결 (특정 데이터베이스 지정 없이)\n",
    "    engine = create_engine(f\"mysql+pymysql://{username}:{password}@{host}:{port}\")\n",
    "\n",
    "    # 데이터베이스 생성 (없는 경우)\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(f\"CREATE DATABASE IF NOT EXISTS {database}\"))\n",
    "        print(f\"Database '{database}' created or already exists.\")\n",
    "\n",
    "    # 이제 생성된 데이터베이스에 연결\n",
    "    engine = create_engine(f\"mysql+pymysql://{username}:{password}@{host}:{port}/{database}\")\n",
    "    # CSV 파일 읽기\n",
    "    new_data = pd.read_csv(\"translated_and_emotion_analyzed_data_test.csv\")\n",
    "\n",
    "    # 테이블 이름\n",
    "    table_name = 'translated_news'\n",
    "\n",
    "    # 테이블이 존재하는지 확인\n",
    "    inspector = inspect(engine)\n",
    "    if not inspector.has_table(table_name):\n",
    "        # 테이블이 없으면 새로 생성 (seq 컬럼 포함)\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(f\"\"\"\n",
    "            CREATE TABLE {table_name} (\n",
    "                seq INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                date DATE,\n",
    "                title VARCHAR(255),\n",
    "                link VARCHAR(255),\n",
    "                content TEXT,\n",
    "                newContent TEXT,\n",
    "                translated_content TEXT,\n",
    "                sadness FLOAT,\n",
    "                joy FLOAT,\n",
    "                love FLOAT,\n",
    "                anger FLOAT,\n",
    "                fear FLOAT,\n",
    "                surprise FLOAT\n",
    "            )\n",
    "            \"\"\"))\n",
    "        print(f\"New table '{table_name}' created in database: {database}\")\n",
    "\n",
    "    # 삽입 전 행 수 확인\n",
    "    before_count = pd.read_sql(f\"SELECT COUNT(*) FROM {table_name}\", engine).iloc[0, 0]\n",
    "    print(f\"Rows before insertion: {before_count}\")\n",
    "\n",
    "    # 중복 체크 및 필터링 함수 추가\n",
    "    def filter_duplicates(new_data, conn, table_name):\n",
    "        existing_titles = pd.read_sql(f\"SELECT title FROM {table_name}\", conn)['title'].tolist()\n",
    "        filtered_data = new_data[~new_data['title'].isin(existing_titles)]\n",
    "        return filtered_data\n",
    "    # 데이터 삽입 또는 업데이트\n",
    "    print(\"with engin 실행됨\")\n",
    "    with engine.begin() as conn:\n",
    "        if inspector.has_table(table_name):\n",
    "            # 기존 테이블에서 마지막 seq 값 가져오기\n",
    "            print(\"# 기존 테이블에서 마지막 seq 값 가져오기 실행됨\")\n",
    "            result = conn.execute(text(f\"SELECT MAX(seq) FROM {table_name}\"))\n",
    "            last_seq = result.scalar() or 0\n",
    "\n",
    "            # 중복 체크 및 필터링\n",
    "            filtered_data = filter_duplicates(new_data, conn, table_name)\n",
    "\n",
    "            if len(filtered_data) > 0:\n",
    "                # 새 데이터에 seq 추가 (기존 마지막 seq부터 시작)\n",
    "                filtered_data['seq'] = range(last_seq + 1, last_seq + 1 + len(filtered_data))\n",
    "                \n",
    "                # 데이터 삽입\n",
    "                try:\n",
    "                    filtered_data.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "                    print(f\"Data inserted successfully. {len(filtered_data)} new rows added.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error inserting data: {str(e)}\")\n",
    "            else:\n",
    "                print(\"No new data to insert. All entries already exist.\")\n",
    "        else:\n",
    "            # 새 테이블 생성 시에는 모든 데이터 삽입\n",
    "            new_data['seq'] = range(1, len(new_data) + 1)\n",
    "            try:\n",
    "                new_data.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "                print(f\"New table created and {len(new_data)} rows inserted successfully.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error inserting data: {str(e)}\")\n",
    "\n",
    "    # 삽입 후 행 수 확인\n",
    "    after_count = pd.read_sql(f\"SELECT COUNT(*) FROM {table_name}\", engine).iloc[0, 0]\n",
    "    print(f\"Rows after insertion: {after_count}\")\n",
    "    print(f\"Total new rows inserted: {after_count - before_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'news_analysis_db' created or already exists.\n",
      "Rows before insertion: 124\n",
      "with engin 실행됨\n",
      "# 기존 테이블에서 마지막 seq 값 가져오기 실행됨\n",
      "No new data to insert. All entries already exist.\n",
      "Rows after insertion: 124\n",
      "Total new rows inserted: 0\n"
     ]
    }
   ],
   "source": [
    "DataFrame_to_mysql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_crawl_emotionClassify_translation_toMysql (search_word,end_page):\n",
    "    news_df = crawl_news(search_word=search_word,end_page=end_page)\n",
    "\n",
    "    translate_emotion_toCSV(news_df)\n",
    "    DataFrame_to_mysql()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
