{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPEN API 를 이용한 챗봇 시스템 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openapi\n",
      "Version: 2.0.0\n",
      "Summary: Python OpenAPI 2.0 (Swagger) object model\n",
      "Home-page: https://github.com/globality-corp/openapi\n",
      "Author: Globality Engineering\n",
      "Author-email: engineering@globality.com\n",
      "License: \n",
      "Location: /opt/anaconda3/lib/python3.11/site-packages\n",
      "Requires: inflection, jsonschema\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openapi\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### OPENAI API 호출 예제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': '죄송합니다, 현재 군자역의 혼잡도 정보는 알려드릴 수 없습니다. 군자역 '\n",
      "                                     '근처의 역 관리소나 공식 웹사이트에서 실시간 정보를 확인하시는 것을 '\n",
      "                                     '권장드립니다.',\n",
      "                          'function_call': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1720085417,\n",
      " 'id': 'chatcmpl-9hD575rBfhSnyAiaTc7r7jAmM2lbq',\n",
      " 'model': 'gpt-3.5-turbo-1106',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': 'fp_44132a4de3',\n",
      " 'usage': {'completion_tokens': 82, 'prompt_tokens': 36, 'total_tokens': 118}}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "import os\n",
    "api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "model = 'gpt-3.5-turbo-1106'\n",
    "\n",
    "messages = [\n",
    "    {'role':'system','content': 'You are a helphful assistant.'},\n",
    "    {'role':'user','content': '군자역 혼잡도 알려줘?'}\n",
    "]\n",
    "response = client.chat.completions.create(model=model, messages=messages).model_dump()\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> gpt 는 json type 으로 답을 넘겨준다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### \n",
    "\n",
    " * [model dump ]\n",
    "    : 메서드 체이닝 -> 메서드를 연쇄적으로 호출하는 방식 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ai chatbot 을 만들기 위해서는 프롬프트 엔지니어링이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseModel.to_dict of ChatCompletion(id='chatcmpl-9hD58Rx4Q2trfXlep9qvKGWw8iftV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='- 인공지능 기술의 발전과 교육의 관련성\\n- 인공지능이 교육에 미치는 영향과 변화\\n- 학교 교육과 인공지능의 융합 가능성\\n- 인공지능을 효과적으로 활용한 교육 방법과 도구\\n- 교사와 학생의 역할 변화와 대비책\\n- 인공지능과 교육의 윤리적 문제들에 대한 대처 전략', role='assistant', function_call=None, tool_calls=None))], created=1720085418, model='gpt-3.5-turbo-1106', object='chat.completion', service_tier=None, system_fingerprint='fp_44132a4de3', usage=CompletionUsage(completion_tokens=152, prompt_tokens=97, total_tokens=249))>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "내일 다음 주제로 미래 교육 포럼에서 발표할 발제문을 작성해야합니다.\n",
    "발제문의 주요 내용을 불릿 기호로 간략히 정리해 주세요.\n",
    "주제:{agenda}\n",
    "\n",
    "\n",
    "\"\"\".format(agenda=\"인공지능 시대의 교육의 역활과 의미\")\n",
    "model = 'gpt-3.5-turbo-1106'\n",
    "response = client.chat.completions.create(\n",
    "    model= model,\n",
    "    messages=[{'role':'user','content':prompt}]\n",
    ").to_dict\n",
    "pprint(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('- 인공지능이 발전함에 따라 교육의 역할이 어떻게 변화하는가?\\n'\n",
      " '- 인공지능이 교육에 미치는 영향은 무엇인가?\\n'\n",
      " '- 학생들을 준비하고 미래를 대비하는 데 교육이 어떤 역할을 해야 하는가?\\n'\n",
      " '- 인공지능과 교육의 상호작용이 미래 사회에 어떠한 의미를 갖는가?')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "prompt = \"\"\"\n",
    "내일 다음 주제로 미래 교육 포럼에서 발표할 발제문을 작성해야합니다.\n",
    "발제문의 주요 내용을 불릿 기호로 간략히 정리해 주세요.\n",
    "주제:{agenda}\n",
    "\"\"\".format(agenda=\"인공지능 시대의 교육의 역할과 의미\")\n",
    "\n",
    "model = 'gpt-3.5-turbo-1106'\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{'role': 'user', 'content': prompt}]\n",
    ")\n",
    "\n",
    "pprint(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Chater 5 프롬프트 엔지니어링의 핵심 기법 \n",
    "- few shot\n",
    "- Cot\n",
    "-SC\n",
    "- ToT\n",
    "- ReAct\n",
    "-RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 인공지능으로, 감정이나 지식을 가지고 있지 않습니다. 그러므로 바보라는 개념이 적용되지 않습니다. 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "def GPT_prompt(model = 2, template_go = False , prompt=\"\"):\n",
    "    from pprint import pprint\n",
    "    import json\n",
    "    from openai import OpenAI\n",
    "    from pprint import pprint\n",
    "    import os\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    if template_go :\n",
    "        \n",
    "        template = \"\"\"\n",
    "        당신은 번역함수이며, 반환값은 반드시 JSON 데이터 여야 합니다. \n",
    "        STEP 별로 작업을 수행하면서 그 결과를 아래의 출력 결과 JSON 포맷에 작성하세요.\n",
    "        STEP-1. 아래 세 개의 백틱으로 구분된 텍스트를 원문 그대로 읽어 올것\n",
    "        STEP-2. 입력받은 텍스트가 긍정적이라면 True를 표기할것\n",
    "        STEP-3. 다음의 말투로 번역할 것: [\"지구의 나이는 45억살이야.\",\"세종 대왕은 조선의 위대한 국왕이야.\"]\n",
    "        ```{text}```\n",
    "        ---\n",
    "        출력결과 : {{\"STEP-1\":<입력텍스트>, \"STEP-2\": <true/false>, \"STEP-3\":<번역결과>}}\n",
    "        \"\"\"\n",
    "        text = \"William Shakespeare was an English playwrit, poet and actor.  He is widely regarded as the greatest writer in the English language and the world's pre-eminent dramatist.\"\n",
    "        \n",
    "        template = template.format(text=text)\n",
    "        context = [{\"role\": \"user\",\"content\": template}]\n",
    "        model_1 = 'gpt-3.5-turbo-1106'\n",
    "        model_2 = 'gpt-4-0613'\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_2 if model == 2 else model_1,\n",
    "            messages=context,\n",
    "            temperature=0,\n",
    "            top_p=0,\n",
    "            seed=1234\n",
    "        ).model_dump()\n",
    "        pprint(json.loads(response['choices'][0]['message']['content']))\n",
    "        return json.loads(response['choices'][0]['message']['content'])\n",
    "    else :\n",
    "        template = prompt\n",
    "        context = [{\"role\": \"user\",\"content\": template}]\n",
    "\n",
    "        model_1 = 'gpt-3.5-turbo-1106'\n",
    "        model_2 = 'gpt-4-0613'\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_2 if model == 2 else model_1,\n",
    "            messages=context,\n",
    "            temperature=0,\n",
    "            top_p=0,\n",
    "            seed=1234\n",
    "        ).model_dump()\n",
    "        print(response['choices'][0]['message']['content'])\n",
    "    \n",
    "    \n",
    "    # pprint(response.choices[0].message.content)\n",
    "GPT_prompt(prompt=\"너 바보야?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "###  프롬프트 가이드라인\n",
    "- 과업배경: 당신은 번역함수\n",
    "- 원하는 결과 예시 \n",
    "- 단계별 가이드 \n",
    "- 제약사항 \n",
    "- 수행결과 작성 형식 : 출력결과 : {{\"STEP-1\":<입력텍스트>, \"STEP-2\": <true/false>, \"STEP-3\":<번역결과>}}\n",
    "- 적절한 구분자의 사용\n",
    "- 구체적이면서 명확한 과업지시\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 인컨텍스트 러닝이란?\n",
    "- 학습햇던 내용을 바탕으로 답하는 것이 아니라, 런타임 시점에 제공되는 입력정보를 바탕으로 추로하는 능력 : 주어진 문맥안에서 그 의미를 배운다\n",
    "- 언어모델 추론능력 향상 -> 프롬프트 엔지니어링의 출발 \n",
    "\n",
    "- Few-shot Prompting \n",
    "    : 그 질문과 관련된 예시를 적절히 제공하면 언어 모델이 그 예시의 의미를 추론하여 답을 말하는원리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero shot prompting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정\n"
     ]
    }
   ],
   "source": [
    "## Zero shot prompting \n",
    "from Functions import NLP_Service as N\n",
    "template = \"\"\"\n",
    "긍정 또는 부정으로 답변을 작성하세요.\n",
    "Q: 매력적인 이성과 사랑에 빠졌어!\n",
    "A: \n",
    "\"\"\"\n",
    "\n",
    "N.GPT_prompt(prompt=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A: 부정 \\n'\n",
      " '\\n'\n",
      " '이유: 이 질문의 답변은 주어진 예시의 패턴을 따르면 부정적인 답변이 되어야 합니다. 예시에서는 긍정적인 상황에는 부정적인 답변을, '\n",
      " '부정적인 상황에는 긍정적인 답변을 하고 있습니다. 따라서 \"매력적인 이성과 사랑에 빠졌어!\"는 긍정적인 상황이므로 부정적인 답변을 해야 '\n",
      " '합니다.')\n"
     ]
    }
   ],
   "source": [
    "## Few shot prompting \n",
    "from Functions import NLP_Service as N\n",
    "template = \"\"\"\n",
    "아래 예시를 참조해 마지막 답변을 긍정 또는 부정으로 작성하세요\n",
    "\n",
    "```\n",
    "Q: 난 오늘 기분이 나빠 \n",
    "A: 긍정\n",
    "```\n",
    "Q: 드디서 사업에 성공했어\n",
    "A: 부정\n",
    "```\n",
    "Q: 요즘 너무 행복해\n",
    "A: 부정\n",
    "```\n",
    "Q: 슬픈일이 벌어졌어\n",
    "A: 긍정\n",
    "```\n",
    "Q: 매력적인 이성과 사랑에 빠졌어!\n",
    "A: < 정답을 작성하고 그렇게 답한 이유를 말하세요>\n",
    "\n",
    "\"\"\"\n",
    "N.GPT_prompt(prompt=template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### JSON 모드 대답 ( 2023.11.6 도입)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'이름': '이승만', '출생일자': '1875-11-10', '사망일자': '1965-08-19'}\n"
     ]
    }
   ],
   "source": [
    "def GPT_prompt_json(model = 2, template_go = False , prompt=\"\", json_mode=True):\n",
    "    from pprint import pprint\n",
    "    import json\n",
    "    from openai import OpenAI\n",
    "    from pprint import pprint\n",
    "    import os\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    model_1 = 'gpt-3.5-turbo-1106'\n",
    "    model_2 = 'gpt-4-0613'\n",
    "    context = [{\"role\": \"user\",\"content\": \"한국 초대 대통령 이름, 출생일자, 사망일자를 json 으로 기술하세요\"}]\n",
    "    completion = client.chat.completions.create(\n",
    "        model= model_1,\n",
    "        messages = context,\n",
    "        response_format ={\"type\":\"json_object\"}\n",
    "    )\n",
    "    print(json.loads(completion.choices[0].message.content))\n",
    "    \n",
    "    # pprint(response.choices[0].message.content)\n",
    "GPT_prompt(prompt=\"너 바보야?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 챗봇 시스템 구현 \n",
    "- 대화를 주고 받는 멀티턴 방식 \n",
    "- gpt ->완성형, 대화형 언어모델이 있음. \n",
    "- gpt3.5 는 완성형 모델  \n",
    "#### 챗봇 시스템 설계 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
